<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>LAB</title>
    <link href="https://www.k8s.it/feed.xml" rel="self" />
    <link href="https://www.k8s.it" />
    <updated>1970-01-01T01:00:00+01:00</updated>
    <author>
        <name>lgirardi</name>
    </author>
    <id>https://www.k8s.it</id>

    <entry>
        <title> Kubernetes-postfix</title>
        <author>
            <name>lgirardi</name>
        </author>
        <link href="https://www.k8s.it/kubernetes-postfix.html"/>
        <id>https://www.k8s.it/kubernetes-postfix.html</id>

        <updated>2020-09-15T22:31:44+02:00</updated>
            <summary>
                <![CDATA[
                     Long story short my vps provider changed tha ammount for the small instance from 1$ to 3$ so i took the advantage to switch my postfix service from cloud to onprem. Why, since the world is moving to cloud ? Because my own domain is&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h1> </h1>
<p>Long story short my vps provider changed tha ammount for the small instance from 1$ to 3$<br>so i took the advantage to switch my postfix service from cloud to onprem.</p>
<p>Why, since the world is moving to cloud ?<br>Because my own domain is used just for alerting and small other stuff and 3$ month is creazy :)<br>Anyway i'll lost some good stuff like static ip and possibility ti have a ptr dns.<br>Shit happens it's just for my stuff.</p>
<p>However we have 3 different topics to describe in this project</p>
<ul>
<li>what is an email</li>
<li>postfix configuration</li>
<li>postfix in kubernetes</li>
</ul>
<h2><a id="user-content-what-is-an-email" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-postfix#what-is-an-email"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>what is an email</h2>
<p>send email sometimes is a dedicated work in an enterprise company.<br>There are many aspect to consider , not only infrastructure , like che segmentation of domains strategy,<br>email answer engagement and each isp is using a different threashold to mark your email as a spam,<br>however now we will focus only on the generic configuration with some minimum requirements.</p>
<p>Here some topic that you probably know:</p>
<ul>
<li>TLS (add an encrypted connection in delivery)</li>
<li>Sender-Id (mostly used for microsoft ecosystem)</li>
<li>PTR record (used to check the corrispondence of a real smtp)</li>
<li>SPF record (used on TXT level to define an whitelist of "smtp allowed to ...")</li>
<li>Dkim (a private and public certificate to match the smtp and emails)</li>
<li>Dmarc (a mix with SPF and Dkim to protect the domain from unauthorized use )</li>
</ul>
<h2><a id="user-content-postfix-configuration" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-postfix#postfix-configuration"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>postfix configuration</h2>
<p>The second one is more related to middleware behaviour<br>i have a domain "example.com" and i'd like to</p>
<ul>
<li>receive email from and to this domain</li>
<li>have catchall system to do not configure any email account but using everything <a href="mailto:a@example.com">a@example.com</a>, <a href="mailto:b@example.com">b@example.com</a>, <a href="mailto:whatever@example.com">whatever@example.com</a></li>
<li>relay all the emails to my gmail account</li>
<li>reject the email that are tried to sent outside my chosed domains</li>
</ul>
<p>For all those topics the main configuration is in virtual and transport map in <em>postfix</em><br>There are some articles in internet, i'll avoid to reinvent hot water with the explanation.</p>
<h2><a id="user-content-postfix-in-kubernetes" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-postfix#postfix-in-kubernetes"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>postfix in kubernetes</h2>
<p>just as recap this was the configuration in the cloud vps</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/66d40f312601abf8ba03699a66366d6455c0805f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336363436332f6d6973632f7670732e706e67"><img loading="lazy" title="vps" src="https://camo.githubusercontent.com/66d40f312601abf8ba03699a66366d6455c0805f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336363436332f6d6973632f7670732e706e67" data-is-external-image="true"  alt="vps" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1598366463/misc/vps.png"></a></p>
<p>now i just whitched the MX to my own microk8s lab</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fd6de4c35300c6596ca2eafcfde2d501bd4c9576/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336363436352f6d6973632f6d6963726f6b38732e706e67"><img loading="lazy" title="microk8s" src="https://camo.githubusercontent.com/fd6de4c35300c6596ca2eafcfde2d501bd4c9576/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336363436352f6d6973632f6d6963726f6b38732e706e67" data-is-external-image="true"  alt="microk8s" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1598366465/misc/microk8s.png"></a></p>
<p>However , inside the box a lot of implementation way can be taken</p>
<h3><a id="user-content-scenario-1" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-postfix#scenario-1"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Scenario 1:</h3>
<p>you can build an image for each dedicate purpose</p>
<ul>
<li>postfix</li>
<li>rsyslog</li>
<li>opendkim</li>
<li>tls</li>
</ul>
<h3><a id="user-content-scenario-2" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-postfix#scenario-2"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Scenario 2:</h3>
<p>looking the configuration adopted in <em>Scenario 1</em> , you can add an ingress tcp forward where<br>you can also add a tls layer with cert-manager (the new kube-lego).</p>
<h3><a id="user-content-scenario-3" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-postfix#scenario-3"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Scenario 3:</h3>
<p><em>Scenario 2</em> plus external storage for logs<br>etc etc</p>
<h3><a id="user-content-scenario-lazy" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-postfix#scenario-lazy"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Scenario Lazy:</h3>
<p>Embedded docker images with all you need with a node port (used only because i have a standalone kubernetes node).</p>
<p>Well having everything in one single container the docker image reflect the pachage used in a virtual machine</p>
<pre><code>FROM debian:buster
MAINTAINER lgirardi &lt;l@k8s.it&gt;

EXPOSE 25/tcp

RUN apt-get -y update &amp;&amp; apt-get -yq install \
	postfix \
	bsd-mailx \
	opendkim \
	opendkim-tools \
	sasl2-bin \
	rsyslog \
        supervisor


# Add files
ADD run.sh /opt/run.sh

# Run
CMD /opt/run.sh;/usr/bin/supervisord -c /etc/supervisor/supervisord.conf
</code></pre>
<p>where the <code>run.sh</code> is the supervisord daemon managing the process.</p>
<ul>
<li>postfix</li>
<li>rsyslog</li>
<li>opendkim</li>
</ul>
<p>The structure used is done to leave the configuration as a configmap and secrets<br>this will help in case you have to tune your system whiout regenerate the images that honestly make no sense to be build each deploy.</p>
<p>As you see the deployment files has a huge number of volumes</p>
<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: postfix
  namespace: postfix
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: postfix
  template:
    metadata:
      labels:
        app: postfix
    spec:
      containers:
      - name: postfix
        image: lgirardi/kubernetes-postfix:v0.2
        lifecycle:
          postStart:
            exec:
              command: [ "bin/bash", "-c", "postmap /etc/postfix/virtual &amp;&amp; postmap /etc/postfix/transport &amp;&amp; supervisorctl restart postfix" ]
        securityContext:
          capabilities:
            add:
            - NET_ADMIN
        ports:
        - name: smtp
          containerPort: 25
        volumeMounts:
        - name: opendkim-key
          mountPath: /etc/mail/dkim-k8s/keys/YOUR_DOMAIN/YOUR_DOMAIN.private
          subPath: opendkim-key
        - name: ca-crt
          mountPath: /etc/postfix/tls/ca.crt
          subPath: ca-crt
        - name: ca-key
          mountPath: /etc/postfix/tls/ca.key
          subPath: ca-key
        - name: postfix-transport
          mountPath: /etc/postfix/transport
          subPath: transport
        - name: postfix-virtual
          mountPath: /etc/postfix/virtual
          subPath: virtual
        - name: postfix-headerchecks
          mountPath: /etc/postfix/header_checks
          subPath: header_checks
        - name: postfix-maincf
          mountPath: /etc/postfix/main.cf
          subPath: main.cf
        - name: postfix-opendkimconf
          mountPath: /etc/opendkim.conf
          subPath: opendkim.conf
        - name: postfix-keytable
          mountPath: /etc/opendkim/KeyTable
          subPath: KeyTable
        - name: postfix-signingtable
          mountPath: /etc/opendkim/SigningTable
          subPath: SigningTable
        - name: postfix-trustedhosts
          mountPath: /etc/opendkim/TrustedHosts
          subPath: TrustedHosts
      volumes:
        - name: postfix-transport
          configMap:
            name: postfix-conf
            items:
            - key: transport
              path: transport
        - name: postfix-virtual
          configMap:
            name: postfix-conf
            items:
            - key: virtual
              path: virtual
        - name: postfix-headerchecks
          configMap:
            name: postfix-conf
            items:
            - key: header_checks
              path: header_checks
        - name: postfix-maincf
          configMap:
            name: postfix-conf
            items:
            - key: main.cf
              path: main.cf
        - name: postfix-opendkimconf
          configMap:
            name: postfix-conf
            items:
            - key: opendkim.conf
              path: opendkim.conf
        - name: postfix-keytable
          configMap:
            name: postfix-conf
            items:
            - key: KeyTable
              path: KeyTable
        - name: postfix-signingtable
          configMap:
            name: postfix-conf
            items:
            - key: SigningTable
              path: SigningTable
        - name: postfix-trustedhosts
          configMap:
            name: postfix-conf
            items:
            - key: TrustedHosts
              path: TrustedHosts
        - name: opendkim-key
          secret:
            secretName: postfix-secret
        - name: ca-crt
          secret:
            secretName: postfix-secret
        - name: ca-key
          secret:
            secretName: postfix-secret
</code></pre>
<p>Here we have the configuration for:</p>
<ul>
<li>main.cf</li>
<li>transport</li>
<li>virtual</li>
<li>header_checks</li>
<li>opendkim.conf</li>
<li>KeyTable</li>
<li>SigningTable</li>
<li>TrustedHosts</li>
</ul>
<p>You can change this aspect , is mostly related to the infrastructure where you fit the pod<br>and the company CI/CD</p>
<p><strong>Remember to ADD your right values inside secrets and configmap where you have CAPS like <code>YOUR_DOMAIN</code></strong></p>
<p>running the <em>apply</em> on kubernetes folder you will have the pod running<br><code>postfix postfix-7d664f786c-rmf54 1/1 Running 0 29m</code></p>
<p>and loogking the logs i can see</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/694d0f364b26c0474b15921ff1ff8a4135190933/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336393033322f6d6973632f706f73746669786c6f672e706e67"><img loading="lazy" title="postfixlog" src="https://camo.githubusercontent.com/694d0f364b26c0474b15921ff1ff8a4135190933/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336393033322f6d6973632f706f73746669786c6f672e706e67" data-is-external-image="true"  alt="postfixlog" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1598369032/misc/postfixlog.png"></a></p>
<p>The <code>key data is not secure</code> just a working because i've enabled this option in the configmap <code>RequireSafeKeys false</code><br>but the certificate is applied <code>opendkim[22]: 91E522A000C: DKIM-Signature field added</code></p>
<p>Last one is the check on the client side with the righ option enabled</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/66fffe878e76dbeff1853c4abaf19f846af46529/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336383833352f6d6973632f656d61696c6f7074696f6e2e706e67"><img loading="lazy" title="clientemail" src="https://camo.githubusercontent.com/66fffe878e76dbeff1853c4abaf19f846af46529/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336383833352f6d6973632f656d61696c6f7074696f6e2e706e67" data-is-external-image="true"  alt="clientemail" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1598368835/misc/emailoption.png"></a></p>
<h2><a id="user-content-conclusion" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-postfix#conclusion"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Conclusion</h2>
<p>You can add postfix infrastructure to kubernetes with no problems at all ,<br>this project is a <em>prototype</em> , in a production infrastructure you can work around this to let it rock solid and scalable</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Kubernetes-servicemesh</title>
        <author>
            <name>lgirardi</name>
        </author>
        <link href="https://www.k8s.it/kubernetes-servicemesh.html"/>
        <id>https://www.k8s.it/kubernetes-servicemesh.html</id>

        <updated>2020-09-15T22:31:44+02:00</updated>
            <summary>
                <![CDATA[
                    Do we need a service mesh ?few years ago i started to evaluate this feature fitting in an existing infrastructure There are many concept to consider and many mistake the people usually think Better to start with what is NOT a work for a service mesh So&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2>Do we need a service mesh ?</h2>
<p>few years ago i started to evaluate this feature fitting in an existing infrastructure</p>
<p>There are many concept to consider and many mistake the people usually think<br>Better to start with what is <em>NOT</em> a work for a service mesh</p>
<ul>
<li>is not an apigw (even if could share some components)</li>
<li>is not the place to put firewall rules</li>
<li>is not something magic that boost the applications</li>
<li>is something that if not used with a know scope could generate a mess</li>
</ul>
<p>So what is ...<br>well short answer</p>
<ul>
<li>is the missing link in the infrastructure observability</li>
<li>is a way to handle in a structured way the application routing</li>
<li>is an internal ratelimit / anti ddos / infrastructure layer (be careful)</li>
<li>could be a clever way to improve some application limits (expanded next)</li>
</ul>
<p>Anyway is this something that we can add in our infrastructure ?</p>
<p>There no YES/NO , however we can evaluate the company and the maturity of microservices<br>internal rate limit , is usually a feature that could safe the infrastructure during snowball effects<br>however means that if the infrastructure is SYNC (no decoupling) have the rate limit can just<br>stop the application to serve requests , and this will propagated to the others below.</p>
<p>result: no answer<br>threads safe</p>
<p>Sometimes it's better to have a strategic business login using the a circuit breaker that bring a huge complexity in configuration.</p>
<p>The other point related to rate limit is .. who will maintain those values ?<br>Should be part of deployment pipeline and directly correlated with the application scope<br>In a 200+ micro services infrastructure this could be a huge problem:</p>
<ul>
<li>project that lost ownership</li>
<li>projects not well maintained</li>
<li>new legacy projects</li>
</ul>
<p>So my idea about rate limit is to use it in a specific "strategic" applications and should not indiscriminately added to the whole infrastructure</p>
<p>About the routing feature, we can consider as a more detailed and customized blue green deployment , this specific case it's really useful when we have to deploy new features in production and <em>canary</em> deployment is not enough to cover the business measurement we need.</p>
<p>This feature could be used to keep a specific affinity within the microservices and this is the real feature that some of you can consider, imagine a strict dependencies between application an cache (as usual)<br>So the application <em>Pippo</em> is using the cache <em>Paperino</em></p>
<p>Pippo is a namespace composed by 10 pods<br>Paperino is a cache composed by 6 pods</p>
<p>Imagine that we have the cache as a replication/sharded and we have 2 availability zones</p>
<p>With service mesh we can use labels to say to Pippo to use the cache Paperino only in the availability zone where the call start from Pippo av, this will reduce dramatically the roundtrip and the answer</p>
<p>I played a bit with service mesh in order to answer some questions,<br>however related to firewall rules the right answer is Cilium :-)</p>
<p>With this, I'd like to say that service mash give you a great value only<br>if your infrastructure is able to embrace it and only if you know what you are doing with this infrastructure.</p>
<ul>
<li>observability</li>
<li>routing purpose (this is strictly related to the microservice architecture)</li>
<li>rate limitng</li>
</ul>
<h2><a id="user-content-service-mesh-sample-lab" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#service-mesh-sample-lab"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Service Mesh sample lab</h2>
<p>This lab is provided to discover and test the functionality w'd like to implement in our environment</p>
<h3><a id="user-content-basic-setup" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#basic-setup"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Basic setup</h3>
<ul>
<li>minikube v1.6.2</li>
<li>Kubernetes v1.17.0 on Docker '19.03.5'</li>
</ul>
<p><code>curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64</code> <code>chmod +x minikube</code><br><code>sudo install minikube /usr/local/bin/</code><br><code>minikube start --memory=3000 --cpus=3</code></p>
<ul>
<li>network (since in production we are using flannel that is not able to manage network policy we can start using no CNI to have the environment as much as close to lmn environment)</li>
</ul>
<h4><a id="user-content-namespaces" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#namespaces"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Namespaces</h4>
<p>a → traefik (ingress)<br>b → apache<br>c → application<br>d → redis</p>
<p>b is a namespaces that manage an apache used for some rewrite rules<br>c is a python application that is connected to a redis database, provide some function to set a time, get a time with /set context and /get context<br>d is the redis database</p>
<p>c code</p>
<pre><code>"""
    Example app that integrates with redis and save/get timing
"""
from os import environ
from datetime import datetime
import json
import redis
from flask import Flask, redirect

VERSION = "1.1.1"
REDIS_ENDPOINT = environ.get("REDIS_ENDPOINT", "redis-svc.d-redis.svc.cluster.local")
REDIS_PORT = int(environ.get("REDIS_PORT", "6379"))


APP = Flask(__name__)


@APP.route("/")
def redisapp():
    """Main redirect"""
    return redirect("/get", code=302)


@APP.route("/set")
def set_var():
    """Set the time"""
    red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)
    red.set("time", str(datetime.now()))
    return json.dumps({"time": str(red.get("time"))})


@APP.route("/get")
def get_var():
    """Get the time"""
    red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)
    return json.dumps({"time": str(red.get("time"))})


@APP.route("/reset")
def reset():
    """Reset the time"""
    red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)
    red.delete("time")
    return json.dumps({"time": str(red.get("time"))})


@APP.route("/version")
def version():
    """Get the app version"""
    return json.dumps({"version": VERSION})


@APP.route("/healthz")
def health():
    """Check the app health"""
    try:
        red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)
        red.ping()
    except redis.exceptions.ConnectionError:
        return json.dumps({"ping": "FAIL"})

    return json.dumps({"ping": red.ping()})


@APP.route("/readyz")
def ready():
    """Check the app readiness"""
    return health()


if __name__ == "__main__":
    APP.run(debug=True, host="0.0.0.0")
</code></pre>
<p>Dokerfile</p>
<pre><code>FROM python:3.6-alpine
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
ENTRYPOINT ["python"]
CMD ["app.py"]
</code></pre>
<p>requirements.txt</p>
<pre><code>Flask
redis
pytest
pytest-flask
</code></pre>
<h3><a id="user-content-folders-structure" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#folders-structure"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Folders structure</h3>
<pre><code>kubernetes/
├── 00-traefik
│   ├── A-00-traefik-ns.yaml
│   ├── A-01-traefik-rbac.yaml
│   └── A-02-traefik-ds.yaml
├── 01-apache
│   ├── B-00-k8s-apacherr-ns.yaml
│   ├── B-01-k8s-apacherr-svc.yaml
│   ├── B-02-k8s-apacherr-ing.yaml
│   ├── B-03-k8s-apacherr-dpl.yaml
│   └── B-04-k8s-apacherr-cfm.yaml
├── 02-redis
│   ├── D-00-lab-redis-ns.yaml
│   ├── D-01-lab-redis-svc.yaml
│   └── D-02-lab-redis-dpl.yaml
└── 03-app
    ├── C-00-app-ns.yaml
    ├── C-01-app-svc.yaml
    └── C-02-app-dpl.yaml
</code></pre>
<h3><a id="user-content-startup" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#startup"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Startup</h3>
<p>kubernetes$ kubectl apply -f 00-traefik/</p>
<pre><code>namespace/a-ingress-traefik created  
clusterrole.rbac.authorization.k8s.io/traefik-ingress-controller created    
serviceaccount/traefik-ingress-controller created  
clusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller created
serviceaccount/traefik-ingress-controller created
daemonset.apps/traefik-ingress-controller created
service/traefik-ingress-service created
</code></pre>
<p>kubernetes$ kubectl apply -f 01-apache/</p>
<pre><code>namespace/b-apacherr created
service/apacherr-svc created
ingress.extensions/apacherr-ingress created
deployment.apps/apacherr created
configmap/apacherr-80-config created
</code></pre>
<p>kubernetes$ kubectl apply -f 02-redis/</p>
<pre><code>namespace/d-redis created
service/redis-svc created
deployment.apps/redis created
</code></pre>
<p>kubernetes$ kubectl apply -f 03-app/</p>
<pre><code>namespace/c-app-count created    
service/app-count-svc created  
deployment.apps/pythonapp created  
</code></pre>
<p>kubectl get po --all-namespaces</p>
<pre><code>NAMESPACE           NAME                               READY   STATUS    RESTARTS   AGE
a-ingress-traefik   traefik-ingress-controller-jkppg   1/1     Running   0          5m29s
b-apacherr          apacherr-8b786b45d-g9vcl           1/1     Running   0          5m19s
c-app-count         pythonapp-555d6d88cd-slhfb         1/1     Running   0          4m55s
d-redis             redis-b869b89d-pf6ms               1/1     Running   0          5m12s
kube-system         coredns-6955765f44-6nrdr           1/1     Running   1          74m
kube-system         coredns-6955765f44-9fbgt           1/1     Running   1          74m
kube-system         etcd-minikube                      1/1     Running   1          74m
kube-system         kube-addon-manager-minikube        1/1     Running   1          74m
kube-system         kube-apiserver-minikube            1/1     Running   1          74m
kube-system         kube-controller-manager-minikube   1/1     Running   1          74m
kube-system         kube-proxy-cchls                   1/1     Running   1          74m
kube-system         kube-scheduler-minikube            1/1     Running   1          74m
kube-system         storage-provisioner                1/1     Running   2          74m
</code></pre>
<p>make sure virtualbox 8081 port should be available</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f303afac85505ee6e02651c55518f1eb809a6f97/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731352f6d6973632f696d675f7669727475616c626f782d706f7274666f7277617264696e672e706e67"><img loading="lazy" title="Virtualbox port forwarding" src="https://camo.githubusercontent.com/f303afac85505ee6e02651c55518f1eb809a6f97/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731352f6d6973632f696d675f7669727475616c626f782d706f7274666f7277617264696e672e706e67" data-is-external-image="true"  alt="Virtualbox port forwarding" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1594573715/misc/img_virtualbox-portforwarding.png"></a></p>
<h2><a id="user-content-flow" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#flow"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>flow</h2>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/70a420864968278b8940023ba6aa95dd7bf932a6/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731342f6d6973632f696d675f666c6f772e706e67"><img loading="lazy" title="flow" src="https://camo.githubusercontent.com/70a420864968278b8940023ba6aa95dd7bf932a6/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731342f6d6973632f696d675f666c6f772e706e67" data-is-external-image="true"  alt="flow" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1594573714/misc/img_flow.png"></a></p>
<h5><a id="user-content-inizialize-the-redis-database" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#inizialize-the-redis-database"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>inizialize the redis database</h5>
<p><code>$ curl http://pippo.lan/count/set</code><br>{"time": "b'2019-12-28 20:06:33.919059'"}</p>
<h5><a id="user-content-test-from-apache-to-application-case-1" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#test-from-apache-to-application-case-1"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>test from apache to application (case 1)</h5>
<p><code>$ curl http://pippo.lan/count/get</code><br>{"time": "b'2019-12-28 20:06:33.919059'"}</p>
<h5><a id="user-content-test-from-apache-to-redis-case-2" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#test-from-apache-to-redis-case-2"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>test from apache to redis (case 2)</h5>
<p><code>$ curl http://pippo.lan/redis/GET/time</code><br>{"GET":"2019-12-28 20:06:33.919059"}</p>
<h5><a id="user-content-network-rule-example" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#network-rule-example"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>network rule example</h5>
<p>cilium labels</p>
<pre><code>ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                           IPv6   IPv4            STATUS   
           ENFORCEMENT        ENFORCEMENT                                                                                               
201        Disabled           Disabled          32580      k8s:app=redis                                                10.15.182.193   ready   
                                                           k8s:io.cilium.k8s.namespace.labels.name=d-redis                                      
                                                           k8s:io.cilium.k8s.policy.cluster=default                                             
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                      
                                                           k8s:io.kubernetes.pod.namespace=d-redis                                              
                                                           k8s:track=redis                                                                      
1257       Disabled           Disabled          4          reserved:health                                              10.15.197.106   ready   
1663       Disabled           Disabled          54130      k8s:app=apacherr                                             10.15.192.41    ready   
                                                           k8s:io.cilium.k8s.namespace.labels.name=b-apacherr                                   
                                                           k8s:io.cilium.k8s.policy.cluster=default                                             
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                      
                                                           k8s:io.kubernetes.pod.namespace=b-apacherr                                           
3167       Disabled           Disabled          33702      k8s:app=pythonapp                                            10.15.247.186   ready   
                                                           k8s:io.cilium.k8s.namespace.labels.name=c-app-count                                  
                                                           k8s:io.cilium.k8s.namespace.labels.purpose=app                                       
                                                           k8s:io.cilium.k8s.policy.cluster=default                                             
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                      
                                                           k8s:io.kubernetes.pod.namespace=c-app-count                                          
                                                           k8s:track=pythonapp-stable         
</code></pre>
<p>network rule</p>
<pre><code>apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: isolate-namespace
  namespace: d-redis
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: c-app-count
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: c-app-count

</code></pre>
<p>   </p>
<p>cilium/hubble <a href="https://github.com/cilium/hubble">https://github.com/cilium/hubble</a> <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/70234ad4768db6537d28a417f0e73061ce2e51b4/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f687562626c652d64726f702e706e67"><img loading="lazy" title="hubble" src="https://camo.githubusercontent.com/70234ad4768db6537d28a417f0e73061ce2e51b4/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f687562626c652d64726f702e706e67" data-is-external-image="true"  alt="hubble" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1594574069/misc/hubble-drop.png"></a></p>
<p> </p>
<p>istio/kiali <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/79a5b07227e5651705810596cef972d074ed201f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f697374696f2d6b69616c692e706e67"><img loading="lazy" title="kiali" src="https://camo.githubusercontent.com/79a5b07227e5651705810596cef972d074ed201f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f697374696f2d6b69616c692e706e67" data-is-external-image="true"  alt="kiali" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1594574069/misc/istio-kiali.png"></a></p>
<p> </p>
<p>video Cilium example --&gt; <a href="https://res.cloudinary.com/ethzero/video/upload/v1594574074/misc/cilium.mkv" rel="nofollow">img/cilium.mkv</a></p>
<p>video Istio + Cilium example --&gt; <a href="https://res.cloudinary.com/ethzero/video/upload/v1594574090/misc/istio.mkv" rel="nofollow">img/istio.mkv</a><br> </p>
<h2><a id="user-content-requirements" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-servicemesh#requirements"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>requirements</h2>
<ul>
<li>use service mesh to segregate redis "d" to accept connections only from application "c"<br>expected "case 1" still working, "case 2" stop working and receive an error</li>
</ul>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Kubernetes-apacherr</title>
        <author>
            <name>lgirardi</name>
        </author>
        <link href="https://www.k8s.it/kubernetes-apacherr.html"/>
        <id>https://www.k8s.it/kubernetes-apacherr.html</id>

        <updated>2020-09-15T22:31:44+02:00</updated>
            <summary>
                <![CDATA[
                    The semi-unuseful apache implementation in kubernetesWell , why we are talking about apache httpd in kubernetes ? We have ingress resources , we have ambassador and we are using microservices... True but internet was not built yesterday and for some reasons out of my knowledge&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2>The semi-unuseful apache implementation in kubernetes</h2>
<p>Well , why we are talking about apache httpd in kubernetes ?<br>We have ingress resources , we have ambassador and we are using microservices...<br>True but internet was not built yesterday and for some reasons out of my knowledge ,<br>people are ostinated to manage rewrite rules in apache instead to use a dedicated router application (react, zuul .. database!?!?! etc etc)<br>However sometimes we have to balance between the academic vision and the reality.</p>
<h2><a id="user-content-digression" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-apacherr#digression"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>digression</h2>
<p>Talking about apache https , nginx , haproxy ... i'm referring to the idea behind manage a complex website.<br>A website could be composed my hundreds of microservices but the domain it's usually one<br><a href="http://www.example.com/" rel="nofollow">www.example.com</a></p>
<p><a href="http://www.example.com/" rel="nofollow">www.example.com</a> has the root path /<br>/it/ managed by cms<br>/it/offerte managed by cms<br>/uk/ managed by cms<br>/uk/offers managed by cms<br>/../ whatever<br>/it/clienti/ managed by customer-app<br>/uk/customers/ managed by customers-app<br>/../somethingelse<br>/secure/ managey by payment-app<br>...<br>omg path clash ... so we need to exclude in apache /uk/customers/ from cms proxypass but<br>meantime enable a dedicated proxy pass to a specific application endpoint.<br>and we are mannually manage all language , all applications with static configurations...<br>and if tomorrow we will open APAC ... what we have to do ?<br>and if we need to cover a former third parti company and acquire his seo ranking we should create<br>thousands of redirects ? and how we can can validate avoiding loops ?</p>
<p>A better design start giving the right responsability , that could be managed using a business layer<br>that we can call "front controller" where we can apply all rules.</p>
<p>In terms of responsability all applaction behind this layer should be working by selfcontained logic<br>example... if i have a seo application this should be working without this layer , removing direct dependency<br>same concept for cms application , customers application and so on.<br>So what this layer will do ?</p>
<p>A front controller should be the owner of root path of our websites "/"<br>Should be also responsible to handle all the others paths after the root ones.</p>
<p>Main duties:</p>
<ul>
<li>handle all requests and manage the backend application with business logic</li>
<li>provide dynamic path based on business rules (language + brand + something else)</li>
<li>provide the AB test logic</li>
<li>provide a validation logic</li>
<li>expose a company backoffice to trim the website layout</li>
</ul>
<p>Examples</p>
<p>Having a global websites spread with multiple countris with differents domains/brands and languages we can immagine</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/184bca691d84bf02cd01d06642b3aac6f582d28f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538323238393238352f6d6973632f66726f6e742d636f6e74726f6c6c65722e706e67"><img loading="lazy" src="https://camo.githubusercontent.com/184bca691d84bf02cd01d06642b3aac6f582d28f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538323238393238352f6d6973632f66726f6e742d636f6e74726f6c6c65722e706e67" data-is-external-image="true"  alt="frontcontroller" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1582289285/misc/front-controller.png"></a></p>
<p>Where the microservice/application CMS is responsible to hangle all domains and all languages and the<br>front controller take the ownership to match brand plus .tld (or paths "/fr/")<br>in order to dinamically generate the right url with canonical pages.</p>
<p>Many and many others assumptions can be covered by this componet, however we have to stay grounded<br>and check how we can manage an apache responsible to redirects proxypass an rewrite rules.</p>
<h2><a id="user-content-some-concepts-about-this-project" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-apacherr#some-concepts-about-this-project"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Some concepts about this project</h2>
<p>Even if we are working in a dynamic environment it's no rare to have the traditional layers</p>
<p>DMZ --&gt; layer 1<br>Application --&gt; layer 2<br>Database --&gt;layer 3</p>
<p>In this picture apache httpd should usually placed on layer 1 ,<br>but consider apache not for the common web server but like a "product" ,<br>something that could be managed not by SRE , but Product Engeneer.<br>A product that own a dedicated business, like seo, sem , vanity urls etc etc.</p>
<p>Having those considerations, we can "downgrade" apache httpd in layer 2 like any application<br>and honor the DMZ (if needed ?!?!) on top by ingress/haproxy/bigf5 (where maybe we can terminate the TLS).</p>
<h2><a id="user-content-implementation" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-apacherr#implementation"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Implementation</h2>
<p>The code in this project is designet to manage apache configuration by configmap,<br>however some websites are really complex and there are some limits implication with ectd max object size.</p>
<p>In this scenario it's higly raccomended to deploy the release with a standard pipeline with compiled<br>container on the source.</p>
<h2><a id="user-content-deploy" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-apacherr#deploy"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>deploy</h2>
<p><code>kubectl apply -f apacherr/deployment/</code></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Kubernetes-guacamole</title>
        <author>
            <name>lgirardi</name>
        </author>
        <link href="https://www.k8s.it/kubernetes-guacamole.html"/>
        <id>https://www.k8s.it/kubernetes-guacamole.html</id>

        <updated>2020-09-15T22:31:44+02:00</updated>
            <summary>
                <![CDATA[
                    Here we are , another apache guacamole implementation in kubernetesThis service is designed to avoid the usage of mysql and create a standalone project The main idea is to use the user-mapping.xml as a config map For production environment i suggest to add the ldap auth (ad.openldap,freeipa),&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <div class="flex-shrink-0 col-12 col-md-9 mb-4 mb-md-0">
<div id="readme" class="Box md js-code-block-container Box--responsive">
<div class="Box-body px-5 pb-5">
<article class="markdown-body entry-content container-lg">
<h2>Here we are , another apache guacamole implementation in kubernetes</h2>
<p>This service is designed to avoid the usage of mysql and create a standalone project</p>
<p>The main idea is to use the <strong>user-mapping.xml</strong> as a config map</p>
<p>For production environment i suggest to add the ldap auth (ad.openldap,freeipa),<br>mysql database should be managed with a dedicated instances and mantained in case of "exit"</p>
<h2><a id="user-content-what-is-a-bastion-host" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-guacamole#what-is-a-bastion-host"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>what is a bastion host</h2>
<p>On the Internet, a bastion host is the only host computer that a company allows to be addressed<br>directly from the public network and that is designed to screen the rest of its network from security exposure.</p>
<h2><a id="user-content-how-this-tool-can-be-used" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-guacamole#how-this-tool-can-be-used"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>how this tool can be used</h2>
<p>The tool is designed to be used when you have some dedicated service in production and you have to keep<br>the control of access and account used , guacamole has the ability to manage the most used platforms (windows and linux)<br>as host in backend to be reached from developers ... contractors ...</p>
<h2><a id="user-content-why-in-kubernetes" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-guacamole#why-in-kubernetes"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>why in kubernetes</h2>
<p>Since the auth method could scale by configmap or ldap or mysql , is designed to scale<br>we have also the benefits to have a low footprint compared to a traditional vm.</p>
<h2><a id="user-content-config-to-change" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-guacamole#config-to-change"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>config to change</h2>
<p>Before deploy you need to specify the following parameters in guacamole folder</p>
<ul>
<li>YOUR_DOMAIN to reflect your domain url in 03-guacamole-ing.yaml</li>
<li>user YOUR_USERNAME / YOUR_MD5_PWD and hosts xml configuration in 04-guacamole-cfm.yaml following <a href="https://guacamole.apache.org/doc/gug/configuring-guacamole.html#user-mapping" rel="nofollow">https://guacamole.apache.org/doc/gug/configuring-guacamole.html#user-mapping</a></li>
</ul>
<p>screenshots</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/905e74d0ce81c8b239f67d405567100a3f181292/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d77696e2e706e67"><img loading="lazy" src="https://camo.githubusercontent.com/905e74d0ce81c8b239f67d405567100a3f181292/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d77696e2e706e67" data-is-external-image="true"  alt="windows" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1580850552/misc/guacamole-win.png"></a><br><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fd53b1991cd9693679aae9aadf72bc75d025c2ad/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d6c696e75782e706e67"><img loading="lazy" src="https://camo.githubusercontent.com/fd53b1991cd9693679aae9aadf72bc75d025c2ad/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d6c696e75782e706e67" data-is-external-image="true"  alt="linux" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1580850552/misc/guacamole-linux.png"></a></p>
<h2><a id="user-content-deploy" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-guacamole#deploy"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>deploy</h2>
<p><code>kubectl apply -f guacd</code></p>
<p><code>kubectl apply -f guacamole</code></p>
<p>You can secure the connection with kube-lego and use cillium to add network rules </p>
</article>
</div>
</div>
</div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Kubernetes-strongswan</title>
        <author>
            <name>lgirardi</name>
        </author>
        <link href="https://www.k8s.it/kubernetes-strongswan.html"/>
        <id>https://www.k8s.it/kubernetes-strongswan.html</id>

        <updated>2020-09-15T22:31:44+02:00</updated>
            <summary>
                <![CDATA[
                    How we can manage vpn in kubernetes environmentHi there , this project is to cover the vpn ipsec-xauth topic in a kubernetes evironment, the goal of this is to have the less effort possible when we have to manage users. Architecture Requirements: WHYThe traditional ipsec-xauth&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <div class="flex-shrink-0 col-12 col-md-9 mb-4 mb-md-0">
<div id="readme" class="Box md js-code-block-container Box--responsive">
<div class="Box-body px-5 pb-5">
<article class="markdown-body entry-content container-lg">
<h2>How we can manage vpn in kubernetes environment</h2>
<p>Hi there , this project is to cover the vpn ipsec-xauth topic in a kubernetes evironment,<br>the goal of this is to have the less effort possible when we have to manage users.</p>
<p>Architecture<br><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ee7bbe0fe8e2f17b0bda45b6b92d585105d9adcc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538343733313733352f6d6973632f76706e5f6469616772616d2e6a7067"><img loading="lazy" src="https://camo.githubusercontent.com/ee7bbe0fe8e2f17b0bda45b6b92d585105d9adcc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538343733313733352f6d6973632f76706e5f6469616772616d2e6a7067" data-is-external-image="true"  alt="architecture" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1584731735/misc/vpn_diagram.jpg"></a></p>
<p>Requirements:</p>
<ul>
<li>Kubernetes</li>
<li>Strongswan</li>
<li>Microsoft Acrive Directory / openldap / freeipa etc etc LDAP (i'll use ldap instead the software name)</li>
</ul>
<h2><a id="user-content-why" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-strongswan#why"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>WHY</h2>
<p>The traditional ipsec-xauth vpn with ikev1 is based on PSK<br>and a client username/password , this is a problem when the credential are stored in a file<br>in kubernetes update a file always mean rollout a new deploy or create a procedure to<br>make effective the changes.<br>So the idea is to deploy something that doesn't need any interaction<br>after the deploy and manage the clients, with the company standards,<br>like password expiration, password complexity, groups attributions and so on.</p>
<h2><a id="user-content-how" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/kubernetes-strongswan#how"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>HOW</h2>
<p>In order to have a fully managed services we can leverage the usage of ldap procedures (that all company has).<br>Strongswan (a fork of *swan ipsec software) could be integrated with ldap with pam.<br>pam is ... well --&gt; <a href="https://tldp.org/HOWTO/User-Authentication-HOWTO/x115.html" rel="nofollow">https://tldp.org/HOWTO/User-Authentication-HOWTO/x115.html</a></p>
<p>So what we need in ldap ?<br>We need:</p>
<ul>
<li>a technical user that is a low level profile that will be used only to check the users inside the ldap tree and the groups associated</li>
<li>a group to associate to people who need/granted the vpn access</li>
</ul>
<p>in this scenario tech users is --&gt; <em>ldapbind</em><br>group is --&gt; <em>vpn</em></p>
<p>here some screen related</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/48427e34136d63b4b7348ba8c2148e178665cdf0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f62696e645f757365722e706e67"><img loading="lazy" src="https://camo.githubusercontent.com/48427e34136d63b4b7348ba8c2148e178665cdf0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f62696e645f757365722e706e67" data-is-external-image="true"  alt="ldapbind" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584730828/misc/strongswan_bind_user.png"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/141e29aaed92e477719b517dd704c815b18c23bc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f757365725f76706e5f67726f75702e706e67"><img loading="lazy" src="https://camo.githubusercontent.com/141e29aaed92e477719b517dd704c815b18c23bc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f757365725f76706e5f67726f75702e706e67" data-is-external-image="true"  alt="vpn group" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584730828/misc/strongswan_user_vpn_group.png"></a></p>
<p>Then... now we have to configure configure the Docker image in order to support pam ldap.</p>
<p>Dockerfile</p>
<pre><code>FROM debian:stretch
MAINTAINER lgirardi &lt;l@k8s.it&gt;


RUN apt-get -y update &amp;&amp; apt-get -yq install \
        strongswan \
        libcharon-extra-plugins \
        iptables \
        kmod \
        libpam-ldap \
        vim

EXPOSE 500/udp 4500/udp

CMD /usr/sbin/ipsec start --nofork
</code></pre>
<p>libpam-ldap and libcharon-extra-plugins are what we need to perform this kind of integration.</p>
<p>Since strongswan is not traditionally used in kubernetes , has some files that needs a configuration.<br>ENV variables are the most useful to configure it,<br>unfortunately the process is not able to share the env this the child process,<br>so we will work with 2 concepts,<br>use the configmap for all files we need to configure use the secrets for all sensitive data we need to add</p>
<p>files configured:</p>
<ul>
<li>ipsec.conf (the strongswan main configuration)</li>
<li>xauth-pam.conf (strongswan configuration to enable pam)</li>
<li>attr.conf (strongswan configuration file for split-tunnel)<br><em>split-tunnel is when you want to move in vpn only the company subnet and use the home gateway for all the other usages</em></li>
<li>ipsec (pam configuration in /etc/pam.d)</li>
</ul>
<p>secrets:</p>
<ul>
<li>ipsec.secrets (file with the ipsec PSK) rif. 003-configmap.yaml</li>
<li>pam_ldap.conf (configuration used by pam module to connect to ldap) rif. 002-secrets.yaml</li>
</ul>
<p><em>remember that all secrets files are managed using base64 encoding</em></p>
<p>When we have multiple files to spread in different locations we have to create some tricks,<br>one is to create symlink in the Dockerfile , however we have to keep the configuration<br>as much as possible agnostic from the Dockerfile.</p>
<p><em>volume</em> and <em>volumeMounts</em> can help on this topic</p>
<pre><code>volumeMounts:
- name: psk
  mountPath: /etc/ipsec.secrets
  subPath: psk
  readOnly: true
- name: pamldap
  mountPath: /etc/pam_ldap.conf
  subPath: pamldap
- name: strongswan-attr
  mountPath: /etc/strongswan.d/charon/attr.conf
  subPath: attr.conf
- name: strongswan-xauth-pam
  mountPath: /etc/strongswan.d/charon/xauth-pam.conf
  subPath: xauth-pam.conf
- name: strongswan-ipsec
  mountPath: /etc/pam.d/ipsec
  subPath: ipsec
- name: strongswan-ipseconf
  mountPath: /etc/ipsec.conf
  subPath: ipsec.conf
volumes:
- name: strongswan-attr
  configMap:
    name: strongswanconfigmap
    items:
    - key: attr.conf
      path: attr.conf
- name: strongswan-xauth-pam
  configMap:
    name: strongswanconfigmap
    items:
    - key: xauth-pam.conf
      path: xauth-pam.conf
- name: strongswan-ipsec
  configMap:
    name: strongswanconfigmap
    items:
    - key: ipsec
      path: ipsec
- name: strongswan-ipseconf
  configMap:
    name: strongswanconfigmap
    items:
    - key: ipsec.conf
      path: ipsec.conf
- name: psk
  secret:
    secretName: strongswan-secret
- name: pamldap
  secret:
    secretName: strongswan-secret
</code></pre>
<p>Now we have all configured, we can just run<br><code>kubectl apply -f deploy</code></p>
<p>We will have soon a pod into strongswan namespace</p>
<pre><code># kubectl get pods -n strongswan
NAME                          READY   STATUS    RESTARTS   AGE
strongswan-77bfbb9f9f-57hmz   1/1     Running   0          22h
</code></pre>
<p>Since the service is configured with nodport we need to enable the default 500 and 4500<br>in our firewall , matching the kubernetes ports 30000-32767, in this this service are</p>
<pre><code>ports:
- name: isakmp-udp
  protocol: UDP
  nodePort: 30500
  port: 500
  targetPort: 500
- name: ipsec-nat-t
  protocol: UDP
  nodePort: 30450
  port: 4500
  targetPort: 4500
type: NodePort
</code></pre>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/9a42ba23f208fb8562105b7b19d240bc5e495426/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832372f6d6973632f7374726f6e677377616e5f6669726577616c6c5f6e61742e706e67"><img loading="lazy" src="https://camo.githubusercontent.com/9a42ba23f208fb8562105b7b19d240bc5e495426/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832372f6d6973632f7374726f6e677377616e5f6669726577616c6c5f6e61742e706e67" data-is-external-image="true"  alt="firewall configuration" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584730827/misc/strongswan_firewall_nat.png"></a></p>
<p>We can configure our standard client (cisco ipsec client is enough)</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ace3ff6a96cf31968f11209b7b05fce4ea5487a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733353439332f6d6973632f7374726f6e677377616e5f616e64726f69645f636c69656e742e706e67"><img loading="lazy" src="https://camo.githubusercontent.com/ace3ff6a96cf31968f11209b7b05fce4ea5487a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733353439332f6d6973632f7374726f6e677377616e5f616e64726f69645f636c69656e742e706e67" data-is-external-image="true"  alt="android configuration" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/c_scale,w_320/v1584735493/misc/strongswan_android_client.png"></a></p>
<pre><code># kubectl logs strongswan-77bfbb9f9f-57hmz -n strongswan
Starting strongSwan 5.5.1 IPsec [starter]...
no netkey IPsec stack detected
no KLIPS IPsec stack detected
no known IPsec stack detected, ignoring!
charon (13) started after 80 ms
00[DMN] Starting IKE charon daemon (strongSwan 5.5.1, Linux 4.15.0-70-generic, x86_64)
00[CFG] mapping attribute type split-exclpude failed
00[CFG] loading ca certificates from '/etc/ipsec.d/cacerts'
00[CFG] loading aa certificates from '/etc/ipsec.d/aacerts'
00[CFG] loading ocsp signer certificates from '/etc/ipsec.d/ocspcerts'
00[CFG] loading attribute certificates from '/etc/ipsec.d/acerts'
00[CFG] loading crls from '/etc/ipsec.d/crls'
00[CFG] loading secrets from '/etc/ipsec.secrets'
00[CFG]   loaded IKE secret for %any
00[CFG] loaded 0 RADIUS server configurations
00[CFG] HA config misses local/remote address
00[LIB] loaded plugins: charon aes rc2 sha2 sha1 md5 random nonce x509 revocation constraints pubkey pkcs1 pkcs7 pkcs8 pkcs12 pgp dnskey sshkey pem openssl fips-prf gmp agent xcbc hmac gcm attr kernel-netlink resolve socket-default connmark farp stroke updown eap-identity eap-aka eap-md5 eap-gtc eap-mschapv2 eap-radius eap-tls eap-ttls eap-tnc xauth-generic xauth-eap xauth-pam tnc-tnccs dhcp lookip error-notify certexpire led addrblock unity
00[LIB] dropped capabilities, running as uid 0, gid 0
00[JOB] spawning 16 worker threads
05[CFG] received stroke: add connection 'roadw'
05[CFG] adding virtual IP address pool 172.16.17.0/29
05[CFG] added configuration 'roadw'
08[NET] received packet: from 10.1.1.1[36312] to 10.1.1.84[500] (756 bytes)
08[ENC] parsed ID_PROT request 0 [ SA V V V V V V V V ]
08[IKE] received NAT-T (RFC 3947) vendor ID
08[IKE] received draft-ietf-ipsec-nat-t-ike-02 vendor ID
08[IKE] received draft-ietf-ipsec-nat-t-ike-02\n vendor ID
08[IKE] received draft-ietf-ipsec-nat-t-ike-00 vendor ID
08[IKE] received XAuth vendor ID
08[IKE] received Cisco Unity vendor ID
08[IKE] received FRAGMENTATION vendor ID
08[IKE] received DPD vendor ID
08[IKE] 10.1.1.1 is initiating a Main Mode IKE_SA
08[ENC] generating ID_PROT response 0 [ SA V V V V ]
08[NET] sending packet: from 10.1.1.84[500] to 10.1.1.1[36312] (160 bytes)
05[NET] received packet: from 10.1.1.1[36312] to 10.1.1.84[500] (228 bytes)
05[ENC] parsed ID_PROT request 0 [ KE No NAT-D NAT-D ]
05[IKE] local host is behind NAT, sending keep alives
05[IKE] remote host is behind NAT
05[ENC] generating ID_PROT response 0 [ KE No NAT-D NAT-D ]
05[NET] sending packet: from 10.1.1.84[500] to 10.1.1.1[36312] (244 bytes)
09[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (92 bytes)
09[ENC] parsed ID_PROT request 0 [ ID HASH ]
09[CFG] looking for XAuthInitPSK peer configs matching 10.1.1.84...10.1.1.1[100.106.113.62]
09[CFG] selected peer config "roadw"
09[ENC] generating ID_PROT response 0 [ ID HASH ]
09[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (92 bytes)
09[ENC] generating TRANSACTION request 3276308191 [ HASH CPRQ(X_USER X_PWD) ]
09[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (76 bytes)
11[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (108 bytes)
11[ENC] parsed TRANSACTION response 3276308191 [ HASH CPRP(X_USER X_PWD) ]
11[IKE] PAM authentication of 'lgirardi' successful
11[IKE] XAuth authentication of 'lgirardi' successful
11[ENC] generating TRANSACTION request 1380277626 [ HASH CPS(X_STATUS) ]
11[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (76 bytes)
10[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (108 bytes)
10[ENC] parsed INFORMATIONAL_V1 request 4006980307 [ HASH N(INITIAL_CONTACT) ]
12[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (92 bytes)
12[ENC] parsed TRANSACTION response 1380277626 [ HASH CPA(X_STATUS) ]
12[IKE] IKE_SA roadw[1] established between 10.1.1.84[ETHZERO_HOME_VPN]...10.1.1.1[100.106.113.62]
12[IKE] scheduling rekeying in 86047s
12[IKE] maximum IKE_SA lifetime 86227s
</code></pre>
<p>ok now i'm connected and i can see my network in tun0</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0ec58f59178a15278c87059d926b2a8b7b2938a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733303936302f6d6973632f7374726f6e677377616e5f636c69656e745f616e64726f69642e6a7067"><img loading="lazy" src="https://camo.githubusercontent.com/0ec58f59178a15278c87059d926b2a8b7b2938a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733303936302f6d6973632f7374726f6e677377616e5f636c69656e745f616e64726f69642e6a7067" data-is-external-image="true"  alt="android ip" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/c_scale,w_320/v1584730960/misc/strongswan_client_android.jpg"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/89492159c8fb5380197b4ecd266dce5c4068a9a0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733363033342f6d6973632f7374726f6e677377616e5f616e64726f69645f70696e672e6a7067"><img loading="lazy" src="https://camo.githubusercontent.com/89492159c8fb5380197b4ecd266dce5c4068a9a0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733363033342f6d6973632f7374726f6e677377616e5f616e64726f69645f70696e672e6a7067" data-is-external-image="true"  alt="android ping" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/c_scale,w_320/v1584736034/misc/strongswan_android_ping.jpg"></a></p>
<p>Thats all ... here my connection</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b702d2df92e56ffae8f754aed08e84ebd4d0595f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733363332382f6d6973632f7374726f6e677377616e5f7374726f6b655f737461747573616c6c2e706e67"><img loading="lazy" src="https://camo.githubusercontent.com/b702d2df92e56ffae8f754aed08e84ebd4d0595f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733363332382f6d6973632f7374726f6e677377616e5f7374726f6b655f737461747573616c6c2e706e67" data-is-external-image="true"  alt="strongswan connection" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584736328/misc/strongswan_stroke_statusall.png"></a></p>
</article>
</div>
</div>
</div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Docker-latency</title>
        <author>
            <name>lgirardi</name>
        </author>
        <link href="https://www.k8s.it/docker-latency.html"/>
        <id>https://www.k8s.it/docker-latency.html</id>

        <updated>2020-09-15T22:31:44+02:00</updated>
            <summary>
                <![CDATA[
                    aka the network blaming toolSo again another grafana stack with docker Well yes but with a precise scope In this period we are almost all working from home, the blaming topic is usually the connection with our offices or the datacenters. Is not so rare&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2><a id="user-content-aka-the-network-blaming-tool" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/docker-latency#aka-the-network-blaming-tool"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>aka the network blaming tool</h2>
<p>So again another grafana stack with docker<br>Well yes but with a precise scope</p>
<p>In this period we are almost all working from home,<br>the blaming topic is usually the connection with our offices or the datacenters.</p>
<p>Is not so rare for a network Administrator hear people that sais ,<br><em>the vpn is slow</em> , <em>i cannot connect to ... $something</em> , bla bla bla</p>
<p>In my experience this is usually due to the quality of the provider,<br>sometimes is also a problem on route path on T2/T3 providers</p>
<h3><a id="user-content-how-we-can-undestand-if-our-network-is-really-slow-" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/docker-latency#how-we-can-undestand-if-our-network-is-really-slow-"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>HOW we can undestand if our network is really slow ?</h3>
<p>The idea is to start a grafana stack ready-made to handle the basics statistics of our internet connection.<br>We need to choose some endpoints to monitor, example , your vpn endpoint , your datacenter/office public ip , the main dns servers and so on</p>
<h4><a id="user-content-requirements" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/docker-latency#requirements"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Requirements</h4>
<ul>
<li>Docker</li>
<li>Docker Compose</li>
</ul>
<h4><a id="user-content-stack" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/docker-latency#stack"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Stack</h4>
<ul>
<li>Influxdb</li>
<li>Grafana</li>
<li>Telegraf</li>
</ul>
<h4><a id="user-content-tree" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/docker-latency#tree"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tree</h4>
<pre><code>├── .env
├── Makefile
├── README.md
├── docker
│   ├── grafana
│   │   ├── Dashboard-PING.json
│   │   ├── dashboard.yaml
│   │   └── datasource.yaml
│   ├── influxdb
│   │   ├── influxdb.conf
│   │   
│   └── telegraf
│       └── telegraf.conf
├── docker-compose.yml
</code></pre>
<p>Makefile is ... well a makefile , commands allowed<br><em>up , down, dev, down, logs, clean</em><br>up is to startup the stack<br>down to shutdown clean is done to remove also the storage saved for influxdb and grafana</p>
<p>.env contains the grafana and influxdb credentials (yes the default password is quite complicated)<br>Since this tool is hosted in your laptop (could be everywhere), never mind the <em>security</em></p>
<pre><code>GRAFANA_USER=admin
GRAFANA_PASSWORD=EQyFJpjxvJG8k2K8
INFLUXDB_DOMAIN=influxdb
INFLUXDB_DATABASE=ping
</code></pre>
<h3><a id="user-content-configuration" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/docker-latency#configuration"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Configuration</h3>
<p>We just need to choose the endpoints we'd like to monitor from our internet connection This could be done editing <em>telegraf.conf</em></p>
<pre><code>[global_tags]
[agent]
  interval = "10s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  hostname = "local-telegraf"
  omit_hostname = false
[[outputs.influxdb]]
   urls = ["http://127.0.0.1:8086"]
   database = "ping"
[[inputs.ping]]
urls = ["1.1.1.1", "8.8.8.8", "208.67.222.222", "test1.velocable.com"]
count = 7
ping_interval = 1.0
</code></pre>
<p>Edit <em>urls =</em> adding / modify the endpoints<br>(in this example, Cloudflare dns , Google dns, opendns, and a server in Madrid used for speedtest)</p>
<p>The configuration is collecting information every 10 seconds , and run a ping command 7 time each with 1 second delay.</p>
<h3><a id="user-content-startup" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/docker-latency#startup"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Startup</h3>
<p>Inside the main folder run</p>
<p><code>make up</code></p>
<p>output:</p>
<pre><code>docker-latency$ make up
docker-compose -f docker-compose.yml up -d
Creating network "docker-latency_default" with the default driver
Creating grafana  ... done
Creating influxdb ... done
Creating telegraf ... done
</code></pre>
<p>login to:<br><code>http://localhost:3000/ </code>admin/EQyFJpjxvJG8k2K8</p>
<p>you will see</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/56bea14df7a89b07f4e319b45ad4d27c39ad865f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353634313235322f6d6973632f67726166616e615f686f6d652e706e67"><img loading="lazy" src="https://camo.githubusercontent.com/56bea14df7a89b07f4e319b45ad4d27c39ad865f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353634313235322f6d6973632f67726166616e615f686f6d652e706e67" data-is-external-image="true"  alt="grafana_home" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1585641252/misc/grafana_home.png"></a></p>
<p>than , checking for the only board present --&gt; <em>internet latency</em></p>
<p>you will have all details about the endpoint chosen , packet loss especially</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5fd87b371e34b4497018003fcd41cd2e09d23c72/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353539353832342f6d6973632f67726166616e615f70696e672e706e67"><img loading="lazy" src="https://camo.githubusercontent.com/5fd87b371e34b4497018003fcd41cd2e09d23c72/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353539353832342f6d6973632f67726166616e615f70696e672e706e67" data-is-external-image="true"  alt="grafana_ping" data-canonical-src="https://res.cloudinary.com/ethzero/image/upload/v1585595824/misc/grafana_ping.png"></a></p>
<p>100% packet loss simulated disabling network card for few seconds.<br>The dashboard is using variables in order to create 1 row for each endpoint.</p>
<h3><a id="user-content-conclusion" class="anchor" aria-hidden="true" href="https://github.com/lorenzogirardi/docker-latency#conclusion"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Conclusion</h3>
<p>Now we have data, so we know what is going on in our internet connection and we can probably<br>have more details about the <em>infomagic</em> words like ... <em>is slow</em></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Terraform your free Claudflare account</title>
        <author>
            <name>lgirardi</name>
        </author>
        <link href="https://www.k8s.it/terraform-your-free-claudflare-account.html"/>
        <id>https://www.k8s.it/terraform-your-free-claudflare-account.html</id>
            <category term="waf"/>
            <category term="terraform"/>
            <category term="gitlab"/>
            <category term="cloudflare"/>
            <category term="cdn"/>
            <category term="automation"/>

        <updated>2020-09-15T22:31:44+02:00</updated>
            <summary>
                <![CDATA[
                    So... after some experience with akamai www.ethzero.it is an alias for aku-cs-akamaiflowers.com.edgesuite.net. aku-cs-akamaiflowers.com.edgesuite.net is an alias for a169.dscksd.akamai.net. a169.dscksd.akamai.net has address 193.45.15.98 a169.dscksd.akamai.net has address 193.45.15.122 a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f62 a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f7aand some others with Incapsula bunker.ethzero.it is an alias for&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>So...</p>
<p>after some experience with akamai </p>
<pre><code><em>www.ethzero.it is an alias for aku-cs-akamaiflowers.com.edgesuite.net.</em></code><br><code><em>aku-cs-akamaiflowers.com.edgesuite.net is an alias for a169.dscksd.akamai.net.</em></code><br><code><em>a169.dscksd.akamai.net has address 193.45.15.98</em></code><br><code><em>a169.dscksd.akamai.net has address 193.45.15.122</em></code><br><code><em>a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f62</em></code><br><code><em>a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f7a</em></code></pre>
<p>and some others with Incapsula</p>
<pre><code><em>bunker.ethzero.it is an alias for ve7cu.x.incapdns.net.</em></code><br><code><em>ve7cu.x.incapdns.net has address 107.154.167.38</em></code></pre>
<p>It's now the moment to talk about Cloudflare</p>
<p> <a href="https://www.cloudflare.com/">Claudflare</a> provide a good free account that allow you to hide your source ip or you want to discover how it's work the free waf protection or have a https certificate having your origin in http and so on ... but what is really cool and quickwin than the competitors is the API support and the native integration with <a href="https://www.terraform.io/docs/providers/cloudflare/index.html">Terraform</a></p>
<p><img loading="lazy" src="https://www.k8s.it/media/posts/5/git-terraform-cloudflare.png" sizes="(max-width: 48em) 100vw, 768px" srcset="https://www.k8s.it/media/posts/5/responsive/git-terraform-cloudflare-xs.png 300w ,https://www.k8s.it/media/posts/5/responsive/git-terraform-cloudflare-sm.png 480w ,https://www.k8s.it/media/posts/5/responsive/git-terraform-cloudflare-md.png 768w ,https://www.k8s.it/media/posts/5/responsive/git-terraform-cloudflare-lg.png 1024w ,https://www.k8s.it/media/posts/5/responsive/git-terraform-cloudflare-xl.png 1360w ,https://www.k8s.it/media/posts/5/responsive/git-terraform-cloudflare-2xl.png 1600w"  alt="" width="2394" height="1254"></p>
<p>Terraform is the most integrated tool for cloud (not only) automation and infrastructure as a code </p>
<p>Here some steps that can show how it's esay deploy a configuration</p>
<p>First of all , retrive the api key from Cloudflare portal</p>
<p><img loading="lazy" src="https://www.k8s.it/media/posts/5/cloudflare-api-key.png" sizes="(max-width: 48em) 100vw, 768px" srcset="https://www.k8s.it/media/posts/5/responsive/cloudflare-api-key-xs.png 300w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-api-key-sm.png 480w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-api-key-md.png 768w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-api-key-lg.png 1024w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-api-key-xl.png 1360w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-api-key-2xl.png 1600w"  alt="" width="1922" height="556"></p>
<p><img loading="lazy" src="https://www.k8s.it/media/posts/5/cloudflare-global-apikey.png" sizes="(max-width: 48em) 100vw, 768px" srcset="https://www.k8s.it/media/posts/5/responsive/cloudflare-global-apikey-xs.png 300w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-global-apikey-sm.png 480w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-global-apikey-md.png 768w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-global-apikey-lg.png 1024w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-global-apikey-xl.png 1360w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-global-apikey-2xl.png 1600w"  alt="" width="1910" height="396"> </p>
<p>then start the main terraform file in a dedicated folder (better in a <a href="https://gitlab.com/">gitlab</a> repo)</p>
<pre><code>$ cat cloudflare-auth.tf</code><code><br>provider "cloudflare" {<br> email = "cloudflare_registration_email"<br> token = "cloudflare_token_api_key"<br>}<br></code></pre>
<p>make a $<code>terraform init</code> and now you can start to configure your account</p>
<p>manage your domain(s)</p>
<pre>$ <code>cat cloudflare_domains.tf</code><br><code>variable "domain" {</code><br><code> default = "k8s.it"</code><br><code>} </code></pre>
<p> </p>
<p>create dns configuration</p>
<pre>$ <code>cat cloudflare_dns.tf</code><br><code>resource "cloudflare_record" "www" {</code><br><code> domain = "${var.domain}"</code><br><code> name = "www"</code><br><code> value = "something.github.io"</code><br><code> type = "CNAME"</code><br><code> proxied = true</code><br><code>}</code><br><br><code>resource "cloudflare_record" "smtp" {</code><br><code> domain = "${var.domain}"</code><br><code> name = "smtp"</code><br><code> value = "IP.OF.PRIVATE.VPS"</code><br><code> type = "A"</code><br><code> proxied = false</code><br><code>}</code><br><br><code>resource "cloudflare_record" "services" {</code><br><code> domain = "${var.domain}"</code><br><code> name = "services"</code><br><code> value = "something.related.to.my.home"</code><br><code> type = "CNAME"</code><br><code> proxied = true</code><br><code>}</code><br><br><code>resource "cloudflare_record" "mx" {</code><br><code> domain = "${var.domain}"</code><br><code> name = "${var.domain}"</code><br><code> value = "smtp.k8s.it"</code><br><code> type = "MX"</code><br><code> priority = "1"</code><br><code>}</code><br><br><code>resource "cloudflare_record" "google-verification" {</code><br><code> domain = "${var.domain}"</code><br><code> name = "${var.domain}"</code><br><code> value = "google-site-verification=fdsfdssgfdg4teurtxh"</code><br><code> type = "TXT"</code><br><code>}</code><br><br><code>resource "cloudflare_record" "spf" {</code><br><code> domain = "${var.domain}"</code><br><code> name = "${var.domain}"</code><br><code> value = "v=spf1 ip4:IP.OF.PRIVATE.VPS mx ~all"</code><br><code> type = "TXT"</code><br><code>}</code></pre>
<p>Force the HTTPS with page rules</p>
<pre>$ <code>cat cloudflare_rules.tf</code><br><code>resource "cloudflare_page_rule" "always_use_https_www" {</code><br><code> zone = "${var.domain}"</code><br><code> target = "http://www.${var.domain}/*"</code><br><code> priority = 1</code><br><br><code> actions = {</code><br><code> always_use_https = "true",</code><br><code> }</code><br><code>}</code><br><br><code>resource "cloudflare_page_rule" "always_use_https_services" {</code><br><code> zone = "${var.domain}"</code><br><code> target = "http://services.${var.domain}/*"</code><br><code> priority = 2</code><br><br><code> actions = {</code><br><code> always_use_https = "true",</code><br><code> }</code><br><code>}</code></pre>
<p>And finally create the common zone settings </p>
<pre>$ <code>cat cloudflare_zone.tf</code><br><code>resource "cloudflare_zone_settings_override" "k8s-settings" {</code><br><code> name = "${var.domain}"</code><br><br><code> settings {</code><br><code> tls_1_3 = "on"</code><br><code> ssl = "flexible"</code><br><code> opportunistic_encryption = "on"</code><br><code> brotli = "on"</code><br><code> automatic_https_rewrites = "on"</code><br><code> security_level = "medium"</code><br><code> minify {</code><br><code> css = "on"</code><br><code> js = "on"</code><br><code> html = "on"</code><br><code> }</code><br><code> browser_cache_ttl = "14400"</code><br><code> }</code><br><code>}</code></pre>
<p>use the terraform plan to check if everything it's of and terrafom plan to apply the changes</p>
<pre>$ <code>terraform apply</code><br><code>cloudflare_record.mx: Refreshing state... (ID: c3624cc8fd163199ec082649a55f337a)</code><br><code>cloudflare_record.services: Refreshing state... (ID: 09041dfd16cbbf3b6915e79b14dc5466)</code><br><code>cloudflare_page_rule.always_use_https_services: Refreshing state... (ID: 92e196e6c7c8cba1f0759a60d713b0b9)</code><br><code>cloudflare_record.spf: Refreshing state... (ID: 3743b9f0be0a2c7a69245e169cf06ea5)</code><br><code>cloudflare_zone_settings_override.k8s-settings: Refreshing state... (ID: d4acc5e5713a0dede4f238b829f98947)</code><br><code>cloudflare_record.smtp: Refreshing state... (ID: 2d4628fc07c491d97e34b07da9ec60db)</code><br><code>cloudflare_page_rule.always_use_https_www: Refreshing state... (ID: 59c25cdd1096177a1019f834178de62f)</code><br><code>cloudflare_record.google-verification: Refreshing state... (ID: 131f35a9f8d2304a786a780db38b37e0)</code><br><code>cloudflare_record.www: Refreshing state... (ID: 76e3906f5ea172b627bed4922ebc1da7)</code><br><br><code>Apply complete! Resources: 0 added, 0 changed, 0 destroyed.</code></pre>
<p> </p>
<pre>$ <code>host www.k8s.it</code><br><code>www.k8s.it has address 104.27.164.146</code><br><code>www.k8s.it has address 104.27.165.146</code><br><code>www.k8s.it has IPv6 address 2400:cb00:2048:1::681b:a492</code><br><code>www.k8s.it has IPv6 address 2400:cb00:2048:1::681b:a592</code></pre>
<pre>$ <code>echo | openssl s_client -servername www.k8s.it -connect www.k8s.it:443</code><br><code>CONNECTED(00000003)</code><br><code>depth=2 C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA Limited, CN = COMODO ECC Certification Authority</code><br><code>---</code><br><code>Certificate chain</code><br><code> 0 s:/OU=Domain Control Validated/OU=PositiveSSL Multi-Domain/CN=sni154797.cloudflaressl.com</code><br><code> i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Domain Validation Secure Server CA 2</code><br><code> 1 s:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Domain Validation Secure Server CA 2</code><br><code> i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Certification Authority</code><br><code> 2 s:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Certification Authority</code><br><code> i:/C=SE/O=AddTrust AB/OU=AddTrust External TTP Network/CN=AddTrust External CA Root</code></pre>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Kubernetes for mere mortals</title>
        <author>
            <name>lgirardi</name>
        </author>
        <link href="https://www.k8s.it/kubernetes-for-mere-mortals.html"/>
        <id>https://www.k8s.it/kubernetes-for-mere-mortals.html</id>
            <category term="traefik"/>
            <category term="orangepi"/>
            <category term="lab"/>
            <category term="kubernetes"/>
            <category term="k8s"/>
            <category term="armbian"/>
            <category term="arm"/>

        <updated>2020-09-15T22:31:44+02:00</updated>
            <summary>
                <![CDATA[
                    Well, what do you need to build your homemade cluster? armbian 4.10.1 kubeadm and kubelet 1.6.4 traefik as a ingress controller heapster, collectd, influxdb and grafana as a monitoring stack NAMESPACE NAME READY STATUS RESTARTS AGEhome-prd k8s-helloworld-3468567185-2fwhb 1/1 Running 0 10dhome-prd k8s-helloworld-3468567185-lbgpk 1/1 Running 2&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>Well, what do you need to build your homemade cluster?</p>
<p><img loading="lazy" src="https://www.k8s.it/media/posts/3/k8s.arm-lg.jpeg" sizes="(max-width: 48em) 100vw, 768px" srcset="https://www.k8s.it/media/posts/3/responsive/k8s.arm-lg-xs.jpeg 300w ,https://www.k8s.it/media/posts/3/responsive/k8s.arm-lg-sm.jpeg 480w ,https://www.k8s.it/media/posts/3/responsive/k8s.arm-lg-md.jpeg 768w ,https://www.k8s.it/media/posts/3/responsive/k8s.arm-lg-lg.jpeg 1024w ,https://www.k8s.it/media/posts/3/responsive/k8s.arm-lg-xl.jpeg 1360w ,https://www.k8s.it/media/posts/3/responsive/k8s.arm-lg-2xl.jpeg 1600w"  alt="" width="744" height="400"></p>
<p><img loading="lazy" src="https://www.k8s.it/media/posts/3/IMG_20170605_150237.jpg" sizes="(max-width: 48em) 100vw, 768px" srcset="https://www.k8s.it/media/posts/3/responsive/IMG_20170605_150237-xs.jpg 300w ,https://www.k8s.it/media/posts/3/responsive/IMG_20170605_150237-sm.jpg 480w ,https://www.k8s.it/media/posts/3/responsive/IMG_20170605_150237-md.jpg 768w ,https://www.k8s.it/media/posts/3/responsive/IMG_20170605_150237-lg.jpg 1024w ,https://www.k8s.it/media/posts/3/responsive/IMG_20170605_150237-xl.jpg 1360w ,https://www.k8s.it/media/posts/3/responsive/IMG_20170605_150237-2xl.jpg 1600w"  alt="" width="832" height="624"></p>
<ul>
<li>1x usb hub Anker 60W PowerPort 6</li>
<li>4x orangepi plus 2e</li>
</ul>
<p> armbian 4.10.1 </p>
<p>kubeadm and kubelet 1.6.4</p>
<p>traefik as a ingress controller</p>
<p>heapster, collectd, influxdb and grafana as a monitoring stack</p>
<div class="slate-resizable-image-embed slate-image-embed__resize-full-width"><img loading="lazy" src="https://media.licdn.com/dms/image/C5612AQFJsWW1J0HYig/article-inline_image-shrink_1500_2232/0?e=2122596000&amp;v=beta&amp;t=O4agFAs9-5g0xGt6frAU-koLZROOeVmv2p7yhmZyEAY" data-is-external-image="true"  data-media-urn="urn:li:digitalmediaAsset:C5612AQFJsWW1J0HYig" data-li-src="https://media.licdn.com/dms/image/C5612AQFJsWW1J0HYig/article-inline_image-shrink_1500_2232/0?e=2122596000&amp;v=beta&amp;t=O4agFAs9-5g0xGt6frAU-koLZROOeVmv2p7yhmZyEAY"></div>
<p> </p>
<div class="slate-resizable-image-embed slate-image-embed__resize-full-width"><img loading="lazy" src="https://media.licdn.com/dms/image/C4E12AQFGmg6f2D2CcQ/article-inline_image-shrink_1000_1488/0?e=2122596000&amp;v=beta&amp;t=H2Sp0_RJzeKQLmbD7JiF6jW-bqdvqkgRzPTmXqhogpI" data-is-external-image="true"  data-media-urn="urn:li:digitalmediaAsset:C4E12AQFGmg6f2D2CcQ" data-li-src="https://media.licdn.com/dms/image/C4E12AQFGmg6f2D2CcQ/article-inline_image-shrink_1000_1488/0?e=2122596000&amp;v=beta&amp;t=H2Sp0_RJzeKQLmbD7JiF6jW-bqdvqkgRzPTmXqhogpI"></div>
<pre spellcheck="false">NAMESPACE     NAME                                        READY     STATUS    RESTARTS   AGE
home-prd      k8s-helloworld<span class="hljs-number">-3468567185-2f</span>whb             <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">0</span>          <span class="hljs-number">10d</span>
home-prd      k8s-helloworld<span class="hljs-number">-3468567185</span>-lbgpk             <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">2</span>          <span class="hljs-number">73d</span>
home-prd      k8s-helloworld<span class="hljs-number">-3468567185</span>-vz9n5             <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">2</span>          <span class="hljs-number">73d</span>
kube-system   etcd-k8s-node001                            <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">19</span>         <span class="hljs-number">81d</span>
kube-system   heapster<span class="hljs-number">-3703175019-7f</span>z27                   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">2</span>          <span class="hljs-number">76d</span>
kube-system   kube-apiserver-k8s-node001                  <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">8</span>          <span class="hljs-number">81d</span>
kube-system   kube-controller-manager-k8s-node001         <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">22</span>         <span class="hljs-number">81d</span>
kube-system   kube-dns<span class="hljs-number">-279829092</span>-r8595                    <span class="hljs-number">3</span>/<span class="hljs-number">3</span>       Running   <span class="hljs-number">39</span>         <span class="hljs-number">81d</span>
kube-system   kube-flannel-ds<span class="hljs-number">-08</span>z1k                       <span class="hljs-number">2</span>/<span class="hljs-number">2</span>       Running   <span class="hljs-number">44</span>         <span class="hljs-number">81d</span>
kube-system   kube-flannel-ds<span class="hljs-number">-3</span>bqmf                       <span class="hljs-number">2</span>/<span class="hljs-number">2</span>       Running   <span class="hljs-number">0</span>          <span class="hljs-number">10d</span>
kube-system   kube-flannel-ds-f51rq                       <span class="hljs-number">2</span>/<span class="hljs-number">2</span>       Running   <span class="hljs-number">10</span>         <span class="hljs-number">81d</span>
kube-system   kube-flannel-ds-l5wjs                       <span class="hljs-number">2</span>/<span class="hljs-number">2</span>       Running   <span class="hljs-number">8</span>          <span class="hljs-number">81d</span>
kube-system   kube-proxy<span class="hljs-number">-3</span>gn3x                            <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">12</span>         <span class="hljs-number">81d</span>
kube-system   kube-proxy<span class="hljs-number">-88762</span>                            <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">2</span>          <span class="hljs-number">81d</span>
kube-system   kube-proxy-dghmh                            <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">0</span>          <span class="hljs-number">10d</span>
kube-system   kube-proxy-dtf9c                            <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">3</span>          <span class="hljs-number">81d</span>
kube-system   kube-scheduler-k8s-node001                  <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">29</span>         <span class="hljs-number">81d</span>
kube-system   kubernetes-dashboard<span class="hljs-number">-1707270776</span>-jgxbp       <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">2</span>          <span class="hljs-number">81d</span>
kube-system   traefik-ingress-controller<span class="hljs-number">-49053153</span>-kgb3p   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>       Running   <span class="hljs-number">1</span>          <span class="hljs-number">30d</span>
</pre>
<p> </p>
<p>backend docker example (nginx on arm) k8s-helloworld-arm</p>
<p><a href="https://services.k8s.it/hello/" target="_blank" rel="nofollow noopener noreferrer">live demo</a></p>
<p><a href="https://services.k8s.it/grafana/dashboard/db/all-k8s-nodes?refresh=1m&amp;orgId=2&amp;from=now-24h&amp;to=now" target="_blank" rel="nofollow noopener noreferrer">monitoring</a></p>
            ]]>
        </content>
    </entry>
</feed>
