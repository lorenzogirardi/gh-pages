{
    "version": "https://jsonfeed.org/version/1",
    "title": "LAB",
    "description": "",
    "home_page_url": "https://www.k8s.it",
    "feed_url": "https://www.k8s.it/feed.json",
    "user_comment": "",
    "author": {
        "name": "lgirardi"
    },
    "items": [
        {
            "id": "https://www.k8s.it/kubernetes-destroyed-the-virtualization-or-not.html",
            "url": "https://www.k8s.it/kubernetes-destroyed-the-virtualization-or-not.html",
            "title": "Kubernetes has destroyed the virtualization... or NOT",
            "summary": "Well ... NO! Ok maybe are missing some context I started this topic looking around the data center world compared with the cloud providers, the advantage of manage services , the mindset infrastructure as a code and so on ... In the last 4y we saw&hellip;",
            "content_html": "<p>Well ... <strong>NO!</strong></p>\n<p>Ok maybe are missing some context</p>\n<p> </p>\n<p>I started this topic looking around the data center world compared with the cloud providers,<br>the advantage of manage services , the mindset infrastructure as a code and so on ...</p>\n<p>In the last 4y we saw a kubernetes rush , a lot of company are sharing the advantages and the perfect picture create into kubernetes, how they save money or scale fast ... but is always true what we see?<br>Most of the times we are saw only builded success case.</p>\n<p>Today we will take in consideration those topics :</p>\n<ul>\n<li>Virtual machines</li>\n<li>Data center</li>\n<li>Kubernetes</li>\n</ul>\n<p>I know that the Data center topic should be covered more in deep, maybe talking about the entire ecosystem (db, vertical services , corporate usage , LEGACY!!!!) however today i'd like to explore only the kubernetes and virtualization rather than lose the discussion in thousand of concepts.</p>\n<h3>Long story short</h3>\n<p>A long time ago Borg was born in Google .. now formally named kubernetes,<br>in the first period the main evaluation was:<br>\"<em>why the virtualization overhead if we will use kubernetes</em>\".<br><br>This concept was justified in some way for <em>overlapping</em> of duties,<br>if i migrate a vm as a kubernetes pod this means i can remove the vm <br><br></p>\n<figure class=\"post__image\">                      <img loading=\"lazy\"  src=\"https://res.cloudinary.com/ethzero/image/upload/v1607974463/misc/vm_vs_pod.png\" data-is-external-image=\"true\"  alt=\"\" width=\"337\" height=\"181\"></figure>\n<p> </p>\n<p> </p>\n<p>We can imagine a picture like this looking back of some years ago</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://res.cloudinary.com/ethzero/image/upload/v1607963386/misc/vm_1.png\" data-is-external-image=\"true\"  alt=\"\" width=\"745\" height=\"386\"></figure>\n<figure class=\"post__image\">The introduction was good , almost all declared this could be a new way.<br>Moving faster, all companies changed a bit this picture with an expansion of kubernetes </figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://res.cloudinary.com/ethzero/image/upload/v1607963386/misc/vm_2.png\" data-is-external-image=\"true\"  alt=\"\" width=\"745\" height=\"386\"></figure><figure class=\"is-loaded\"><img loading=\"lazy\"  src=\"Kubernetes destroyed the virtualization... or NOT - LAB_files/vm_2.png\" data-is-external-image=\"true\"  alt=\"\" width=\"745\" height=\"386\" data-is-external-image=\"true\"></figure>\n<p>Like an infection (good this time, not the 20covid ones) kubernetes come as a main platform for most of the online company...<br>In a datacenter , you know, there no something eternal:</p>\n<ul>\n<li>hardware in EOL</li>\n<li>generation refresh</li>\n<li>brand change</li>\n<li>good is ok but cheaper is better (usually from finance)</li>\n</ul>\n<p>Is also true , that sometimes this encouraged a forced/incorrect usage of kubernetes node labeling in order to bend the infrastructure to better fit the products migrated or the existing hardware availability</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://res.cloudinary.com/ethzero/image/upload/v1607959262/misc/vm_3.png\" data-is-external-image=\"true\"  alt=\"\" width=\"748\" height=\"389\"></figure>\n<figure class=\"post__image\"><figure class=\"is-loaded\"><img loading=\"lazy\"  src=\"Kubernetes destroyed the virtualization... or NOT - LAB_files/vm_3.png\" data-is-external-image=\"true\"  alt=\"\" data-is-external-image=\"true\"></figure></figure>\n<h3>Houston we have a problem...</h3>\n<p>Working in this way, the environment could be fragmented ,<br>even if the technology is the same there are some logical segmentations that create some problems in the day by day activities.</p>\n<ul>\n<li>isolate some workloads with labels can create an hw lock-in (better approach a multi-cluster with unique controlplane)</li>\n<li>updates require to be managed in a different way looking for the label/role</li>\n<li>please do not touch the storage nodes now (fiber channel with external storage)</li>\n<li>please do not touch the storage nodes tomorrow (fiber channel with external storage)</li>\n<li>omg we lost a storage nodes (fiber channel with external storage)</li>\n<li>and so on ...</li>\n</ul>\n<p>Moreover an hardware fault could create problems .... <br>YES i know in a infrastructure as a code , with puppet foreman chef salt ansible terraform etc, this will be recovered fast ... but this is not always true ... you know... some machines/roles in a mid/ent company are still fragile.</p>\n<ul>\n<li>legacy with no ownership</li>\n<li>legacy with wrong ownership</li>\n<li>single point of failure ... (yes also in 2020)</li>\n</ul>\n<p> </p>\n<p>Other problems are related with new hardware...</p>\n<ul>\n<li>is the provisioning working as expected with new generations ?</li>\n<li>and if we change the hardware vendor ?</li>\n<li>etc etc when you have to handle new preseed/ks because the layout is changed ☠️</li>\n</ul>\n<p> </p>\n<p>Last but not least ... what about the bare metal density ?</p>\n<p><code>Allocated resources:</code><br><code> (<span class=\"il\">Total</span> <span class=\"il\">limits</span> <span class=\"il\">may</span> be <span class=\"il\">over</span> <span class=\"il\">100</span> <span class=\"il\">percent</span>, i.e., <span class=\"il\">overcommitted</span>.</code><br><code> CPU Requests CPU <span class=\"il\">Limits</span> Memory Requests Memory <span class=\"il\">Limits</span></code><br><code> ------------ ---------- --------------- -------------</code><br><code> 55 (98%) 101300m (180%) 86376Mi (44%) 121672Mi (62%)</code></p>\n<p>This HW has 56 core with HT , we reached the 98% but this number is high <br>because some pods needs a default cpu just to fit the nodes and start, while the running cost is really low. </p>\n<p> </p>\n<h3>So why not kubernetes hosted in virtual machines ?</h3>\n<ul>\n<li>Having an abstraction layer, is quite simple tune the provisioning based on this , rather than the bare metal, it's just a metter of roles not to the entire provisioning.</li>\n<li>Hardware fault could be easily covered by live migration</li>\n<li>Maintenance and update can be manage creating a blue green approach and rolling updates</li>\n<li>Density could be increased with mode nodes in the same hw</li>\n<li>Flexibility to scale up and to upset a new datacenter in case of migration will be higher</li>\n<li>Team at the and is also able to scale , working from the vmware and not from bare metal</li>\n</ul>\n<figure class=\"post__image\"><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://res.cloudinary.com/ethzero/image/upload/v1607961166/misc/team_scale.png\" data-is-external-image=\"true\"  alt=\"\" width=\"718\" height=\"353\"></figure></figure>\n<h3> </h3>\n<h3>Conclusions</h3>\n<p>Virtualization and kubernetes are not antagonist, must be in addition , the first one has just change the scope to better cooperate with kubernetes</p>\n<p>Instead a layer for microservices , virtualization is now the layer that guarantee an homogeneous platform were a team can work on top to create the infrastructure having the advantage of a fully consolidated technology that is able to promote the right abstraction </p>\n<p>Last but not least , we don't need to reinvent something , we can just copy from the major competitors for the kubernetes topic<br>How is working GKE , AKS , EKS ? .... virtual machines :)</p>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
            ],
            "date_published": "2020-12-07T14:40:52+01:00",
            "date_modified": "2020-12-14T21:20:08+01:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-apigw.html",
            "url": "https://www.k8s.it/kubernetes-apigw.html",
            "title": "Kubernetes api gateway",
            "summary": "It's time to talk about the api gateway In a modern infrastructure , especially in a microservices environment you probably know what i'm referring to ,however it's better to clarify some points. An API gateway takes all API calls from clients, then routes them to&hellip;",
            "content_html": "<p>It's time to talk about the api gateway</p>\n<p>In a modern infrastructure , especially in a microservices environment you probably know what i'm referring to ,however it's better to clarify some points.</p>\n<p><em>An API gateway takes all API calls from clients, then routes them to the appropriate microservice with request routing, composition, and protocol translation. Typically it handles a request by invoking multiple microservices and aggregating the results, to determine the best path. It can translate between web protocols and web‑unfriendly protocols that are used internally.</em></p>\n<p><em>An e‑commerce site might use an API gateway to provide mobile clients with an endpoint for retrieving all product details with a single request. It invokes various services, like product info and reviews, and combines the results</em></p>\n<p><br><br></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/70d257f92412994f23cfce0b702ca359556a2b64b7835f8f3ef9b58a493a4d60/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630343833393633312f6d6973632f61706967772e706e67\"><img loading=\"lazy\" title=\"apigw\" src=\"https://camo.githubusercontent.com/70d257f92412994f23cfce0b702ca359556a2b64b7835f8f3ef9b58a493a4d60/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630343833393633312f6d6973632f61706967772e706e67\" data-is-external-image=\"true\"  alt=\"apigw\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1604839631/misc/apigw.png\"></a></p>\n<p><br><br></p>\n<p>Some months ago i discussed about the service mesh<br><a href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh\">https://github.com/lorenzogirardi/kubernetes-servicemesh</a></p>\n<p>To better understand the differences on those products it is better to summarize the common areas</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/43086b5aea0afa64170f3dac4261da1ad4a2ae2645d428fee16b7ce2eb6484f1/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343730333838302f6d6973632f61706967775f76735f736572766963656d6573682e706e67\"><img loading=\"lazy\" title=\"apigw_vs_servicemesh\" src=\"https://camo.githubusercontent.com/43086b5aea0afa64170f3dac4261da1ad4a2ae2645d428fee16b7ce2eb6484f1/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343730333838302f6d6973632f61706967775f76735f736572766963656d6573682e706e67\" data-is-external-image=\"true\"  alt=\"apigw_vs_servicemesh\" width=\"491\" height=\"328\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1024/v1604703880/misc/apigw_vs_servicemesh.png\"></a></p>\n<p>So forget about service mesh and have the focus only on the apigw.</p>\n<p><br><br></p>\n<h2><a id=\"user-content-goal\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/Kubernetes-apigw#goal\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>GOAL</h2>\n<p>Needed:</p>\n<ul>\n<li>Api must be public</li>\n<li>Users needs to have authentication</li>\n<li>An user could be rate limited</li>\n<li>A service could be rate limited</li>\n<li>Backend applications should not be changed</li>\n<li>We need to interact as a code with the apigw<br><br><br></li>\n</ul>\n<p>Important:</p>\n<ul>\n<li>Analytics</li>\n<li>Transformation</li>\n<li>Versioning</li>\n<li>Circuit Breaker</li>\n<li>gRPC support</li>\n<li>Caching</li>\n<li>Documentation</li>\n</ul>\n<p><br><br></p>\n<h2><a id=\"user-content-software-opportunity\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/Kubernetes-apigw#software-opportunity\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Software opportunity</h2>\n<p>Around the api gateway world we have some possibility, some of those are onprem, some other in cloud or hybrid.</p>\n<p>The onprem scenario we have some historycal software and a \"new generation\" born in a kubernetes architecture, howevere here we will check for a tool that could work in kubernetes (with a plus for supporting vm)</p>\n<p>From the most knew i'd like to mention:</p>\n<ul>\n<li>Kong</li>\n<li>Tyk</li>\n<li>Nginx</li>\n<li>Ambassador</li>\n<li>3scale</li>\n</ul>\n<p>On the other side on the cloud scenario we have:</p>\n<ul>\n<li>Aws api gateway</li>\n<li>Mashery (from Tibco)</li>\n<li>Google apigee</li>\n<li>Akana (hybrid)</li>\n<li>Azure api management</li>\n</ul>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\">\n<tbody>\n<tr>\n<th style=\"width: 16.932%;\"> </th>\n<th style=\"width: 15.3401%;\">nginx</th>\n<th style=\"width: 16.2084%;\">kong</th>\n<th style=\"width: 13.1693%;\">tyk</th>\n<th style=\"width: 15.3401%;\">ambassador</th>\n<th style=\"width: 36.4688%;\">aws api gw</th>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">basic</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">oauth</td>\n<td style=\"width: 15.3401%;\">pay</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">pay</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">jwt</td>\n<td style=\"width: 15.3401%;\">pay</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">pay</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">ip listing</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">no</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">analytics</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">rate limiting</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">transformation</td>\n<td style=\"width: 15.3401%;\">pay</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">grpc</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 36.4688%;\">no</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">websocket</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">service mesh</td>\n<td style=\"width: 15.3401%;\">no</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">pay</td>\n<td style=\"width: 36.4688%;\">no</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">k8s ingress</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 36.4688%;\">no</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">caching</td>\n<td style=\"width: 15.3401%;\">yes</td>\n<td style=\"width: 16.2084%;\">pay</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">no</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">documentation</td>\n<td style=\"width: 15.3401%;\">pay</td>\n<td style=\"width: 16.2084%;\">yes</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">no</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">admin ui</td>\n<td style=\"width: 15.3401%;\">pay</td>\n<td style=\"width: 16.2084%;\">trd party</td>\n<td style=\"width: 13.1693%;\">yes</td>\n<td style=\"width: 15.3401%;\">no</td>\n<td style=\"width: 36.4688%;\">pay</td>\n</tr>\n<tr>\n<td style=\"width: 16.932%;\">ease to setup</td>\n<td style=\"width: 15.3401%;\">3.5</td>\n<td style=\"width: 16.2084%;\">4</td>\n<td style=\"width: 13.1693%;\">2.5</td>\n<td style=\"width: 15.3401%;\">3</td>\n<td style=\"width: 36.4688%;\">5</td>\n</tr>\n</tbody>\n</table>\n<p> </p>\n<p>Cloud</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/6f7e05d1971da2d537452717a8571e3fc13ac8a7471428550e0cf065ca2997e1/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630343736363830322f6d6973632f61706967775f636c6f75642e706e67\"><img loading=\"lazy\" title=\"apigw_cloud\" src=\"https://camo.githubusercontent.com/6f7e05d1971da2d537452717a8571e3fc13ac8a7471428550e0cf065ca2997e1/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630343736363830322f6d6973632f61706967775f636c6f75642e706e67\" data-is-external-image=\"true\"  alt=\"apigw_cloud\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1604766802/misc/apigw_cloud.png\"></a></p>\n<p>The advantage/disadvantage of cloud solution is the pay per use, you don't need to manage the infrastrcture but only the configuration and you have the support that can drive you on the right configuration.<br>Another valid point of view is the <em>DDOS</em> attack that will not land to your platform but to a cloud infrastructure that is supposed was designed to manage this scenario.</p>\n<p>PRO:</p>\n<ul>\n<li>managed infrastructure</li>\n<li>support</li>\n<li>attacks mitigation</li>\n</ul>\n<p>CONS:</p>\n<ul>\n<li>pricing</li>\n<li>often not customizable<br><br></li>\n</ul>\n<p>Onprem</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/f650f08e78f1fa640565179fa79ccedcb5928fc85554118e8b2cbb720bbea6e6/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630343736363830322f6d6973632f61706967775f64632e706e67\"><img loading=\"lazy\" title=\"apigw_dc\" src=\"https://camo.githubusercontent.com/f650f08e78f1fa640565179fa79ccedcb5928fc85554118e8b2cbb720bbea6e6/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630343736363830322f6d6973632f61706967775f64632e706e67\" data-is-external-image=\"true\"  alt=\"apigw_dc\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1604766802/misc/apigw_dc.png\"></a></p>\n<p>Those solutions should be hosted on your platform or in a cloud to let the datacenter <em>unknown</em> (anyway you have to pay per traffic \"*\" ).<br>Your engineer team need to know how it's working the infrastructure but they can also improve the process with automations</p>\n<p>PRO:</p>\n<ul>\n<li>open source</li>\n<li>customizable</li>\n<li>awareness on the complete funnel</li>\n</ul>\n<p>CONS:</p>\n<ul>\n<li>you have to take care about attacks</li>\n<li>infrastructure knowhow</li>\n</ul>\n<p><br><br>\"*\" you can easly have the apigw hosted onprem combined with a cdn/waf with ip lockdown , however you still have to pay the traffic towards it.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/e66b9fb512155cc277683660dd1ab517d7e9b9e50f023d3fc53f2b7e06a9f5e7/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630343736363830322f6d6973632f61706967775f7761662e706e67\"><img loading=\"lazy\" title=\"apigw_waf\" src=\"https://camo.githubusercontent.com/e66b9fb512155cc277683660dd1ab517d7e9b9e50f023d3fc53f2b7e06a9f5e7/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630343736363830322f6d6973632f61706967775f7761662e706e67\" data-is-external-image=\"true\"  alt=\"apigw_waf\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1604766802/misc/apigw_waf.png\"></a></p>\n<p><br><br></p>\n<h2><a id=\"user-content-scenario\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/Kubernetes-apigw#scenario\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Scenario</h2>\n<p>I tried some cloud solution like Aws and Mashery,<br>i played also with some onprem solution, anyway i found out the right compromise with <a href=\"https://konghq.com/kong/\" rel=\"nofollow\">Kong</a></p>\n<p>where compromise is :</p>\n<ul>\n<li><strong>Kubernetes ingress</strong></li>\n<li><strong>Api managed</strong></li>\n<li><strong>Documentation</strong></li>\n<li>Admin UI (konga for the open source)</li>\n<li>Basic auth</li>\n<li><strong>Apikey</strong></li>\n<li><strong>Oauth</strong></li>\n<li><strong>JWT</strong></li>\n<li>ip listing</li>\n<li><strong>Analytics</strong></li>\n<li><strong>Rate limiting</strong></li>\n<li><strong>Transformation</strong></li>\n<li>gRPC</li>\n<li>Websockets</li>\n<li>Service mesh (~ nice to have)</li>\n<li><strong>Easy to use</strong></li>\n</ul>\n<p><br><br></p>\n<h2><a id=\"user-content-infrastructure\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/Kubernetes-apigw#infrastructure\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Infrastructure</h2>\n<ul>\n<li>kubernetes</li>\n<li>backend application</li>\n<li>kong api gateway</li>\n<li>konga admin ui</li>\n<li>waf (free cloudflare service)</li>\n</ul>\n<p><br><br></p>\n<p>What we need for this test is a backend api application, i created a prototype just to simulate different applications behind the apigw.</p>\n<p>Here you can find out more details</p>\n<p><a href=\"https://github.com/lorenzogirardi/py-test-backend\">https://github.com/lorenzogirardi/py-test-backend</a></p>\n<p>briefly recap the application answer on /api/ with the main html page with methods</p>\n<table>\n<thead>\n<tr>\n<th>HTTP Method</th>\n<th align=\"center\">URI</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>GET</td>\n<td align=\"center\">http://[hostname]/api/get/context</td>\n<td>Retrieve list of context</td>\n</tr>\n<tr>\n<td>GET</td>\n<td align=\"center\">http://[hostname]/api/get/context/[context_id]</td>\n<td>Retrieve a context</td>\n</tr>\n<tr>\n<td>POST</td>\n<td align=\"center\">http://[hostname]/api/post/context</td>\n<td>Create a new context</td>\n</tr>\n<tr>\n<td>PUT</td>\n<td align=\"center\">http://[hostname]/api/put/context/[context_id]</td>\n<td>Update an existing context</td>\n</tr>\n<tr>\n<td>DELETE</td>\n<td align=\"center\">http://[hostname]/api/delete/context/[context_id]</td>\n<td>Delete acontext</td>\n</tr>\n</tbody>\n</table>\n<p><br><br></p>\n<h2><a id=\"user-content-configuration\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/Kubernetes-apigw#configuration\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Configuration</h2>\n<div>\n<div>git repo --&gt; <a href=\"https://github.com/lorenzogirardi/Kubernetes-apigw\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/lorenzogirardi/Kubernetes-apigw</a></div>\n</div>\n<p>Let's start to work...<br>I've used the public kong deployment with some changes to have the database where store the configurations.</p>\n<p>Another trick is create it as a secondary <em>ingress</em> , since i've already and ingress in my infrastructure , kong is done to answer on different ports</p>\n<p>All the yaml are subdivided per role</p>\n<pre><code>kong\n|-- 01-kong-ns.yaml\n|-- 02-kong-cr.yaml\n|-- 03-kong-sa.yaml\n|-- 04-kong-rbac.yaml\n|-- 05-kong-crb.yaml\n|-- 06-kong-svc.yaml\n|-- 07-kong-dpl.yaml\n|-- 08-kong-ss.yaml\n`-- 09-kong-job.yaml\n</code></pre>\n<p>some differences are related to the services node ports, deployment binding host and the database is now hosted with a volumeClaimTemplates</p>\n<pre><code>  ports:\n  - name: proxy\n    nodePort: 30080\n    port: 80\n    protocol: TCP\n    targetPort: 8000\n  - name: proxy-ssl\n    nodePort: 30443\n    port: 443\n    protocol: TCP\n    targetPort: 8443\n  - name: admin\n    port: 8100\n    protocol: TCP\n    targetPort: 8100\n  - name: admin-ssl\n    port: 8444\n    protocol: TCP\n    targetPort: 8444\n  selector:\n    app: ingress-kong\n  type: LoadBalancer\n</code></pre>\n<pre><code>      containers:\n      - env:\n        - name: KONG_DATABASE\n          value: postgres\n        - name: KONG_PG_HOST\n          value: postgres\n        - name: KONG_PG_PASSWORD\n          value: kong\n        - name: KONG_PROXY_LISTEN\n          value: 0.0.0.0:8000, 0.0.0.0:8443 ssl http2\n        - name: KONG_PORT_MAPS\n          value: 80:8000, 443:8443\n        - name: KONG_ADMIN_LISTEN\n          value: 0.0.0.0:8444 ssl\n        - name: KONG_STATUS_LISTEN\n          value: 0.0.0.0:8100\n</code></pre>\n<pre><code>  volumeClaimTemplates:\n  - metadata:\n      name: datadir\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 250Mi\n</code></pre>\n<p>Here what is expected to see</p>\n<pre><code>$ kubectl get svc -n kong\nNAME                      TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                    AGE\nkong-proxy                LoadBalancer   10.152.183.55    &lt;pending&gt;     80:30080/TCP,443:30443/TCP,8100:32588/TCP,8444:31793/TCP   7d\nkong-validation-webhook   ClusterIP      10.152.183.190   &lt;none&gt;        443/TCP                                                    7d\npostgres                  ClusterIP      10.152.183.177   &lt;none&gt;        5432/TCP\n</code></pre>\n<p>and the pods needed to have it online</p>\n<pre><code>kong           ingress-kong-686b4bc5df-nm7zk              2/2     Running     4          7d\nkong           kong-migrations-ftgdv                      0/1     Completed   0          7d\nkong           postgres-0                                 1/1     Running     2          7d\nkube-system    hostpath-provisioner-5c65fbdb4f-f5qsb      1/1     Running     6          40d\n</code></pre>\n<pre><code>NAME                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS        AGE\ndatadir-postgres-0   Bound    pvc-8c5791c3-939f-4457-b5fb-74ac417ca3d7   250Mi        RWO                 k8s-hostpath   7d\n</code></pre>\n<p><br><br></p>\n<p>Now i'd like to have also an Admin UI, i'm not fan of web ui ,<br>however i need to know if this interface could be shared outside IT<br>to delegate some business ownership and so on.</p>\n<p>Kong Enterprise has it's own web ui instead the community one needs a third party tool... <a href=\"https://github.com/pantsel/konga\">Konga</a></p>\n<p>In the same way of kong, konga needs a database , and in the same way i elaborated a bit the default deployment</p>\n<pre><code>konga\n|-- 01-ns-konga.yaml\n|-- 02-svc-konga.yaml\n|-- 03-ing-konga.yaml\n`-- 04-dpl-konga.yaml\n</code></pre>\n<p>just a couple of TIPS</p>\n<p>postgres persistent storage</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  namespace: konga\n  name: konga-pv-claim\n  labels:\n    app: konga-storage-claim\nspec:\n  storageClassName: microk8s-hostpath\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 200Mi\n</code></pre>\n<p>and on deployment ...</p>\n<pre><code>        env:\n        - name: NODE_TLS_REJECT_UNAUTHORIZED\n          value: \"0\"\n        - name: NODE_ENV\n          value: \"production\"\n</code></pre>\n<p>where NODE_TLS_REJECT_UNAUTHORIZED is the option to not verify the kong api certificate and</p>\n<p><br>NODE_ENV is way to enable production or development , if you are not using production, the other two option enables the debug model and increase the cpu usage, i suggest to use production anyway <strong>during the first deploy you should enable development in order to bootstrap the sql schema</strong> that production is not able to do ... or create an init container to deploy the schema</p>\n<p><code>konga konga-stable-8957b9d85-tq72z 2/2 Running 2 6d3h</code></p>\n<p>since is now up and running it will be available on the standard infrastructure ingress</p>\n<pre><code>  - host: konga.ing.h4x0r3d.lan\n</code></pre>\n<p>Konga Home </p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/0f76d690a796607e512cffaaf5f1405516e613575ecdf562d91399e1c646b05b/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343737373233372f6d6973632f6b6f6e67615f75692e706e67\"><img loading=\"lazy\" title=\"konga_home\" src=\"https://camo.githubusercontent.com/0f76d690a796607e512cffaaf5f1405516e613575ecdf562d91399e1c646b05b/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343737373233372f6d6973632f6b6f6e67615f75692e706e67\" data-is-external-image=\"true\"  alt=\"konga_home\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1024/v1604777237/misc/konga_ui.png\"></a></p>\n<p>Konga node configuration </p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/cda833f675290b3538fa9b4e4d49f8c91ea586bae71505e705d7646646b30fa8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343737373233382f6d6973632f6b6f6e67615f75695f6b6f6e676e6f64652e706e67\"><img loading=\"lazy\" title=\"konga_node\" src=\"https://camo.githubusercontent.com/cda833f675290b3538fa9b4e4d49f8c91ea586bae71505e705d7646646b30fa8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343737373233382f6d6973632f6b6f6e67615f75695f6b6f6e676e6f64652e706e67\" data-is-external-image=\"true\"  alt=\"konga_node\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1024/v1604777238/misc/konga_ui_kongnode.png\"></a></p>\n<p><br><br></p>\n<ul>\n<li>kong [INSTALLED]</li>\n<li>konga [INSTALLED]</li>\n<li>backend [INSTALLED]</li>\n</ul>\n<p>First of all we need to expose the backend with Kong in this example i created an ingress configuration dedicated for this porpose</p>\n<pre><code>apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: \"kong\"\n  name: api\n  namespace: pytbak\n  labels:\n    app: api\nspec:\n  rules:\n    - host: api.ing.h4x0r3d.lan\n      http:\n        paths:\n          - path: /api/\n            backend:\n              serviceName: pytbak-svc\n              servicePort: 5000\n          - path: /api/get/\n            backend:\n              serviceName: pytbak-svc\n              servicePort: 5000\n          - path: /api/post/\n            backend:\n              serviceName: pytbak-svc\n              servicePort: 5000\n          - path: /api/put/\n            backend:\n              serviceName: pytbak-svc\n              servicePort: 5000\n          - path: /api/delete/\n            backend:\n              serviceName: pytbak-svc\n              servicePort: 5000\n</code></pre>\n<p><code>kubernetes.io/ingress.class: \"kong\" </code>to match the kong ingress on the backend application <code>namespace: pytbak</code>.<br>As you can see i created mutiple paths to simulate different applications behind and create different ruls per path/application/context.</p>\n<p>The kong configuration could be applied with</p>\n<ul>\n<li>kubernetes yaml</li>\n<li>kong api</li>\n<li>konga ui (only if you have the database)</li>\n</ul>\n<p>In the repo you will see some in kubernetes and some other not present , i tested the three option and the <strong>kong api</strong> is the best one</p>\n<p><br><br>Create api user</p>\n<p><code>curl -k -i -X POST --url https://192.168.1.14:31793/consumers/ --data \"username=slow_user\"</code></p>\n<pre><code>HTTP/1.1 201 Created\nDate: Sat, 07 Nov 2020 19:46:05 GMT\nContent-Type: application/json; charset=utf-8\nConnection: keep-alive\nAccess-Control-Allow-Origin: *\nServer: kong/2.1.4\nContent-Length: 121\nX-Kong-Admin-Latency: 16\n</code></pre>\n<p><code>{\"custom_id\":null,\"created_at\":1604778365,\"id\":\"3d45a73d-4024-4813-b356-43a14ecea702\",\"tags\":null,\"username\":\"slow_user\"}</code> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/34bd577bcb080782018378247fac228663f6c4508bfc1191f173a07d9f731e28/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343737383930332f6d6973632f6b6f6e67615f636f6e73756d65722e706e67\"><img loading=\"lazy\" title=\"konga_consumer\" src=\"https://camo.githubusercontent.com/34bd577bcb080782018378247fac228663f6c4508bfc1191f173a07d9f731e28/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343737383930332f6d6973632f6b6f6e67615f636f6e73756d65722e706e67\" data-is-external-image=\"true\"  alt=\"konga_consumer\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1024/v1604778903/misc/konga_consumer.png\"></a></p>\n<p><br><br>add a key token with key-auth plugin</p>\n<p><code>curl -k -i -X POST --url https://192.168.1.14:31793/consumers/slow_user/key-auth/ --data 'key=332d05445a560ee65a76aeaa372d8904'</code></p>\n<pre><code>HTTP/1.1 201 Created\nDate: Sat, 07 Nov 2020 19:51:03 GMT\nContent-Type: application/json; charset=utf-8\nConnection: keep-alive\nAccess-Control-Allow-Origin: *\nServer: kong/2.1.4\nContent-Length: 190\nX-Kong-Admin-Latency: 10\n</code></pre>\n<p><code>{\"created_at\":1604778663,\"id\":\"52970ca8-848d-49b5-a16f-a235fe0e9ceb\",\"tags\":null,\"ttl\":null,\"key\":\"332d05445a560ee65a76aeaa372d8904\",\"consumer\":{\"id\":\"3d45a73d-4024-4813-b356-43a14ecea702\"}}</code> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/2a45dbea6ede1ac159c1950a65f518aa347650b73efa3539a0edc11f8dbee793/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343737383930332f6d6973632f6b6f6e67615f636f6e73756d65725f63726564656e7469616c2e706e67\"><img loading=\"lazy\" title=\"konga_consumer_cred\" src=\"https://camo.githubusercontent.com/2a45dbea6ede1ac159c1950a65f518aa347650b73efa3539a0edc11f8dbee793/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343737383930332f6d6973632f6b6f6e67615f636f6e73756d65725f63726564656e7469616c2e706e67\" data-is-external-image=\"true\"  alt=\"konga_consumer_cred\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1024/v1604778903/misc/konga_consumer_credential.png\"></a></p>\n<p><br><br></p>\n<p>routes.id where created when we created the kong ingress configuration for pytbak <code>curl -k -i -X GET <a href=\"https://192.168.1.14:31793/routes/\">https://192.168.1.14:31793/routes/</a></code></p>\n<p> </p>\n<table style=\"border-collapse: collapse; width: 93.4879%; height: 294px;\" border=\"1\">\n<tbody>\n<tr style=\"height: 49px;\">\n<td style=\"width: 19.2341%; height: 49px;\">ROUTE NAME</td>\n<td style=\"width: 19.7563%; height: 49px;\">PATH </td>\n<td style=\"width: 55.5885%; height: 49px;\">ROUTE.ID</td>\n</tr>\n<tr style=\"height: 49px;\">\n<td style=\"width: 19.2341%; height: 49px;\">pytbak.api.00</td>\n<td style=\"width: 19.7563%; height: 49px;\">/api/</td>\n<td style=\"width: 55.5885%; height: 49px;\">0a78b572-cfe0-4228-bdfe-639ef04b5117</td>\n</tr>\n<tr style=\"height: 49px;\">\n<td style=\"width: 19.2341%; height: 49px;\">pytbak.api.01</td>\n<td style=\"width: 19.7563%; height: 49px;\">/api/get/</td>\n<td style=\"width: 55.5885%; height: 49px;\">8d2a24aa-636d-43ee-b0aa-b0fd1d3643fd</td>\n</tr>\n<tr style=\"height: 49px;\">\n<td style=\"width: 19.2341%; height: 49px;\">pytbak.api.02</td>\n<td style=\"width: 19.7563%; height: 49px;\">/api/post/</td>\n<td style=\"width: 55.5885%; height: 49px;\">f75ed3b6-07c3-4293-932b-4f53d0c38f74</td>\n</tr>\n<tr style=\"height: 49px;\">\n<td style=\"width: 19.2341%; height: 49px;\">pytbak.api.03</td>\n<td style=\"width: 19.7563%; height: 49px;\">/api/put  </td>\n<td style=\"width: 55.5885%; height: 49px;\">f4823063-04e4-4da8-9c11-21977a93b1ba</td>\n</tr>\n<tr style=\"height: 49px;\">\n<td style=\"width: 19.2341%; height: 49px;\">pytbak.api.04</td>\n<td style=\"width: 19.7563%; height: 49px;\">/api/delete</td>\n<td style=\"width: 55.5885%; height: 49px;\">e396750c-9158-4a96-8d79-047197669cff</td>\n</tr>\n</tbody>\n</table>\n<p> </p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/c17c8b10cdcbb8526fdb448c903c6dad6090e4e460de537185e6a04be663c3e4/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343737393732302f6d6973632f6b6f6e67615f726f757465732e706e67\"><img loading=\"lazy\" title=\"konga_routes\" src=\"https://camo.githubusercontent.com/c17c8b10cdcbb8526fdb448c903c6dad6090e4e460de537185e6a04be663c3e4/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343737393732302f6d6973632f6b6f6e67615f726f757465732e706e67\" data-is-external-image=\"true\"  alt=\"konga_routes\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1024/v1604779720/misc/konga_routes.png\"></a></p>\n<p><br><br>now i'd like to limit the user slow_user to perform only 4 request per sec on /api/<br>and 2 on /api/get/</p>\n<pre><code>$ curl -k -X POST https://192.168.1.14:31793/plugins/ \\\n&gt;             --data \"name=rate-limiting\"  \\\n&gt;             --data \"config.second=4\" \\\n&gt;             --data \"config.hour=1200\" \\\n&gt;             --data \"config.policy=local\" \\\n&gt;             --data \"consumer.id=3d45a73d-4024-4813-b356-43a14ecea702\" \\\n&gt;             --data \"route.id=0a78b572-cfe0-4228-bdfe-639ef04b5117\"\n</code></pre>\n<p><code>{\"created_at\":1604780031,\"id\":\"cfd3d752-7864-493c-a3b7-3970ab6eca86\",\"tags\":null,\"enabled\":true,\"protocols\":[\"grpc\",\"grpcs\",\"http\",\"https\"],\"name\":\"rate-limiting\",\"consumer\":{\"id\":\"3d45a73d-4024-4813-b356-43a14ecea702\"},\"service\":null,\"route\":{\"id\":\"0a78b572-cfe0-4228-bdfe-639ef04b5117\"},\"config\":{\"hide_client_headers\":false,\"minute\":null,\"policy\":\"local\",</code><code>\"month\":null,\"redis_timeout\":2000,\"limit_by\":\"consumer\",\"redis_password\":null,\"second\":4,\"day\":null,\"redis_database\":0,\"year\":null,\"hour\":1200,\"redis_host\":null,\"redis_port\":6379,\"header_name\":null,\"fault_tolerant\":true}}</code></p>\n<pre><code>curl -k -X POST https://192.168.1.14:31793/plugins/ \\\n                --data \"name=rate-limiting\"  \\\n                --data \"config.second=2\" \\\n                --data \"config.hour=600\" \\\n                --data \"config.policy=local\" \\\n                --data \"consumer.id=3d45a73d-4024-4813-b356-43a14ecea702\" \\\n                --data \"route.id=8d2a24aa-636d-43ee-b0aa-b0fd1d3643fd\" \n</code></pre>\n<p><code>{\"created_at\":1604780101,\"id\":\"33bfc138-776a-4116-a2a9-8c70ab9d7a2a\",\"tags\":null,\"enabled\":true,\"protocols\":[\"grpc\",\"grpcs\",\"http\",\"https\"],\"name\":\"rate-limiting\",\"consumer\":{\"id\":\"3d45a73d-4024-4813-b356-43a14ecea702\"},\"service\":null,\"route\":{\"id\":\"8d2a24aa-636d-43ee-b0aa-b0fd1d3643fd\"},\"config\":{\"hide_client_headers\":false,\"minute\":null,\"policy\":\"local\",\"month\":null,\"redis_timeout\":2000,\"limit_by\":\"consumer\",\"redis_password\":null,\"second\":2,\"day\":null,\"redis_database\":0,\"year\":null,\"hour\":600,\"redis_host\":null,\"redis_port\":6379,\"header_name\":null,\"fault_tolerant\":true}}</code></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/31f166746c62aae6fda1d4e1bdb7a85ec1683afd6bdf2d859baf6150883e302e/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343738303230302f6d6973632f6b6f6e67615f726174655f6c696d69745f726f757465732e706e67\"><img loading=\"lazy\" title=\"konga_rate_routes\" src=\"https://camo.githubusercontent.com/31f166746c62aae6fda1d4e1bdb7a85ec1683afd6bdf2d859baf6150883e302e/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313032342f76313630343738303230302f6d6973632f6b6f6e67615f726174655f6c696d69745f726f757465732e706e67\" data-is-external-image=\"true\"  alt=\"konga_rate_routes\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1024/v1604780200/misc/konga_rate_limit_routes.png\"></a></p>\n<p><br><br></p>\n<h2><a id=\"user-content-use-cases\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/Kubernetes-apigw#use-cases\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Use cases</h2>\n<p>I created 3 users , one on the example above and a new one with a double of requests per second</p>\n<table>\n<thead>\n<tr>\n<th>route</th>\n<th align=\"center\">slow_user rate/s</th>\n<th>fast_user rate/s</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>/api/</td>\n<td align=\"center\">4</td>\n<td>8</td>\n</tr>\n<tr>\n<td>/api/get/</td>\n<td align=\"center\">2</td>\n<td>4</td>\n</tr>\n<tr>\n<td>/api/post/</td>\n<td align=\"center\">1</td>\n<td>2</td>\n</tr>\n<tr>\n<td>/api/put/</td>\n<td align=\"center\">1</td>\n<td>2</td>\n</tr>\n<tr>\n<td>/api/delete/</td>\n<td align=\"center\">1</td>\n<td>2</td>\n</tr>\n</tbody>\n</table>\n<p><br><br>slow_user has apikey: 332d05445a560ee65a76aeaa372d8904<br>fast_user has apikey: 695aa0b18c6dbd1b387ee7c32c72c513<br>admin has a apikey: admin</p>\n<p><br><br>i've also created a global rules on the service with max 9 reqquest per second for all other users with no specific rate limit rule applied (ex admin.)</p>\n<p><code>$ curl -k -X POST https://192.168.1.14:31793/plugins --data \"name=rate-limiting\" --data \"config.second=9\" --data \"config.policy=local\" --data \"service.id=53d35e73-b285-4eb2-ad24-853d82563ca4\"</code></p>\n<pre><code>{\"created_at\":1604786501,\"id\":\"34182311-ecbf-49a3-bdcf-bdc1c9c58706\",<br>\"tags\":null,\"enabled\":true,\"protocols\":[\"grpc\",\"grpcs\",\"http\",\"https\"],<br>\"name\":\"rate-limiting\",\"consumer\":null,<br>\"service\":{\"id\":\"53d35e73-b285-4eb2-ad24-853d82563ca4\"},<br>\"route\":null,\"config\":{\"hide_client_headers\":false,\"minute\":null,\"policy\":\"local\",<br>\"month\":null,\"redis_timeout\":2000,\"limit_by\":\"consumer\",<br>\"redis_password\":null,\"second\":9,\"day\":null,\"redis_database\":0,\"year\":null,<br>\"hour\":null,\"redis_host\":null,\"redis_port\":6379,\"header_name\":null,<br>\"fault_tolerant\":true}}\n</code></pre>\n<p>Using siege i've benchmarked the users</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/ee42763f67ce2c6a3e6f97b945740f70bf12d80bc251a6fd1266b07cf10d68f9/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630343738373237302f6d6973632f73696567655f75736572732e706e67\"><img loading=\"lazy\" title=\"siege_users\" src=\"https://camo.githubusercontent.com/ee42763f67ce2c6a3e6f97b945740f70bf12d80bc251a6fd1266b07cf10d68f9/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630343738373237302f6d6973632f73696567655f75736572732e706e67\" data-is-external-image=\"true\"  alt=\"siege_users\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1604787270/misc/siege_users.png\"></a></p>\n<p>You can check the headers with curl<br><code>$ while true; do curl -I -H \"apikey:332d05445a560ee65a76aeaa372d8904\" http://api.ing.h4x0r3d.lan:30080/api/ &amp;&amp; sleep 0.2; done</code></p>\n<pre><code>HTTP/1.1 200 OK\nContent-Type: text/html; charset=utf-8\nContent-Length: 658\nConnection: keep-alive\nServer: Werkzeug/1.0.1 Python/3.9.0\nDate: Sat, 07 Nov 2020 22:21:34 GMT\nX-RateLimit-Limit-Second: 4\nX-RateLimit-Remaining-Second: 3\nX-RateLimit-Limit-Hour: 1000000\nRateLimit-Limit: 4\nX-RateLimit-Remaining-Hour: 999755\nRateLimit-Remaining: 3\nRateLimit-Reset: 1\nX-Kong-Upstream-Latency: 3\nX-Kong-Proxy-Latency: 1\nVia: kong/2.1.4\n\nHTTP/1.1 200 OK\nContent-Type: text/html; charset=utf-8\nContent-Length: 658\nConnection: keep-alive\nServer: Werkzeug/1.0.1 Python/3.9.0\nDate: Sat, 07 Nov 2020 22:21:34 GMT\nX-RateLimit-Limit-Second: 4\nX-RateLimit-Remaining-Second: 2\nX-RateLimit-Limit-Hour: 1000000\nRateLimit-Limit: 4\nX-RateLimit-Remaining-Hour: 999754\nRateLimit-Remaining: 2\nRateLimit-Reset: 1\nX-Kong-Upstream-Latency: 3\nX-Kong-Proxy-Latency: 0\nVia: kong/2.1.4\n\nHTTP/1.1 200 OK\nContent-Type: text/html; charset=utf-8\nContent-Length: 658\nConnection: keep-alive\nServer: Werkzeug/1.0.1 Python/3.9.0\nDate: Sat, 07 Nov 2020 22:21:34 GMT\nX-RateLimit-Limit-Second: 4\nX-RateLimit-Remaining-Second: 1\nX-RateLimit-Limit-Hour: 1000000\nRateLimit-Limit: 4\nX-RateLimit-Remaining-Hour: 999753\nRateLimit-Remaining: 1\nRateLimit-Reset: 1\nX-Kong-Upstream-Latency: 3\nX-Kong-Proxy-Latency: 1\nVia: kong/2.1.4\n\nHTTP/1.1 200 OK\nContent-Type: text/html; charset=utf-8\nContent-Length: 658\nConnection: keep-alive\nServer: Werkzeug/1.0.1 Python/3.9.0\nDate: Sat, 07 Nov 2020 22:21:34 GMT\nX-RateLimit-Limit-Second: 4\nX-RateLimit-Remaining-Second: 0\nX-RateLimit-Limit-Hour: 1000000\nRateLimit-Limit: 4\nX-RateLimit-Remaining-Hour: 999752\nRateLimit-Remaining: 0\nRateLimit-Reset: 1\nX-Kong-Upstream-Latency: 3\nX-Kong-Proxy-Latency: 1\nVia: kong/2.1.4\n\nHTTP/1.1 429 Too Many Requests\nDate: Sat, 07 Nov 2020 22:21:34 GMT\nContent-Type: application/json; charset=utf-8\nConnection: keep-alive\nRetry-After: 1\nContent-Length: 41\nX-RateLimit-Limit-Second: 4\nX-RateLimit-Remaining-Second: 0\nX-RateLimit-Limit-Hour: 1000000\nRateLimit-Limit: 4\nX-RateLimit-Remaining-Hour: 999752\nRateLimit-Remaining: 0\nRateLimit-Reset: 1\nX-Kong-Response-Latency: 1\nServer: kong/2.1.4\n</code></pre>\n<p><br><br></p>\n<h3><a id=\"user-content-rules-precedence\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/Kubernetes-apigw#rules-precedence\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Rules Precedence</h3>\n<p>A plugin will always be run once and only once per request. But the configuration with which it will run depends on the entities it has been configured for.</p>\n<p>Plugins can be configured for various entities, combination of entities, or even globally. This is useful, for example, when you wish to configure a plugin a certain way for most requests, but make authenticated requests behave slightly differently.</p>\n<p>Therefore, there exists an order of precedence for running a plugin when it has been applied to different entities with different configurations. The rule of thumb is: the more specific a plugin is with regards to how many entities it has been configured on, the higher its priority.</p>\n<p>The complete order of precedence when a plugin has been configured multiple times is:</p>\n<ol>\n<li>Plugins configured on a combination of: a Route, a Service, and a Consumer. (Consumer means the request must be authenticated).</li>\n<li>Plugins configured on a combination of a Route and a Consumer. (Consumer means the request must be authenticated).</li>\n<li>Plugins configured on a combination of a Service and a Consumer. (Consumer means the request must be authenticated).</li>\n<li>Plugins configured on a combination of a Route and a Service.</li>\n<li>Plugins configured on a Consumer. (Consumer means the request must be authenticated).</li>\n<li>Plugins configured on a Route.</li>\n<li>Plugins configured on a Service.</li>\n<li>Plugins configured to run globally.</li>\n</ol>\n<p>Example: if the rate-limiting plugin is applied twice (with different configurations): for a Service (Plugin config A), and for a Consumer (Plugin config B), then requests authenticating this Consumer will run Plugin config B and ignore A. However, requests that do not authenticate this Consumer will fallback to running Plugin config A. Note that if config B is disabled (its enabled flag is set to false), config A will apply to requests that would have otherwise matched config B.</p>\n<p><br><br></p>\n<h3><a id=\"user-content-waf\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/Kubernetes-apigw#waf\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>WAF</h3>\n<p>Last but not lease , the api is configured behind Cloudflare,</p>\n<p>the users <code>slow_user fast_user</code> are available in case you want to test directly the service.</p>\n<p>Endpoint: <code>https://services.k8s.it/api/</code></p>\n<p><br><br></p>\n<p><code>$ curl -I -H \"apikey:332d05445a560ee65a76aeaa372d8904\" https://services.k8s.it/api/</code></p>\n<pre><code>HTTP/2 200\ndate: Sun, 08 Nov 2020 10:14:21 GMT\ncontent-type: text/html; charset=utf-8\nset-cookie: __cfduid=dab5b88be5427314b7b17a1a65d3178a41604830461; <br>expires=Tue, 08-Dec-20 10:14:21 GMT; path=/; domain=.k8s.it; HttpOnly; <br>SameSite=Lax\nvary: Accept-Encoding\nx-ratelimit-limit-second: 4\nx-ratelimit-remaining-second: 3\nx-ratelimit-limit-hour: 1000000\nratelimit-limit: 4\nx-ratelimit-remaining-hour: 999995\nratelimit-remaining: 3\nratelimit-reset: 1\nx-kong-upstream-latency: 3\nx-kong-proxy-latency: 4\nvia: kong/2.1.4\ncf-cache-status: DYNAMIC\ncf-request-id: 0648f2980000000f72931c2000000001\nexpect-ct: max-age=604800, <br>report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\nreport-to: {\"endpoints\":[{\"url\":\"https:\\/\\/a.nel.cloudflare.com\\/report?s=z4j%2FU3og%2FT2jBByhUKZtShDNLfLMWncExIy3EowJ2hOPJ17oCB0oeyY1GVaXirT%2BgWpTEEu<br>U%2F03gx%2F91uOy3mGD%2BFE4FhBGqFt7iC2bhaPc%3D\"}],\"group\":\"cf-nel\",\"max_age\":604800}\nnel: {\"report_to\":\"cf-nel\",\"max_age\":604800}\nserver: cloudflare\ncf-ray: 5eee86d319770f72-MXP\n</code></pre>\n<p><br><br></p>\n<h2><a id=\"user-content-conclusion\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/Kubernetes-apigw#conclusion\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion</h2>\n<p>Kong is a scalable, open source API Gateway.<br>Kong runs in front of any RESTful API and is extended through Plugins, which provide extra functionality and services beyond the core platform.</p>\n<p>The architecture is quite simple to understand and is made up of a few components…</p>\n<ul>\n<li>Kong base-module which wraps OpenResty and Nginx and is the engine which does the actual work</li>\n<li>Database layer with choice of Cassandra or Postgres to store all the configuration so it can be retrieved easily in case of failures</li>\n<li>Dashboard which provides User-Interface for API administration and viewing analytics (embedded in th Enerprise, third party for the community <em>Konga</em>)</li>\n</ul>\n<p>The Powerful of Kong is also supported by plugins from authentication, security, traffic control, logging, and etc…<br><br></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/d2a4de6795889077f983473c7575a12036254ec671f5440c6e63b68889926d65/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3438302f76313630373333323133302f6d6973632f554d4c5f6170695f67772e706e67\"><img loading=\"lazy\" title=\"uml_api_gw\" src=\"https://camo.githubusercontent.com/d2a4de6795889077f983473c7575a12036254ec671f5440c6e63b68889926d65/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3438302f76313630373333323133302f6d6973632f554d4c5f6170695f67772e706e67\" data-is-external-image=\"true\"  alt=\"uml_api_gw\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_480/v1607332130/misc/UML_api_gw.png\"></a></p>\n<p> </p>\n<p> </p>\n<p>Monitoring is also covered well by default kong official prometheus available here <a href=\"https://github.com/Kong/kong-plugin-prometheus\">https://github.com/Kong/kong-plugin-prometheus</a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/28dedd2eae334443bd6e668838f06caedc99f3c5cbd95e5b8d12869015cad8e9/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630353732333433362f6d6973632f6b6f6e665f6d6f6e69746f722e706e67\"><img loading=\"lazy\" title=\"kong_monitor\" src=\"https://camo.githubusercontent.com/28dedd2eae334443bd6e668838f06caedc99f3c5cbd95e5b8d12869015cad8e9/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630353732333433362f6d6973632f6b6f6e665f6d6f6e69746f722e706e67\" data-is-external-image=\"true\"  alt=\"kong_monitor\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1605723436/misc/konf_monitor.png\"></a></p>\n<p>Live: <a href=\"https://services.k8s.it/grafana/d/mY9p7dQmz/kong?orgId=2&amp;refresh=1m\" rel=\"nofollow\">https://services.k8s.it/grafana/d/mY9p7dQmz/kong?orgId=2&amp;refresh=1m</a></p>\n<p> </p>\n<p><strong>If your business exposes APIs, the API GATEWAY is a requirement to handle the third party.</strong></p>",
            "image": "https://www.k8s.it/media/posts/16/Screenshot-2020-11-20-at-22.20.25-2.png",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "token",
                   "rate limit",
                   "kubernetes",
                   "konga",
                   "kong",
                   "auth",
                   "apigw",
                   "api-gateway",
                   "api key"
            ],
            "date_published": "2020-11-08T13:57:27+01:00",
            "date_modified": "2020-12-07T15:22:46+01:00"
        },
        {
            "id": "https://www.k8s.it/python-rest-api-test-application.html",
            "url": "https://www.k8s.it/python-rest-api-test-application.html",
            "title": "Python rest api test application",
            "summary": "Working most of the times (always) in Platform i'm usually play with the infrastructure, however sometimes to create prototype i need backends that are done for the specific purpose. GOALS:The application must be a REST apiRun in kubernetes Docker and kubernetesThe application is working with&hellip;",
            "content_html": "<p>Working most of the times (always) in Platform i'm usually play with the infrastructure, however sometimes to create prototype i need backends that are done for the specific purpose.</p>\n<h2><a id=\"user-content-goals\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/py-test-backend#goals\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>GOALS:</h2>\n<ul>\n<li>The application must be a REST api</li>\n<li>Run in kubernetes<br><br><br><br></li>\n</ul>\n<h3><a id=\"user-content-docker-and-kubernetes\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/py-test-backend#docker-and-kubernetes\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Docker and kubernetes</h3>\n<p>The application is working with GET, POST, PUT, DELETE<br>enouth to cover most of the usages based on rest api.</p>\n<p>Inside the docker path you can run easly as local docker</p>\n<p><code>docker build --tag pytbak:0.1 .</code><br><code>docker run -t -p 5000:5000 pytbak:0.1</code><br>and access on it with <code>locahost:5000/api/</code></p>\n<p>instead if you want to run it in kubernetes ,<br>starting from the main folder you can apply the kubernetes folder on your environment<br><code>kubectl apply -f kubernetes/</code></p>\n<pre><code>$ kubectl  get pods -n pytbak\nNAME                             READY   STATUS    RESTARTS   AGE\npytbak-stable-5dfb4fbfd4-n64kx   1/1     Running   0          40m\n</code></pre>\n<p>Remember to change the host in the ingress file configuration</p>\n<pre><code>$ cat 03-ing-pytbak.yaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: pytbak-ingress\n  namespace: pytbak\n  annotations:\n    ingress.kubernetes.io/proxy-connect-timeout: \"10\"\n    ingress.kubernetes.io/proxy-read-timeout: \"30\"\n    ingress.kubernetes.io/proxy-send-timeout: \"30\"\nspec:\n  rules:\n  - host: pytbak.ing.h4x0r3d.lan\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: pytbak-svc\n          servicePort: 5000\n</code></pre>\n<p><em>host: pytbak.ing.h4x0r3d.lan</em> this is my ingress dns resolution</p>\n<p>TIPS: for ingress endpoints you can manage multiple namespace creating an A record in your DNS (as a subdomain) with a wildcard dedicated only for ingress matching the namespace and the host created</p>\n<p>in my case i have the home dns as <code>h4x0r3d.lan</code><br>and <code>*.ing.h4x0r3d.lan</code> as a record A of my kubernetes ingress<br>in this way if i create a namespace <em>pippo</em> the dns that i have to call to reach it out will be <em>pippo.ing.4x0r3d.lan</em> with no change on DNS.<br><br><br><br></p>\n<h3><a id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/py-test-backend#usage\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Usage</h3>\n<p>The application answer on /api/ with the main html page with methods</p>\n<table>\n<thead>\n<tr>\n<th>HTTP Method</th>\n<th align=\"center\">URI</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>GET</td>\n<td align=\"center\">http://[hostname]/api/get/context</td>\n<td>Retrieve list of context</td>\n</tr>\n<tr>\n<td>GET</td>\n<td align=\"center\">http://[hostname]/api/get/context/[context_id]</td>\n<td>Retrieve a context</td>\n</tr>\n<tr>\n<td>POST</td>\n<td align=\"center\">http://[hostname]/api/post/context</td>\n<td>Create a new context</td>\n</tr>\n<tr>\n<td>PUT</td>\n<td align=\"center\">http://[hostname]/api/put/context/[context_id]</td>\n<td>Update an existing context</td>\n</tr>\n<tr>\n<td>DELETE</td>\n<td align=\"center\">http://[hostname]/api/delete/context/[context_id]</td>\n<td>Delete acontext</td>\n</tr>\n</tbody>\n</table>\n<p>Following the methods example</p>\n<pre><code>$ curl -i http://pytbak.ing.h4x0r3d.lan/api/get/context\nHTTP/1.1 200 OK\nServer: openresty/1.15.8.1\nDate: Wed, 28 Oct 2020 20:02:02 GMT\nContent-Type: application/json\nContent-Length: 696\nConnection: keep-alive\nVary: Accept-Encoding\n\n{\n  \"context\": [\n    {\n      \"description\": \"RHEL 6 based\",\n      \"done\": false,\n      \"title\": \"Cento 6\",\n      \"uri\": \"http://pytbak.ing.h4x0r3d.lan/api/get/context/1\"\n    },\n    {\n      \"description\": \"RHEL 7 based\",\n      \"done\": false,\n      \"title\": \"Centos 7\",\n      \"uri\": \"http://pytbak.ing.h4x0r3d.lan/api/get/context/2\"\n    },\n    {\n      \"description\": \"RHEL 8 based\",\n      \"done\": false,\n      \"title\": \"Centos 8\",\n      \"uri\": \"http://pytbak.ing.h4x0r3d.lan/api/get/context/3\"\n    },\n    {\n      \"description\": \"Fedora + RHEL based\",\n      \"done\": false,\n      \"title\": \"Centos stream\",\n      \"uri\": \"http://pytbak.ing.h4x0r3d.lan/api/get/context/4\"\n    }\n  ]\n</code></pre>\n<p><br><br></p>\n<pre><code>$ curl -i -H \"Content-Type: application/json\" -X POST -d '{\"title\":\"Ubuntu 20.04 LTS\", \"description\":\"focal\"}' http://pytbak.ing.h4x0r3d.lan/api/post/context\nHTTP/1.1 201 CREATED\nServer: openresty/1.15.8.1\nDate: Wed, 28 Oct 2020 19:49:31 GMT\nContent-Type: application/json\nContent-Length: 165\nConnection: keep-alive\n\n{\n  \"task\": {\n    \"description\": \"focal\",\n    \"done\": false,\n    \"title\": \"Ubuntu 20.04 LTS\",\n    \"uri\": \"http://pytbak.ing.h4x0r3d.lan/api/get/context/5\"\n  }\n}\n</code></pre>\n<p><br><br></p>\n<pre><code>$ curl -i -H \"Content-Type: application/json\" -X PUT -d '{\"description\":\"Focal Fossa\"}' http://pytbak.ing.h4x0r3d.lan/api/put/context/5\nHTTP/1.1 200 OK\nServer: openresty/1.15.8.1\nDate: Wed, 28 Oct 2020 20:02:43 GMT\nContent-Type: application/json\nContent-Length: 171\nConnection: keep-alive\n\n{\n  \"task\": {\n    \"description\": \"Focal Fossa\",\n    \"done\": false,\n    \"title\": \"Ubuntu 20.04 LTS\",\n    \"uri\": \"http://pytbak.ing.h4x0r3d.lan/api/get/context/5\"\n  }\n}\n</code></pre>\n<p><br><br></p>\n<pre><code>$ curl -i -H \"Content-Type: application/json\" -X DELETE http://pytbak.ing.h4x0r3d.lan/api/delete/context/5\nHTTP/1.1 200 OK\nServer: openresty/1.15.8.1\nDate: Wed, 28 Oct 2020 20:04:47 GMT\nContent-Type: application/json\nContent-Length: 21\nConnection: keep-alive\n\n{\n  \"result\": true\n}\n$ curl -i http://pytbak.ing.h4x0r3d.lan/api/get/context/5\nHTTP/1.1 404 NOT FOUND\nServer: openresty/1.15.8.1\nDate: Wed, 28 Oct 2020 20:04:54 GMT\nContent-Type: application/json\nContent-Length: 27\nConnection: keep-alive\n\n{\n  \"error\": \"Not found\"\n}</code><code></code></pre>",
            "image": "https://www.k8s.it/media/posts/15/Screenshot-2020-11-20-at-23.08.36.png",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "test",
                   "restapi",
                   "rest-api",
                   "rest",
                   "python",
                   "kubernetes",
                   "docker",
                   "backend",
                   "api",
                   "PUT",
                   "POST",
                   "GET",
                   "DELETE"
            ],
            "date_published": "2020-10-30T10:39:29+01:00",
            "date_modified": "2020-11-20T23:08:55+01:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-sitespeedio.html",
            "url": "https://www.k8s.it/kubernetes-sitespeedio.html",
            "title": "Kubernetes sitespeed.io",
            "summary": "Hello First of all, this is a thought around a website metrics management, is not the only way, but is one way for a high level overview. How to read this ... However you can reach the GOAL just using docker and crontab for example&hellip;",
            "content_html": "<p>Hello</p>\n<p>First of all, this is a thought around a website metrics management, is not the only way, but is one way for a high level overview.</p>\n<p>How to read this ...</p>\n<ul>\n<li>i'm focused to share some concept about website monitoring</li>\n<li>i'm sharing a possible way to manage in kubernetes</li>\n<li>i'm using some other tools in kubernetes just because i'm evaluating this for other purpose</li>\n</ul>\n<p>However you can reach the GOAL just using docker and crontab for example<br><br><br><br></p>\n<h2><a id=\"user-content-motivations\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-sitespeed.io#motivations\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Motivations</h2>\n<p>Well ... a website is a product itself,<br>it could be a Wordpress, a Magento ecommerce or a structured multiple applications that owns each ones a different section of the website.</p>\n<p>However if running a business on top, you should move your evolution as a customer perspective:</p>\n<ul>\n<li>how long does is take the website asnwer ?</li>\n<li>is the response time common for all sections ?</li>\n<li>new versions/deployments are better than before for the customer ?</li>\n</ul>\n<p>You know, if the response time is more than X seconds ... and you are selling a common gadgets that could be retrieved elsewhere , you are losing money and customer affiliation.</p>\n<p>There are also some others problems... when someone in your company or a customer will say ... the website il slow</p>\n<ul>\n<li>Faster from my fiber home connection</li>\n<li>Faster from my mobile premium plus SIM</li>\n<li>Slow from wireless</li>\n<li>Fast from wireless</li>\n<li>No idea</li>\n<li>Faster than … ?!?! compared to ... ?!?!</li>\n</ul>\n<p>No, look how it's slow (2g connection in the sahara desert)<br><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/3251fd1e9ec686be58b3f6c8669b185187843283/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3238362f76313630313533343536332f6d6973632f53637265656e73686f745f323032302d31302d30315f61745f30382e34302e30362e706e67\"><img loading=\"lazy\" title=\"reaction\" src=\"https://camo.githubusercontent.com/3251fd1e9ec686be58b3f6c8669b185187843283/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3238362f76313630313533343536332f6d6973632f53637265656e73686f745f323032302d31302d30315f61745f30382e34302e30362e706e67\" data-is-external-image=\"true\"  alt=\"reaction\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_286/v1601534563/misc/Screenshot_2020-10-01_at_08.40.06.png\"></a><br><br><br></p>\n<p>Now, we know what we need ... DATA<br>Evaluate those during a long therm periode looking for performance</p>\n<ul>\n<li>release by release</li>\n<li>feature by feature</li>\n<li>etc etc</li>\n</ul>\n<p>First of all we have to test our websites on the customer position... so no 1gbit inline connection with 0.00001 roundtrip :)</p>\n<p>From the multitude of products , webtest , lighthouse , selenium and so on i really like sitespeed.io<br><br><br></p>\n<h3><a id=\"user-content-goal\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-sitespeed.io#goal\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>GOAL</h3>\n<ul>\n<li>be able to have an objective trend</li>\n<li>check the goodness of releases</li>\n</ul>\n<p><br><br><br><br></p>\n<h2><a id=\"user-content-the-customer-point-of-view\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-sitespeed.io#the-customer-point-of-view\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>The customer point of view</h2>\n<p>You have to know your product and your customer ...</p>\n<p>If you own the product you know that the customer is \"forced\" to buy by you. Immgine to are Apple, you know that customers are affiliated to you... so if something is slow, probably even if the device is available in other websites the customer will wait the answer.</p>\n<p>On the opposite side if you are a retailer , and the product is quite common with no brandlove etc etc ... if the website is slow the user will change immediatly the website to land to somewhere else.<br><br></p>\n<h3><a id=\"user-content-speed\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-sitespeed.io#speed\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Speed</h3>\n<p>we usually define a <em>slowness</em> by a perception.</p>\n<p>However , in 2020 you know the Data that comes from GA and understand when people leave a page , after some amount of time.</p>\n<p>Consider those, rate and the timing to tune the threadshold</p>\n<ul>\n<li>Bounce</li>\n<li>Leave/Exit</li>\n</ul>\n<p>and <ins>create the awareness</ins> about the limits and improvements you can achieve.</p>\n<p>Example. If a search take more than 10seconds, say <em>ciao ciao</em> to the customer.</p>\n<p>As said, when you mesure the speed you have to move yourself in the customer side ... so not all people has 1gbit connection , maybe the major are using mobile , maybe your host is in US and the customer in KR.<br>So ... internet connection should reflect the avg/wrost scenario Believe me that those data <a href=\"https://www.speedtest.net/global-index\" rel=\"nofollow\">https://www.speedtest.net/global-index</a> are quite optimistic :) i appreciate instead the documentation of sitespeed that has classified 4 networks</p>\n<p><a href=\"https://www.sitespeed.io/documentation/sitespeed.io/connectivity/\" rel=\"nofollow\">https://www.sitespeed.io/documentation/sitespeed.io/connectivity/</a></p>\n<ul>\n<li>3g</li>\n<li>3gfast</li>\n<li>3gslow</li>\n<li>cable</li>\n</ul>\n<p>I'd like to say that in 2020 <em>cable</em> and <em>3gfast</em> cover perfectly the wrost scenario</p>\n<p>Even if you don't agree with the speed category, remember to look the graphs and the metrics considering the DELTA<br><br><br><br></p>\n<h2><a id=\"user-content-sitespeedio\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-sitespeed.io#sitespeedio\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Sitespeed.io</h2>\n<p>This tool is open source , has a huge extension , in this scenario<br>i'll use only parts of that since i don't need the video recording, or HAR files and so on.</p>\n<p>A full report could be useful to check all feature and you can find here<br><a href=\"https://lorenzogirardi.github.io/sitespeedio-results/\" rel=\"nofollow\">https://lorenzogirardi.github.io/sitespeedio-results/</a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/48cabf3aeb609d823d3b407a2eede60b8039c554/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630313338373533332f6d6973632f7369746573706565642d726573756c74732e706e67\"><img loading=\"lazy\" title=\"sitespeed-results\" src=\"https://camo.githubusercontent.com/48cabf3aeb609d823d3b407a2eede60b8039c554/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313630313338373533332f6d6973632f7369746573706565642d726573756c74732e706e67\" data-is-external-image=\"true\"  alt=\"sitespeed-results\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1601387533/misc/sitespeed-results.png\"></a></p>\n<p>and you can have those results only with using the docker image</p>\n<p><code>docker run --rm -v \"$(pwd):/sitespeed.io\" sitespeedio/sitespeed.io:15.2.0 https://www.k8s.it/</code></p>\n<p>is know easy understand that you can extend in crontab this code and add some other option to store metrics and results files in s3 for example</p>\n<p><code>/usr/bin/docker run --privileged --shm-size=1g --rm --network=cable sitespeedio/sitespeed.io httos://www.example.com -v -b chrome --video --speedIndex -c cable --browsertime.iterations 1 --s3.key S3_KEY --s3.secret S3_SECRET --s3.bucketname S3_BUCKET --s3.removeLocalResult true --s3.path S3_PATH www.ecample.com --graphite.host GRAPHITE_HOST --graphite.port GRAPHITE_PORT --graphite.namespace GRAPHITE_PREFIX</code></p>\n<p><br><br><br><br></p>\n<h3><a id=\"user-content-case-of-study\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-sitespeed.io#case-of-study\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Case of study</h3>\n<p>Since we have identified the tool i have to specify the use case</p>\n<ul>\n<li>I need only metrics in this example because, so i don't need to store the output artifact</li>\n<li>I want to store the metrics in influxdb</li>\n<li>I want to run it not as a docker but inside kubernetes</li>\n<li>TBD i'd like to orchestrate actions</li>\n</ul>\n<p>The sitespeed.io docker fit perfectly in a kubernetes cronjob vision<br><a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/\" rel=\"nofollow\">https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/</a><br>is done to start, execute an action and exit</p>\n<p>However i'd like to explore a workflow manager ... not just for this case but also to exend some other <em>jobs</em><br><br><br></p>\n<h4><a id=\"user-content-argo\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-sitespeed.io#argo\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Argo</h4>\n<p>I chose this product because i was interested to have something similar to Rundeck , but with more extended capability in order to be possible build a ci/cd without spinnaker<br><a href=\"https://argoproj.github.io/\" rel=\"nofollow\">https://argoproj.github.io/</a></p>\n<p>The installation is quite easy , i've just trick a configmap due to volume mount problem genereted by my small kubernetes installation</p>\n<p>For a basic installation you need to create a dedicated namespace<br><code>kubectl create namespace argo</code></p>\n<p>and than deploy the argo infrastructure (server and workflow)<br><code>kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo/stable/manifests/install.yaml</code></p>\n<pre><code>NAMESPACE      NAME                                       READY   STATUS      RESTARTS   AGE\nargo           argo-server-6c886c5b77-l8jfv               1/1     Running     1          2d13h\nargo           workflow-controller-65948977d-zc9vt        1/1     Running     0          2d14h\n</code></pre>\n<p>As mentioned before i discover a <em>bug</em> (just because i use containerd instead docker in microk8s) , running the firt job<br><code>MountVolume.SetUp failed for volume \"docker-lib\" : hostPath type check failed: /var/lib/docker is not a directory</code><br>However adding</p>\n<pre><code>data:\n  config: |\n    containerRuntimeExecutor: pns\n</code></pre>\n<p>in <code>workflow-controller-configmap</code></p>\n<p>i fixed the issue.</p>\n<p><br><br></p>\n<p>Well now Argo is running and you can interact with the web UI or creating a services and a ingress configuration or with the port forwarding.<br>Since i'm now experimenting the solution i'm just using the second option.</p>\n<pre><code>$ kubectl -n argo port-forward deployment/argo-server 2746:2746\nForwarding from 127.0.0.1:2746 -&gt; 2746\nForwarding from [::1]:2746 -&gt; 2746\n</code></pre>\n<p>The UI interface is pretty clean and the authentication model follow the RBAC policy</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/c71a2d41217a3e5ddd0f1f0f5d8be257c5837273/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313535393038372f6d6973632f6172676f5f342e706e67\"><img loading=\"lazy\" title=\"argo_4\" src=\"https://camo.githubusercontent.com/c71a2d41217a3e5ddd0f1f0f5d8be257c5837273/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313535393038372f6d6973632f6172676f5f342e706e67\" data-is-external-image=\"true\"  alt=\"argo_4\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1080/v1601559087/misc/argo_4.png\"></a></p>\n<p>The editor as well is really good and if i have to think about a solution to share to other teams/depts , this has a good level of abstraction (at least you need to know what is contab)</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/8018d2f4ee3abd5e64fab8b04a8a8942cd5be16f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313535393038372f6d6973632f6172676f5f312e706e67\"><img loading=\"lazy\" title=\"argo_1\" src=\"https://camo.githubusercontent.com/8018d2f4ee3abd5e64fab8b04a8a8942cd5be16f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313535393038372f6d6973632f6172676f5f312e706e67\" data-is-external-image=\"true\"  alt=\"argo_1\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1080/v1601559087/misc/argo_1.png\"></a></p>\n<p>All informations are shared with the most relevant needs<br><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/edbf1e994dd7efc315e1d356c7222b3829b36891/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313535393038382f6d6973632f6172676f5f332e706e67\"><img loading=\"lazy\" title=\"argo_3\" src=\"https://camo.githubusercontent.com/edbf1e994dd7efc315e1d356c7222b3829b36891/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313535393038382f6d6973632f6172676f5f332e706e67\" data-is-external-image=\"true\"  alt=\"argo_3\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1080/v1601559088/misc/argo_3.png\"></a></p>\n<p>Events could be retrieved and evaluated as well<br><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/a472dbd7228b9b098ad942a92a2f336a228f32d0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3432302f76313630313535393038372f6d6973632f6172676f5f362e706e67\"><img loading=\"lazy\" title=\"argo_6\" src=\"https://camo.githubusercontent.com/a472dbd7228b9b098ad942a92a2f336a228f32d0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3432302f76313630313535393038372f6d6973632f6172676f5f362e706e67\" data-is-external-image=\"true\"  alt=\"argo_6\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_420/v1601559087/misc/argo_6.png\"></a></p>\n<p>Last but not least .... logs are in the UI <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/75169652516669d95b5549e5791198c3a937b5cc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313535393038372f6d6973632f6172676f5f352e706e67\"><img loading=\"lazy\" title=\"argo_5\" src=\"https://camo.githubusercontent.com/75169652516669d95b5549e5791198c3a937b5cc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313535393038372f6d6973632f6172676f5f352e706e67\" data-is-external-image=\"true\"  alt=\"argo_5\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1080/v1601559087/misc/argo_5.png\"></a></p>\n<p><br><br></p>\n<h3><a id=\"user-content-results\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-sitespeed.io#results\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Results</h3>\n<p>We are now able to see the metrics in grafana...</p>\n<p>you have 2 option , what is used in the<br><code>001-argo-job-sitespeedio.yaml</code><br>is the <em>influxdb</em> backend that could be rendered using</p>\n<p><a href=\"https://github.com/sitespeedio/grafana-bootstrap-docker/blob/main/dashboards/influxdb/pageSummary.json\">https://github.com/sitespeedio/grafana-bootstrap-docker/blob/main/dashboards/influxdb/pageSummary.json</a></p>\n<p>LIVE VIEW <a href=\"https://services.k8s.it/grafana/d/000000053/pagesummary-influxdb?orgId=2&amp;refresh=15m\" rel=\"nofollow\">https://services.k8s.it/grafana/d/000000053/pagesummary-influxdb?orgId=2&amp;refresh=15m</a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/db62aefc87c98b7a8ded25c187d55e255a412a62/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313234342f6d6973632f67726166616e615f312e706e67\"><img loading=\"lazy\" title=\"grafana_1\" src=\"https://camo.githubusercontent.com/db62aefc87c98b7a8ded25c187d55e255a412a62/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313234342f6d6973632f67726166616e615f312e706e67\" data-is-external-image=\"true\"  alt=\"grafana_1\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1080/v1601661244/misc/grafana_1.png\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/3eebdf9d9e19c08aa1a4f21dfd711c20ecce1c6a/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313234332f6d6973632f67726166616e615f322e706e67\"><img loading=\"lazy\" title=\"grafana_2\" src=\"https://camo.githubusercontent.com/3eebdf9d9e19c08aa1a4f21dfd711c20ecce1c6a/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313234332f6d6973632f67726166616e615f322e706e67\" data-is-external-image=\"true\"  alt=\"grafana_2\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1080/v1601661243/misc/grafana_2.png\"></a></p>\n<p>However you can also use <em>graphite</em> backend with the same metrics (even more with provided dashboards)</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/cfd27795ad1dfe9a29dd6658313cb044de1b8a80/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313832382f6d6973632f67726170686974655f312e706e67\"><img loading=\"lazy\" title=\"graphite_1\" src=\"https://camo.githubusercontent.com/cfd27795ad1dfe9a29dd6658313cb044de1b8a80/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313832382f6d6973632f67726170686974655f312e706e67\" data-is-external-image=\"true\"  alt=\"graphite_1\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1080/v1601661828/misc/graphite_1.png\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/f9f4a443bf3d57412c65f77a94bc1eb149ba0d4e/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313832382f6d6973632f67726170686974655f322e706e67\"><img loading=\"lazy\" title=\"graphite_2\" src=\"https://camo.githubusercontent.com/f9f4a443bf3d57412c65f77a94bc1eb149ba0d4e/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313832382f6d6973632f67726170686974655f322e706e67\" data-is-external-image=\"true\"  alt=\"graphite_2\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1080/v1601661828/misc/graphite_2.png\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/7e56609ce946b33a53517c01bd7ab7e0f5516334/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313832382f6d6973632f67726170686974655f332e706e67\"><img loading=\"lazy\" title=\"graphite_3\" src=\"https://camo.githubusercontent.com/7e56609ce946b33a53517c01bd7ab7e0f5516334/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313832382f6d6973632f67726170686974655f332e706e67\" data-is-external-image=\"true\"  alt=\"graphite_3\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1080/v1601661828/misc/graphite_3.png\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/c6079d0125e7cc38de67e40345b234313a3bf107/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313832392f6d6973632f67726170686974655f342e706e67\"><img loading=\"lazy\" title=\"graphite_4\" src=\"https://camo.githubusercontent.com/c6079d0125e7cc38de67e40345b234313a3bf107/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f313038302f76313630313636313832392f6d6973632f67726170686974655f342e706e67\" data-is-external-image=\"true\"  alt=\"graphite_4\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_1080/v1601661829/misc/graphite_4.png\"></a></p>\n<p><br><br><br><br></p>\n<h2><a id=\"user-content-whats-next\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-sitespeed.io#whats-next\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>WHAT'S NEXT</h2>\n<p>Sitespeed is really good to have an high level view but also details that probably could save load time.</p>\n<p>The introduction of Argo can orchestrate multiple checks on all pages/application you need to monitor without a specific crontab time for each job but considering a producer/consumer workflow.</p>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "workflow",
                   "sitespeed.io",
                   "sitespeed",
                   "observability",
                   "metrics",
                   "kubernetes",
                   "grafana",
                   "customer-view",
                   "argo"
            ],
            "date_published": "2020-10-02T20:41:42+02:00",
            "date_modified": "2020-11-14T22:55:02+01:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-postfix.html",
            "url": "https://www.k8s.it/kubernetes-postfix.html",
            "title": " Kubernetes postfix",
            "summary": " Long story short my vps provider changed tha ammount for the small instance from 1$ to 3$ so i took the advantage to switch my postfix service from cloud to onprem. Why, since the world is moving to cloud ? Because my own domain is&hellip;",
            "content_html": "<h1> </h1>\n<p>Long story short my vps provider changed tha ammount for the small instance from 1$ to 3$<br>so i took the advantage to switch my postfix service from cloud to onprem.</p>\n<p>Why, since the world is moving to cloud ?<br>Because my own domain is used just for alerting and small other stuff and 3$ month is creazy :)<br>Anyway i'll lost some good stuff like static ip and possibility ti have a ptr dns.<br>Shit happens it's just for my stuff.</p>\n<p>However we have 3 different topics to describe in this project</p>\n<ul>\n<li>what is an email</li>\n<li>postfix configuration</li>\n<li>postfix in kubernetes</li>\n</ul>\n<h2><a id=\"user-content-what-is-an-email\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-postfix#what-is-an-email\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>what is an email</h2>\n<p>send email sometimes is a dedicated work in an enterprise company.<br>There are many aspect to consider , not only infrastructure , like che segmentation of domains strategy,<br>email answer engagement and each isp is using a different threashold to mark your email as a spam,<br>however now we will focus only on the generic configuration with some minimum requirements.</p>\n<p>Here some topic that you probably know:</p>\n<ul>\n<li>TLS (add an encrypted connection in delivery)</li>\n<li>Sender-Id (mostly used for microsoft ecosystem)</li>\n<li>PTR record (used to check the corrispondence of a real smtp)</li>\n<li>SPF record (used on TXT level to define an whitelist of \"smtp allowed to ...\")</li>\n<li>Dkim (a private and public certificate to match the smtp and emails)</li>\n<li>Dmarc (a mix with SPF and Dkim to protect the domain from unauthorized use )</li>\n</ul>\n<h2><a id=\"user-content-postfix-configuration\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-postfix#postfix-configuration\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>postfix configuration</h2>\n<p>The second one is more related to middleware behaviour<br>i have a domain \"example.com\" and i'd like to</p>\n<ul>\n<li>receive email from and to this domain</li>\n<li>have catchall system to do not configure any email account but using everything <a href=\"mailto:a@example.com\">a@example.com</a>, <a href=\"mailto:b@example.com\">b@example.com</a>, <a href=\"mailto:whatever@example.com\">whatever@example.com</a></li>\n<li>relay all the emails to my gmail account</li>\n<li>reject the email that are tried to sent outside my chosed domains</li>\n</ul>\n<p>For all those topics the main configuration is in virtual and transport map in <em>postfix</em><br>There are some articles in internet, i'll avoid to reinvent hot water with the explanation.</p>\n<h2><a id=\"user-content-postfix-in-kubernetes\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-postfix#postfix-in-kubernetes\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>postfix in kubernetes</h2>\n<p>just as recap this was the configuration in the cloud vps</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/66d40f312601abf8ba03699a66366d6455c0805f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336363436332f6d6973632f7670732e706e67\"><img loading=\"lazy\" title=\"vps\" src=\"https://camo.githubusercontent.com/66d40f312601abf8ba03699a66366d6455c0805f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336363436332f6d6973632f7670732e706e67\" data-is-external-image=\"true\"  alt=\"vps\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1598366463/misc/vps.png\"></a></p>\n<p>now i just whitched the MX to my own microk8s lab</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/fd6de4c35300c6596ca2eafcfde2d501bd4c9576/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336363436352f6d6973632f6d6963726f6b38732e706e67\"><img loading=\"lazy\" title=\"microk8s\" src=\"https://camo.githubusercontent.com/fd6de4c35300c6596ca2eafcfde2d501bd4c9576/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336363436352f6d6973632f6d6963726f6b38732e706e67\" data-is-external-image=\"true\"  alt=\"microk8s\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1598366465/misc/microk8s.png\"></a></p>\n<p>However , inside the box a lot of implementation way can be taken</p>\n<h3><a id=\"user-content-scenario-1\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-postfix#scenario-1\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Scenario 1:</h3>\n<p>you can build an image for each dedicate purpose</p>\n<ul>\n<li>postfix</li>\n<li>rsyslog</li>\n<li>opendkim</li>\n<li>tls</li>\n</ul>\n<h3><a id=\"user-content-scenario-2\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-postfix#scenario-2\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Scenario 2:</h3>\n<p>looking the configuration adopted in <em>Scenario 1</em> , you can add an ingress tcp forward where<br>you can also add a tls layer with cert-manager (the new kube-lego).</p>\n<h3><a id=\"user-content-scenario-3\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-postfix#scenario-3\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Scenario 3:</h3>\n<p><em>Scenario 2</em> plus external storage for logs<br>etc etc</p>\n<h3><a id=\"user-content-scenario-lazy\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-postfix#scenario-lazy\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Scenario Lazy:</h3>\n<p>Embedded docker images with all you need with a node port (used only because i have a standalone kubernetes node).</p>\n<p>Well having everything in one single container the docker image reflect the pachage used in a virtual machine</p>\n<pre><code>FROM debian:buster\nMAINTAINER lgirardi &lt;l@k8s.it&gt;\n\nEXPOSE 25/tcp\n\nRUN apt-get -y update &amp;&amp; apt-get -yq install \\\n\tpostfix \\\n\tbsd-mailx \\\n\topendkim \\\n\topendkim-tools \\\n\tsasl2-bin \\\n\trsyslog \\\n        supervisor\n\n\n# Add files\nADD run.sh /opt/run.sh\n\n# Run\nCMD /opt/run.sh;/usr/bin/supervisord -c /etc/supervisor/supervisord.conf\n</code></pre>\n<p>where the <code>run.sh</code> is the supervisord daemon managing the process.</p>\n<ul>\n<li>postfix</li>\n<li>rsyslog</li>\n<li>opendkim</li>\n</ul>\n<p>The structure used is done to leave the configuration as a configmap and secrets<br>this will help in case you have to tune your system whiout regenerate the images that honestly make no sense to be build each deploy.</p>\n<p>As you see the deployment files has a huge number of volumes</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postfix\n  namespace: postfix\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app: postfix\n  template:\n    metadata:\n      labels:\n        app: postfix\n    spec:\n      containers:\n      - name: postfix\n        image: lgirardi/kubernetes-postfix:v0.2\n        lifecycle:\n          postStart:\n            exec:\n              command: [ \"bin/bash\", \"-c\", \"postmap /etc/postfix/virtual &amp;&amp; postmap /etc/postfix/transport &amp;&amp; supervisorctl restart postfix\" ]\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n        ports:\n        - name: smtp\n          containerPort: 25\n        volumeMounts:\n        - name: opendkim-key\n          mountPath: /etc/mail/dkim-k8s/keys/YOUR_DOMAIN/YOUR_DOMAIN.private\n          subPath: opendkim-key\n        - name: ca-crt\n          mountPath: /etc/postfix/tls/ca.crt\n          subPath: ca-crt\n        - name: ca-key\n          mountPath: /etc/postfix/tls/ca.key\n          subPath: ca-key\n        - name: postfix-transport\n          mountPath: /etc/postfix/transport\n          subPath: transport\n        - name: postfix-virtual\n          mountPath: /etc/postfix/virtual\n          subPath: virtual\n        - name: postfix-headerchecks\n          mountPath: /etc/postfix/header_checks\n          subPath: header_checks\n        - name: postfix-maincf\n          mountPath: /etc/postfix/main.cf\n          subPath: main.cf\n        - name: postfix-opendkimconf\n          mountPath: /etc/opendkim.conf\n          subPath: opendkim.conf\n        - name: postfix-keytable\n          mountPath: /etc/opendkim/KeyTable\n          subPath: KeyTable\n        - name: postfix-signingtable\n          mountPath: /etc/opendkim/SigningTable\n          subPath: SigningTable\n        - name: postfix-trustedhosts\n          mountPath: /etc/opendkim/TrustedHosts\n          subPath: TrustedHosts\n      volumes:\n        - name: postfix-transport\n          configMap:\n            name: postfix-conf\n            items:\n            - key: transport\n              path: transport\n        - name: postfix-virtual\n          configMap:\n            name: postfix-conf\n            items:\n            - key: virtual\n              path: virtual\n        - name: postfix-headerchecks\n          configMap:\n            name: postfix-conf\n            items:\n            - key: header_checks\n              path: header_checks\n        - name: postfix-maincf\n          configMap:\n            name: postfix-conf\n            items:\n            - key: main.cf\n              path: main.cf\n        - name: postfix-opendkimconf\n          configMap:\n            name: postfix-conf\n            items:\n            - key: opendkim.conf\n              path: opendkim.conf\n        - name: postfix-keytable\n          configMap:\n            name: postfix-conf\n            items:\n            - key: KeyTable\n              path: KeyTable\n        - name: postfix-signingtable\n          configMap:\n            name: postfix-conf\n            items:\n            - key: SigningTable\n              path: SigningTable\n        - name: postfix-trustedhosts\n          configMap:\n            name: postfix-conf\n            items:\n            - key: TrustedHosts\n              path: TrustedHosts\n        - name: opendkim-key\n          secret:\n            secretName: postfix-secret\n        - name: ca-crt\n          secret:\n            secretName: postfix-secret\n        - name: ca-key\n          secret:\n            secretName: postfix-secret\n</code></pre>\n<p>Here we have the configuration for:</p>\n<ul>\n<li>main.cf</li>\n<li>transport</li>\n<li>virtual</li>\n<li>header_checks</li>\n<li>opendkim.conf</li>\n<li>KeyTable</li>\n<li>SigningTable</li>\n<li>TrustedHosts</li>\n</ul>\n<p>You can change this aspect , is mostly related to the infrastructure where you fit the pod<br>and the company CI/CD</p>\n<p><strong>Remember to ADD your right values inside secrets and configmap where you have CAPS like <code>YOUR_DOMAIN</code></strong></p>\n<p>running the <em>apply</em> on kubernetes folder you will have the pod running<br><code>postfix postfix-7d664f786c-rmf54 1/1 Running 0 29m</code></p>\n<p>and loogking the logs i can see</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/694d0f364b26c0474b15921ff1ff8a4135190933/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336393033322f6d6973632f706f73746669786c6f672e706e67\"><img loading=\"lazy\" title=\"postfixlog\" src=\"https://camo.githubusercontent.com/694d0f364b26c0474b15921ff1ff8a4135190933/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336393033322f6d6973632f706f73746669786c6f672e706e67\" data-is-external-image=\"true\"  alt=\"postfixlog\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1598369032/misc/postfixlog.png\"></a></p>\n<p>The <code>key data is not secure</code> just a working because i've enabled this option in the configmap <code>RequireSafeKeys false</code><br>but the certificate is applied <code>opendkim[22]: 91E522A000C: DKIM-Signature field added</code></p>\n<p>Last one is the check on the client side with the righ option enabled</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/66fffe878e76dbeff1853c4abaf19f846af46529/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336383833352f6d6973632f656d61696c6f7074696f6e2e706e67\"><img loading=\"lazy\" title=\"clientemail\" src=\"https://camo.githubusercontent.com/66fffe878e76dbeff1853c4abaf19f846af46529/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539383336383833352f6d6973632f656d61696c6f7074696f6e2e706e67\" data-is-external-image=\"true\"  alt=\"clientemail\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1598368835/misc/emailoption.png\"></a></p>\n<h2><a id=\"user-content-conclusion\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-postfix#conclusion\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion</h2>\n<p>You can add postfix infrastructure to kubernetes with no problems at all ,<br>this project is a <em>prototype</em> , in a production infrastructure you can work around this to let it rock solid and scalable</p>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "tls",
                   "spf",
                   "postfix",
                   "kubernetes",
                   "dmarc",
                   "dkim"
            ],
            "date_published": "2020-08-25T18:53:21+02:00",
            "date_modified": "2020-11-14T22:55:07+01:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-servicemesh.html",
            "url": "https://www.k8s.it/kubernetes-servicemesh.html",
            "title": "Kubernetes servicemesh",
            "summary": "Do we need a service mesh ?few years ago i started to evaluate this feature fitting in an existing infrastructure There are many concept to consider and many mistake the people usually think Better to start with what is NOT a work for a service mesh So&hellip;",
            "content_html": "<h2>Do we need a service mesh ?</h2>\n<p>few years ago i started to evaluate this feature fitting in an existing infrastructure</p>\n<p>There are many concept to consider and many mistake the people usually think<br>Better to start with what is <em>NOT</em> a work for a service mesh</p>\n<ul>\n<li>is not an apigw (even if could share some components)</li>\n<li>is not the place to put firewall rules</li>\n<li>is not something magic that boost the applications</li>\n<li>is something that if not used with a know scope could generate a mess</li>\n</ul>\n<p>So what is ...<br>well short answer</p>\n<ul>\n<li>is the missing link in the infrastructure observability</li>\n<li>is a way to handle in a structured way the application routing</li>\n<li>is an internal ratelimit / anti ddos / infrastructure layer (be careful)</li>\n<li>could be a clever way to improve some application limits (expanded next)</li>\n</ul>\n<p>Anyway is this something that we can add in our infrastructure ?</p>\n<p>There no YES/NO , however we can evaluate the company and the maturity of microservices<br>internal rate limit , is usually a feature that could safe the infrastructure during snowball effects<br>however means that if the infrastructure is SYNC (no decoupling) have the rate limit can just<br>stop the application to serve requests , and this will propagated to the others below.</p>\n<p>result: no answer<br>threads safe</p>\n<p>Sometimes it's better to have a strategic business login using the a circuit breaker that bring a huge complexity in configuration.</p>\n<p>The other point related to rate limit is .. who will maintain those values ?<br>Should be part of deployment pipeline and directly correlated with the application scope<br>In a 200+ micro services infrastructure this could be a huge problem:</p>\n<ul>\n<li>project that lost ownership</li>\n<li>projects not well maintained</li>\n<li>new legacy projects</li>\n</ul>\n<p>So my idea about rate limit is to use it in a specific \"strategic\" applications and should not indiscriminately added to the whole infrastructure</p>\n<p>About the routing feature, we can consider as a more detailed and customized blue green deployment , this specific case it's really useful when we have to deploy new features in production and <em>canary</em> deployment is not enough to cover the business measurement we need.</p>\n<p>This feature could be used to keep a specific affinity within the microservices and this is the real feature that some of you can consider, imagine a strict dependencies between application an cache (as usual)<br>So the application <em>Pippo</em> is using the cache <em>Paperino</em></p>\n<p>Pippo is a namespace composed by 10 pods<br>Paperino is a cache composed by 6 pods</p>\n<p>Imagine that we have the cache as a replication/sharded and we have 2 availability zones</p>\n<p>With service mesh we can use labels to say to Pippo to use the cache Paperino only in the availability zone where the call start from Pippo av, this will reduce dramatically the roundtrip and the answer</p>\n<p>I played a bit with service mesh in order to answer some questions,<br>however related to firewall rules the right answer is Cilium :-)</p>\n<p>With this, I'd like to say that service mash give you a great value only<br>if your infrastructure is able to embrace it and only if you know what you are doing with this infrastructure.</p>\n<ul>\n<li>observability</li>\n<li>routing purpose (this is strictly related to the microservice architecture)</li>\n<li>rate limitng</li>\n</ul>\n<h2><a id=\"user-content-service-mesh-sample-lab\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#service-mesh-sample-lab\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Service Mesh sample lab</h2>\n<p>This lab is provided to discover and test the functionality w'd like to implement in our environment</p>\n<h3><a id=\"user-content-basic-setup\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#basic-setup\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Basic setup</h3>\n<ul>\n<li>minikube v1.6.2</li>\n<li>Kubernetes v1.17.0 on Docker '19.03.5'</li>\n</ul>\n<p><code>curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64</code> <code>chmod +x minikube</code><br><code>sudo install minikube /usr/local/bin/</code><br><code>minikube start --memory=3000 --cpus=3</code></p>\n<ul>\n<li>network (since in production we are using flannel that is not able to manage network policy we can start using no CNI to have the environment as much as close to lmn environment)</li>\n</ul>\n<h4><a id=\"user-content-namespaces\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#namespaces\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Namespaces</h4>\n<p>a → traefik (ingress)<br>b → apache<br>c → application<br>d → redis</p>\n<p>b is a namespaces that manage an apache used for some rewrite rules<br>c is a python application that is connected to a redis database, provide some function to set a time, get a time with /set context and /get context<br>d is the redis database</p>\n<p>c code</p>\n<pre><code>\"\"\"\n    Example app that integrates with redis and save/get timing\n\"\"\"\nfrom os import environ\nfrom datetime import datetime\nimport json\nimport redis\nfrom flask import Flask, redirect\n\nVERSION = \"1.1.1\"\nREDIS_ENDPOINT = environ.get(\"REDIS_ENDPOINT\", \"redis-svc.d-redis.svc.cluster.local\")\nREDIS_PORT = int(environ.get(\"REDIS_PORT\", \"6379\"))\n\n\nAPP = Flask(__name__)\n\n\n@APP.route(\"/\")\ndef redisapp():\n    \"\"\"Main redirect\"\"\"\n    return redirect(\"/get\", code=302)\n\n\n@APP.route(\"/set\")\ndef set_var():\n    \"\"\"Set the time\"\"\"\n    red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)\n    red.set(\"time\", str(datetime.now()))\n    return json.dumps({\"time\": str(red.get(\"time\"))})\n\n\n@APP.route(\"/get\")\ndef get_var():\n    \"\"\"Get the time\"\"\"\n    red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)\n    return json.dumps({\"time\": str(red.get(\"time\"))})\n\n\n@APP.route(\"/reset\")\ndef reset():\n    \"\"\"Reset the time\"\"\"\n    red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)\n    red.delete(\"time\")\n    return json.dumps({\"time\": str(red.get(\"time\"))})\n\n\n@APP.route(\"/version\")\ndef version():\n    \"\"\"Get the app version\"\"\"\n    return json.dumps({\"version\": VERSION})\n\n\n@APP.route(\"/healthz\")\ndef health():\n    \"\"\"Check the app health\"\"\"\n    try:\n        red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)\n        red.ping()\n    except redis.exceptions.ConnectionError:\n        return json.dumps({\"ping\": \"FAIL\"})\n\n    return json.dumps({\"ping\": red.ping()})\n\n\n@APP.route(\"/readyz\")\ndef ready():\n    \"\"\"Check the app readiness\"\"\"\n    return health()\n\n\nif __name__ == \"__main__\":\n    APP.run(debug=True, host=\"0.0.0.0\")\n</code></pre>\n<p>Dokerfile</p>\n<pre><code>FROM python:3.6-alpine\nCOPY . /app\nWORKDIR /app\nRUN pip install -r requirements.txt\nENTRYPOINT [\"python\"]\nCMD [\"app.py\"]\n</code></pre>\n<p>requirements.txt</p>\n<pre><code>Flask\nredis\npytest\npytest-flask\n</code></pre>\n<h3><a id=\"user-content-folders-structure\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#folders-structure\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Folders structure</h3>\n<pre><code>kubernetes/\n├── 00-traefik\n│   ├── A-00-traefik-ns.yaml\n│   ├── A-01-traefik-rbac.yaml\n│   └── A-02-traefik-ds.yaml\n├── 01-apache\n│   ├── B-00-k8s-apacherr-ns.yaml\n│   ├── B-01-k8s-apacherr-svc.yaml\n│   ├── B-02-k8s-apacherr-ing.yaml\n│   ├── B-03-k8s-apacherr-dpl.yaml\n│   └── B-04-k8s-apacherr-cfm.yaml\n├── 02-redis\n│   ├── D-00-lab-redis-ns.yaml\n│   ├── D-01-lab-redis-svc.yaml\n│   └── D-02-lab-redis-dpl.yaml\n└── 03-app\n    ├── C-00-app-ns.yaml\n    ├── C-01-app-svc.yaml\n    └── C-02-app-dpl.yaml\n</code></pre>\n<h3><a id=\"user-content-startup\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#startup\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Startup</h3>\n<p>kubernetes$ kubectl apply -f 00-traefik/</p>\n<pre><code>namespace/a-ingress-traefik created  \nclusterrole.rbac.authorization.k8s.io/traefik-ingress-controller created    \nserviceaccount/traefik-ingress-controller created  \nclusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller created\nserviceaccount/traefik-ingress-controller created\ndaemonset.apps/traefik-ingress-controller created\nservice/traefik-ingress-service created\n</code></pre>\n<p>kubernetes$ kubectl apply -f 01-apache/</p>\n<pre><code>namespace/b-apacherr created\nservice/apacherr-svc created\ningress.extensions/apacherr-ingress created\ndeployment.apps/apacherr created\nconfigmap/apacherr-80-config created\n</code></pre>\n<p>kubernetes$ kubectl apply -f 02-redis/</p>\n<pre><code>namespace/d-redis created\nservice/redis-svc created\ndeployment.apps/redis created\n</code></pre>\n<p>kubernetes$ kubectl apply -f 03-app/</p>\n<pre><code>namespace/c-app-count created    \nservice/app-count-svc created  \ndeployment.apps/pythonapp created  \n</code></pre>\n<p>kubectl get po --all-namespaces</p>\n<pre><code>NAMESPACE           NAME                               READY   STATUS    RESTARTS   AGE\na-ingress-traefik   traefik-ingress-controller-jkppg   1/1     Running   0          5m29s\nb-apacherr          apacherr-8b786b45d-g9vcl           1/1     Running   0          5m19s\nc-app-count         pythonapp-555d6d88cd-slhfb         1/1     Running   0          4m55s\nd-redis             redis-b869b89d-pf6ms               1/1     Running   0          5m12s\nkube-system         coredns-6955765f44-6nrdr           1/1     Running   1          74m\nkube-system         coredns-6955765f44-9fbgt           1/1     Running   1          74m\nkube-system         etcd-minikube                      1/1     Running   1          74m\nkube-system         kube-addon-manager-minikube        1/1     Running   1          74m\nkube-system         kube-apiserver-minikube            1/1     Running   1          74m\nkube-system         kube-controller-manager-minikube   1/1     Running   1          74m\nkube-system         kube-proxy-cchls                   1/1     Running   1          74m\nkube-system         kube-scheduler-minikube            1/1     Running   1          74m\nkube-system         storage-provisioner                1/1     Running   2          74m\n</code></pre>\n<p>make sure virtualbox 8081 port should be available</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/f303afac85505ee6e02651c55518f1eb809a6f97/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731352f6d6973632f696d675f7669727475616c626f782d706f7274666f7277617264696e672e706e67\"><img loading=\"lazy\" title=\"Virtualbox port forwarding\" src=\"https://camo.githubusercontent.com/f303afac85505ee6e02651c55518f1eb809a6f97/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731352f6d6973632f696d675f7669727475616c626f782d706f7274666f7277617264696e672e706e67\" data-is-external-image=\"true\"  alt=\"Virtualbox port forwarding\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1594573715/misc/img_virtualbox-portforwarding.png\"></a></p>\n<h2><a id=\"user-content-flow\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#flow\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>flow</h2>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/70a420864968278b8940023ba6aa95dd7bf932a6/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731342f6d6973632f696d675f666c6f772e706e67\"><img loading=\"lazy\" title=\"flow\" src=\"https://camo.githubusercontent.com/70a420864968278b8940023ba6aa95dd7bf932a6/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731342f6d6973632f696d675f666c6f772e706e67\" data-is-external-image=\"true\"  alt=\"flow\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1594573714/misc/img_flow.png\"></a></p>\n<h5><a id=\"user-content-inizialize-the-redis-database\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#inizialize-the-redis-database\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>inizialize the redis database</h5>\n<p><code>$ curl http://pippo.lan/count/set</code><br>{\"time\": \"b'2019-12-28 20:06:33.919059'\"}</p>\n<h5><a id=\"user-content-test-from-apache-to-application-case-1\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#test-from-apache-to-application-case-1\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>test from apache to application (case 1)</h5>\n<p><code>$ curl http://pippo.lan/count/get</code><br>{\"time\": \"b'2019-12-28 20:06:33.919059'\"}</p>\n<h5><a id=\"user-content-test-from-apache-to-redis-case-2\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#test-from-apache-to-redis-case-2\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>test from apache to redis (case 2)</h5>\n<p><code>$ curl http://pippo.lan/redis/GET/time</code><br>{\"GET\":\"2019-12-28 20:06:33.919059\"}</p>\n<h5><a id=\"user-content-network-rule-example\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#network-rule-example\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>network rule example</h5>\n<p>cilium labels</p>\n<pre><code>ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                           IPv6   IPv4            STATUS   \n           ENFORCEMENT        ENFORCEMENT                                                                                               \n201        Disabled           Disabled          32580      k8s:app=redis                                                10.15.182.193   ready   \n                                                           k8s:io.cilium.k8s.namespace.labels.name=d-redis                                      \n                                                           k8s:io.cilium.k8s.policy.cluster=default                                             \n                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                      \n                                                           k8s:io.kubernetes.pod.namespace=d-redis                                              \n                                                           k8s:track=redis                                                                      \n1257       Disabled           Disabled          4          reserved:health                                              10.15.197.106   ready   \n1663       Disabled           Disabled          54130      k8s:app=apacherr                                             10.15.192.41    ready   \n                                                           k8s:io.cilium.k8s.namespace.labels.name=b-apacherr                                   \n                                                           k8s:io.cilium.k8s.policy.cluster=default                                             \n                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                      \n                                                           k8s:io.kubernetes.pod.namespace=b-apacherr                                           \n3167       Disabled           Disabled          33702      k8s:app=pythonapp                                            10.15.247.186   ready   \n                                                           k8s:io.cilium.k8s.namespace.labels.name=c-app-count                                  \n                                                           k8s:io.cilium.k8s.namespace.labels.purpose=app                                       \n                                                           k8s:io.cilium.k8s.policy.cluster=default                                             \n                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                      \n                                                           k8s:io.kubernetes.pod.namespace=c-app-count                                          \n                                                           k8s:track=pythonapp-stable         \n</code></pre>\n<p>network rule</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: isolate-namespace\n  namespace: d-redis\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: c-app-count\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: c-app-count\n\n</code></pre>\n<p>   </p>\n<p>cilium/hubble <a href=\"https://github.com/cilium/hubble\">https://github.com/cilium/hubble</a> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/70234ad4768db6537d28a417f0e73061ce2e51b4/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f687562626c652d64726f702e706e67\"><img loading=\"lazy\" title=\"hubble\" src=\"https://camo.githubusercontent.com/70234ad4768db6537d28a417f0e73061ce2e51b4/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f687562626c652d64726f702e706e67\" data-is-external-image=\"true\"  alt=\"hubble\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1594574069/misc/hubble-drop.png\"></a></p>\n<p> </p>\n<p>istio/kiali <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/79a5b07227e5651705810596cef972d074ed201f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f697374696f2d6b69616c692e706e67\"><img loading=\"lazy\" title=\"kiali\" src=\"https://camo.githubusercontent.com/79a5b07227e5651705810596cef972d074ed201f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f697374696f2d6b69616c692e706e67\" data-is-external-image=\"true\"  alt=\"kiali\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1594574069/misc/istio-kiali.png\"></a></p>\n<p> </p>\n<p>video Cilium example --&gt; <a href=\"https://res.cloudinary.com/ethzero/video/upload/v1594574074/misc/cilium.mkv\" rel=\"nofollow\">img/cilium.mkv</a></p>\n<p>video Istio + Cilium example --&gt; <a href=\"https://res.cloudinary.com/ethzero/video/upload/v1594574090/misc/istio.mkv\" rel=\"nofollow\">img/istio.mkv</a><br> </p>\n<h2><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#requirements\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>requirements</h2>\n<ul>\n<li>use service mesh to segregate redis \"d\" to accept connections only from application \"c\"<br>expected \"case 1\" still working, \"case 2\" stop working and receive an error</li>\n</ul>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "service mesh",
                   "rate limit",
                   "observability",
                   "metrics",
                   "linkerd",
                   "kubernetes",
                   "kiali",
                   "istio",
                   "cilium",
                   "api"
            ],
            "date_published": "2020-08-11T20:50:36+02:00",
            "date_modified": "2020-11-14T22:55:12+01:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-apacherr.html",
            "url": "https://www.k8s.it/kubernetes-apacherr.html",
            "title": "Kubernetes apache httpd",
            "summary": "The semi-unuseful apache implementation in kubernetesWell , why we are talking about apache httpd in kubernetes ? We have ingress resources , we have ambassador and we are using microservices... True but internet was not built yesterday and for some reasons out of my knowledge&hellip;",
            "content_html": "<h2>The semi-unuseful apache implementation in kubernetes</h2>\n<p>Well , why we are talking about apache httpd in kubernetes ?<br>We have ingress resources , we have ambassador and we are using microservices...<br>True but internet was not built yesterday and for some reasons out of my knowledge ,<br>people are ostinated to manage rewrite rules in apache instead to use a dedicated router application (react, zuul .. database!?!?! etc etc)<br>However sometimes we have to balance between the academic vision and the reality.</p>\n<h2><a id=\"user-content-digression\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-apacherr#digression\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>digression</h2>\n<p>Talking about apache https , nginx , haproxy ... i'm referring to the idea behind manage a complex website.<br>A website could be composed my hundreds of microservices but the domain it's usually one<br><a href=\"http://www.example.com/\" rel=\"nofollow\">www.example.com</a></p>\n<p><a href=\"http://www.example.com/\" rel=\"nofollow\">www.example.com</a> has the root path /<br>/it/ managed by cms<br>/it/offerte managed by cms<br>/uk/ managed by cms<br>/uk/offers managed by cms<br>/../ whatever<br>/it/clienti/ managed by customer-app<br>/uk/customers/ managed by customers-app<br>/../somethingelse<br>/secure/ managey by payment-app<br>...<br>omg path clash ... so we need to exclude in apache /uk/customers/ from cms proxypass but<br>meantime enable a dedicated proxy pass to a specific application endpoint.<br>and we are mannually manage all language , all applications with static configurations...<br>and if tomorrow we will open APAC ... what we have to do ?<br>and if we need to cover a former third parti company and acquire his seo ranking we should create<br>thousands of redirects ? and how we can can validate avoiding loops ?</p>\n<p>A better design start giving the right responsability , that could be managed using a business layer<br>that we can call \"front controller\" where we can apply all rules.</p>\n<p>In terms of responsability all applaction behind this layer should be working by selfcontained logic<br>example... if i have a seo application this should be working without this layer , removing direct dependency<br>same concept for cms application , customers application and so on.<br>So what this layer will do ?</p>\n<p>A front controller should be the owner of root path of our websites \"/\"<br>Should be also responsible to handle all the others paths after the root ones.</p>\n<p>Main duties:</p>\n<ul>\n<li>handle all requests and manage the backend application with business logic</li>\n<li>provide dynamic path based on business rules (language + brand + something else)</li>\n<li>provide the AB test logic</li>\n<li>provide a validation logic</li>\n<li>expose a company backoffice to trim the website layout</li>\n</ul>\n<p>Examples</p>\n<p>Having a global websites spread with multiple countris with differents domains/brands and languages we can immagine</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/184bca691d84bf02cd01d06642b3aac6f582d28f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538323238393238352f6d6973632f66726f6e742d636f6e74726f6c6c65722e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/184bca691d84bf02cd01d06642b3aac6f582d28f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538323238393238352f6d6973632f66726f6e742d636f6e74726f6c6c65722e706e67\" data-is-external-image=\"true\"  alt=\"frontcontroller\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1582289285/misc/front-controller.png\"></a></p>\n<p>Where the microservice/application CMS is responsible to hangle all domains and all languages and the<br>front controller take the ownership to match brand plus .tld (or paths \"/fr/\")<br>in order to dinamically generate the right url with canonical pages.</p>\n<p>Many and many others assumptions can be covered by this componet, however we have to stay grounded<br>and check how we can manage an apache responsible to redirects proxypass an rewrite rules.</p>\n<h2><a id=\"user-content-some-concepts-about-this-project\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-apacherr#some-concepts-about-this-project\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Some concepts about this project</h2>\n<p>Even if we are working in a dynamic environment it's no rare to have the traditional layers</p>\n<p>DMZ --&gt; layer 1<br>Application --&gt; layer 2<br>Database --&gt;layer 3</p>\n<p>In this picture apache httpd should usually placed on layer 1 ,<br>but consider apache not for the common web server but like a \"product\" ,<br>something that could be managed not by SRE , but Product Engeneer.<br>A product that own a dedicated business, like seo, sem , vanity urls etc etc.</p>\n<p>Having those considerations, we can \"downgrade\" apache httpd in layer 2 like any application<br>and honor the DMZ (if needed ?!?!) on top by ingress/haproxy/bigf5 (where maybe we can terminate the TLS).</p>\n<h2><a id=\"user-content-implementation\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-apacherr#implementation\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Implementation</h2>\n<p>The code in this project is designet to manage apache configuration by configmap,<br>however some websites are really complex and there are some limits implication with ectd max object size.</p>\n<p>In this scenario it's higly raccomended to deploy the release with a standard pipeline with compiled<br>container on the source.</p>\n<h2><a id=\"user-content-deploy\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-apacherr#deploy\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>deploy</h2>\n<p><code>kubectl apply -f apacherr/deployment/</code></p>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "rewrite rules",
                   "kubernetes",
                   "httpd",
                   "front controller",
                   "apache"
            ],
            "date_published": "2020-08-11T20:48:50+02:00",
            "date_modified": "2020-11-14T22:55:32+01:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-guacamole.html",
            "url": "https://www.k8s.it/kubernetes-guacamole.html",
            "title": "Kubernetes guacamole",
            "summary": "Here we are , another apache guacamole implementation in kubernetesThis service is designed to avoid the usage of mysql and create a standalone project The main idea is to use the user-mapping.xml as a config map For production environment i suggest to add the ldap auth (ad.openldap,freeipa),&hellip;",
            "content_html": "<div class=\"flex-shrink-0 col-12 col-md-9 mb-4 mb-md-0\">\n<div id=\"readme\" class=\"Box md js-code-block-container Box--responsive\">\n<div class=\"Box-body px-5 pb-5\">\n<article class=\"markdown-body entry-content container-lg\">\n<h2>Here we are , another apache guacamole implementation in kubernetes</h2>\n<p>This service is designed to avoid the usage of mysql and create a standalone project</p>\n<p>The main idea is to use the <strong>user-mapping.xml</strong> as a config map</p>\n<p>For production environment i suggest to add the ldap auth (ad.openldap,freeipa),<br>mysql database should be managed with a dedicated instances and mantained in case of \"exit\"</p>\n<h2><a id=\"user-content-what-is-a-bastion-host\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#what-is-a-bastion-host\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>what is a bastion host</h2>\n<p>On the Internet, a bastion host is the only host computer that a company allows to be addressed<br>directly from the public network and that is designed to screen the rest of its network from security exposure.</p>\n<h2><a id=\"user-content-how-this-tool-can-be-used\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#how-this-tool-can-be-used\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>how this tool can be used</h2>\n<p>The tool is designed to be used when you have some dedicated service in production and you have to keep<br>the control of access and account used , guacamole has the ability to manage the most used platforms (windows and linux)<br>as host in backend to be reached from developers ... contractors ...</p>\n<h2><a id=\"user-content-why-in-kubernetes\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#why-in-kubernetes\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>why in kubernetes</h2>\n<p>Since the auth method could scale by configmap or ldap or mysql , is designed to scale<br>we have also the benefits to have a low footprint compared to a traditional vm.</p>\n<h2><a id=\"user-content-config-to-change\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#config-to-change\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>config to change</h2>\n<p>Before deploy you need to specify the following parameters in guacamole folder</p>\n<ul>\n<li>YOUR_DOMAIN to reflect your domain url in 03-guacamole-ing.yaml</li>\n<li>user YOUR_USERNAME / YOUR_MD5_PWD and hosts xml configuration in 04-guacamole-cfm.yaml following <a href=\"https://guacamole.apache.org/doc/gug/configuring-guacamole.html#user-mapping\" rel=\"nofollow\">https://guacamole.apache.org/doc/gug/configuring-guacamole.html#user-mapping</a></li>\n</ul>\n<p>screenshots</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/905e74d0ce81c8b239f67d405567100a3f181292/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d77696e2e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/905e74d0ce81c8b239f67d405567100a3f181292/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d77696e2e706e67\" data-is-external-image=\"true\"  alt=\"windows\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1580850552/misc/guacamole-win.png\"></a><br><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/fd53b1991cd9693679aae9aadf72bc75d025c2ad/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d6c696e75782e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/fd53b1991cd9693679aae9aadf72bc75d025c2ad/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d6c696e75782e706e67\" data-is-external-image=\"true\"  alt=\"linux\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1580850552/misc/guacamole-linux.png\"></a></p>\n<h2><a id=\"user-content-deploy\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#deploy\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>deploy</h2>\n<p><code>kubectl apply -f guacd</code></p>\n<p><code>kubectl apply -f guacamole</code></p>\n<p>You can secure the connection with kube-lego and use cillium to add network rules </p>\n</article>\n</div>\n</div>\n</div>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "ssh",
                   "rdp",
                   "kubernetes",
                   "guacd",
                   "guacamole",
                   "bastion host",
                   "bastion"
            ],
            "date_published": "2020-08-11T20:46:54+02:00",
            "date_modified": "2020-11-14T22:55:40+01:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-strongswan.html",
            "url": "https://www.k8s.it/kubernetes-strongswan.html",
            "title": "Kubernetes vpn strongswan",
            "summary": "How we can manage vpn in kubernetes environmentHi there , this project is to cover the vpn ipsec-xauth topic in a kubernetes evironment, the goal of this is to have the less effort possible when we have to manage users. Architecture Requirements: WHYThe traditional ipsec-xauth&hellip;",
            "content_html": "<div class=\"flex-shrink-0 col-12 col-md-9 mb-4 mb-md-0\">\n<div id=\"readme\" class=\"Box md js-code-block-container Box--responsive\">\n<div class=\"Box-body px-5 pb-5\">\n<article class=\"markdown-body entry-content container-lg\">\n<h2>How we can manage vpn in kubernetes environment</h2>\n<p>Hi there , this project is to cover the vpn ipsec-xauth topic in a kubernetes evironment,<br>the goal of this is to have the less effort possible when we have to manage users.</p>\n<p>Architecture<br><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/ee7bbe0fe8e2f17b0bda45b6b92d585105d9adcc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538343733313733352f6d6973632f76706e5f6469616772616d2e6a7067\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/ee7bbe0fe8e2f17b0bda45b6b92d585105d9adcc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538343733313733352f6d6973632f76706e5f6469616772616d2e6a7067\" data-is-external-image=\"true\"  alt=\"architecture\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1584731735/misc/vpn_diagram.jpg\"></a></p>\n<p>Requirements:</p>\n<ul>\n<li>Kubernetes</li>\n<li>Strongswan</li>\n<li>Microsoft Acrive Directory / openldap / freeipa etc etc LDAP (i'll use ldap instead the software name)</li>\n</ul>\n<h2><a id=\"user-content-why\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-strongswan#why\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>WHY</h2>\n<p>The traditional ipsec-xauth vpn with ikev1 is based on PSK<br>and a client username/password , this is a problem when the credential are stored in a file<br>in kubernetes update a file always mean rollout a new deploy or create a procedure to<br>make effective the changes.<br>So the idea is to deploy something that doesn't need any interaction<br>after the deploy and manage the clients, with the company standards,<br>like password expiration, password complexity, groups attributions and so on.</p>\n<h2><a id=\"user-content-how\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-strongswan#how\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>HOW</h2>\n<p>In order to have a fully managed services we can leverage the usage of ldap procedures (that all company has).<br>Strongswan (a fork of *swan ipsec software) could be integrated with ldap with pam.<br>pam is ... well --&gt; <a href=\"https://tldp.org/HOWTO/User-Authentication-HOWTO/x115.html\" rel=\"nofollow\">https://tldp.org/HOWTO/User-Authentication-HOWTO/x115.html</a></p>\n<p>So what we need in ldap ?<br>We need:</p>\n<ul>\n<li>a technical user that is a low level profile that will be used only to check the users inside the ldap tree and the groups associated</li>\n<li>a group to associate to people who need/granted the vpn access</li>\n</ul>\n<p>in this scenario tech users is --&gt; <em>ldapbind</em><br>group is --&gt; <em>vpn</em></p>\n<p>here some screen related</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/48427e34136d63b4b7348ba8c2148e178665cdf0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f62696e645f757365722e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/48427e34136d63b4b7348ba8c2148e178665cdf0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f62696e645f757365722e706e67\" data-is-external-image=\"true\"  alt=\"ldapbind\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584730828/misc/strongswan_bind_user.png\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/141e29aaed92e477719b517dd704c815b18c23bc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f757365725f76706e5f67726f75702e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/141e29aaed92e477719b517dd704c815b18c23bc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f757365725f76706e5f67726f75702e706e67\" data-is-external-image=\"true\"  alt=\"vpn group\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584730828/misc/strongswan_user_vpn_group.png\"></a></p>\n<p>Then... now we have to configure configure the Docker image in order to support pam ldap.</p>\n<p>Dockerfile</p>\n<pre><code>FROM debian:stretch\nMAINTAINER lgirardi &lt;l@k8s.it&gt;\n\n\nRUN apt-get -y update &amp;&amp; apt-get -yq install \\\n        strongswan \\\n        libcharon-extra-plugins \\\n        iptables \\\n        kmod \\\n        libpam-ldap \\\n        vim\n\nEXPOSE 500/udp 4500/udp\n\nCMD /usr/sbin/ipsec start --nofork\n</code></pre>\n<p>libpam-ldap and libcharon-extra-plugins are what we need to perform this kind of integration.</p>\n<p>Since strongswan is not traditionally used in kubernetes , has some files that needs a configuration.<br>ENV variables are the most useful to configure it,<br>unfortunately the process is not able to share the env this the child process,<br>so we will work with 2 concepts,<br>use the configmap for all files we need to configure use the secrets for all sensitive data we need to add</p>\n<p>files configured:</p>\n<ul>\n<li>ipsec.conf (the strongswan main configuration)</li>\n<li>xauth-pam.conf (strongswan configuration to enable pam)</li>\n<li>attr.conf (strongswan configuration file for split-tunnel)<br><em>split-tunnel is when you want to move in vpn only the company subnet and use the home gateway for all the other usages</em></li>\n<li>ipsec (pam configuration in /etc/pam.d)</li>\n</ul>\n<p>secrets:</p>\n<ul>\n<li>ipsec.secrets (file with the ipsec PSK) rif. 003-configmap.yaml</li>\n<li>pam_ldap.conf (configuration used by pam module to connect to ldap) rif. 002-secrets.yaml</li>\n</ul>\n<p><em>remember that all secrets files are managed using base64 encoding</em></p>\n<p>When we have multiple files to spread in different locations we have to create some tricks,<br>one is to create symlink in the Dockerfile , however we have to keep the configuration<br>as much as possible agnostic from the Dockerfile.</p>\n<p><em>volume</em> and <em>volumeMounts</em> can help on this topic</p>\n<pre><code>volumeMounts:\n- name: psk\n  mountPath: /etc/ipsec.secrets\n  subPath: psk\n  readOnly: true\n- name: pamldap\n  mountPath: /etc/pam_ldap.conf\n  subPath: pamldap\n- name: strongswan-attr\n  mountPath: /etc/strongswan.d/charon/attr.conf\n  subPath: attr.conf\n- name: strongswan-xauth-pam\n  mountPath: /etc/strongswan.d/charon/xauth-pam.conf\n  subPath: xauth-pam.conf\n- name: strongswan-ipsec\n  mountPath: /etc/pam.d/ipsec\n  subPath: ipsec\n- name: strongswan-ipseconf\n  mountPath: /etc/ipsec.conf\n  subPath: ipsec.conf\nvolumes:\n- name: strongswan-attr\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: attr.conf\n      path: attr.conf\n- name: strongswan-xauth-pam\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: xauth-pam.conf\n      path: xauth-pam.conf\n- name: strongswan-ipsec\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: ipsec\n      path: ipsec\n- name: strongswan-ipseconf\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: ipsec.conf\n      path: ipsec.conf\n- name: psk\n  secret:\n    secretName: strongswan-secret\n- name: pamldap\n  secret:\n    secretName: strongswan-secret\n</code></pre>\n<p>Now we have all configured, we can just run<br><code>kubectl apply -f deploy</code></p>\n<p>We will have soon a pod into strongswan namespace</p>\n<pre><code># kubectl get pods -n strongswan\nNAME                          READY   STATUS    RESTARTS   AGE\nstrongswan-77bfbb9f9f-57hmz   1/1     Running   0          22h\n</code></pre>\n<p>Since the service is configured with nodport we need to enable the default 500 and 4500<br>in our firewall , matching the kubernetes ports 30000-32767, in this this service are</p>\n<pre><code>ports:\n- name: isakmp-udp\n  protocol: UDP\n  nodePort: 30500\n  port: 500\n  targetPort: 500\n- name: ipsec-nat-t\n  protocol: UDP\n  nodePort: 30450\n  port: 4500\n  targetPort: 4500\ntype: NodePort\n</code></pre>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/9a42ba23f208fb8562105b7b19d240bc5e495426/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832372f6d6973632f7374726f6e677377616e5f6669726577616c6c5f6e61742e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/9a42ba23f208fb8562105b7b19d240bc5e495426/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832372f6d6973632f7374726f6e677377616e5f6669726577616c6c5f6e61742e706e67\" data-is-external-image=\"true\"  alt=\"firewall configuration\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584730827/misc/strongswan_firewall_nat.png\"></a></p>\n<p>We can configure our standard client (cisco ipsec client is enough)</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/ace3ff6a96cf31968f11209b7b05fce4ea5487a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733353439332f6d6973632f7374726f6e677377616e5f616e64726f69645f636c69656e742e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/ace3ff6a96cf31968f11209b7b05fce4ea5487a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733353439332f6d6973632f7374726f6e677377616e5f616e64726f69645f636c69656e742e706e67\" data-is-external-image=\"true\"  alt=\"android configuration\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_320/v1584735493/misc/strongswan_android_client.png\"></a></p>\n<pre><code># kubectl logs strongswan-77bfbb9f9f-57hmz -n strongswan\nStarting strongSwan 5.5.1 IPsec [starter]...\nno netkey IPsec stack detected\nno KLIPS IPsec stack detected\nno known IPsec stack detected, ignoring!\ncharon (13) started after 80 ms\n00[DMN] Starting IKE charon daemon (strongSwan 5.5.1, Linux 4.15.0-70-generic, x86_64)\n00[CFG] mapping attribute type split-exclpude failed\n00[CFG] loading ca certificates from '/etc/ipsec.d/cacerts'\n00[CFG] loading aa certificates from '/etc/ipsec.d/aacerts'\n00[CFG] loading ocsp signer certificates from '/etc/ipsec.d/ocspcerts'\n00[CFG] loading attribute certificates from '/etc/ipsec.d/acerts'\n00[CFG] loading crls from '/etc/ipsec.d/crls'\n00[CFG] loading secrets from '/etc/ipsec.secrets'\n00[CFG]   loaded IKE secret for %any\n00[CFG] loaded 0 RADIUS server configurations\n00[CFG] HA config misses local/remote address\n00[LIB] loaded plugins: charon aes rc2 sha2 sha1 md5 random nonce x509 revocation constraints pubkey pkcs1 pkcs7 pkcs8 pkcs12 pgp dnskey sshkey pem openssl fips-prf gmp agent xcbc hmac gcm attr kernel-netlink resolve socket-default connmark farp stroke updown eap-identity eap-aka eap-md5 eap-gtc eap-mschapv2 eap-radius eap-tls eap-ttls eap-tnc xauth-generic xauth-eap xauth-pam tnc-tnccs dhcp lookip error-notify certexpire led addrblock unity\n00[LIB] dropped capabilities, running as uid 0, gid 0\n00[JOB] spawning 16 worker threads\n05[CFG] received stroke: add connection 'roadw'\n05[CFG] adding virtual IP address pool 172.16.17.0/29\n05[CFG] added configuration 'roadw'\n08[NET] received packet: from 10.1.1.1[36312] to 10.1.1.84[500] (756 bytes)\n08[ENC] parsed ID_PROT request 0 [ SA V V V V V V V V ]\n08[IKE] received NAT-T (RFC 3947) vendor ID\n08[IKE] received draft-ietf-ipsec-nat-t-ike-02 vendor ID\n08[IKE] received draft-ietf-ipsec-nat-t-ike-02\\n vendor ID\n08[IKE] received draft-ietf-ipsec-nat-t-ike-00 vendor ID\n08[IKE] received XAuth vendor ID\n08[IKE] received Cisco Unity vendor ID\n08[IKE] received FRAGMENTATION vendor ID\n08[IKE] received DPD vendor ID\n08[IKE] 10.1.1.1 is initiating a Main Mode IKE_SA\n08[ENC] generating ID_PROT response 0 [ SA V V V V ]\n08[NET] sending packet: from 10.1.1.84[500] to 10.1.1.1[36312] (160 bytes)\n05[NET] received packet: from 10.1.1.1[36312] to 10.1.1.84[500] (228 bytes)\n05[ENC] parsed ID_PROT request 0 [ KE No NAT-D NAT-D ]\n05[IKE] local host is behind NAT, sending keep alives\n05[IKE] remote host is behind NAT\n05[ENC] generating ID_PROT response 0 [ KE No NAT-D NAT-D ]\n05[NET] sending packet: from 10.1.1.84[500] to 10.1.1.1[36312] (244 bytes)\n09[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (92 bytes)\n09[ENC] parsed ID_PROT request 0 [ ID HASH ]\n09[CFG] looking for XAuthInitPSK peer configs matching 10.1.1.84...10.1.1.1[100.106.113.62]\n09[CFG] selected peer config \"roadw\"\n09[ENC] generating ID_PROT response 0 [ ID HASH ]\n09[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (92 bytes)\n09[ENC] generating TRANSACTION request 3276308191 [ HASH CPRQ(X_USER X_PWD) ]\n09[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (76 bytes)\n11[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (108 bytes)\n11[ENC] parsed TRANSACTION response 3276308191 [ HASH CPRP(X_USER X_PWD) ]\n11[IKE] PAM authentication of 'lgirardi' successful\n11[IKE] XAuth authentication of 'lgirardi' successful\n11[ENC] generating TRANSACTION request 1380277626 [ HASH CPS(X_STATUS) ]\n11[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (76 bytes)\n10[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (108 bytes)\n10[ENC] parsed INFORMATIONAL_V1 request 4006980307 [ HASH N(INITIAL_CONTACT) ]\n12[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (92 bytes)\n12[ENC] parsed TRANSACTION response 1380277626 [ HASH CPA(X_STATUS) ]\n12[IKE] IKE_SA roadw[1] established between 10.1.1.84[ETHZERO_HOME_VPN]...10.1.1.1[100.106.113.62]\n12[IKE] scheduling rekeying in 86047s\n12[IKE] maximum IKE_SA lifetime 86227s\n</code></pre>\n<p>ok now i'm connected and i can see my network in tun0</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/0ec58f59178a15278c87059d926b2a8b7b2938a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733303936302f6d6973632f7374726f6e677377616e5f636c69656e745f616e64726f69642e6a7067\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/0ec58f59178a15278c87059d926b2a8b7b2938a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733303936302f6d6973632f7374726f6e677377616e5f636c69656e745f616e64726f69642e6a7067\" data-is-external-image=\"true\"  alt=\"android ip\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_320/v1584730960/misc/strongswan_client_android.jpg\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/89492159c8fb5380197b4ecd266dce5c4068a9a0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733363033342f6d6973632f7374726f6e677377616e5f616e64726f69645f70696e672e6a7067\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/89492159c8fb5380197b4ecd266dce5c4068a9a0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733363033342f6d6973632f7374726f6e677377616e5f616e64726f69645f70696e672e6a7067\" data-is-external-image=\"true\"  alt=\"android ping\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_320/v1584736034/misc/strongswan_android_ping.jpg\"></a></p>\n<p>Thats all ... here my connection</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/b702d2df92e56ffae8f754aed08e84ebd4d0595f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733363332382f6d6973632f7374726f6e677377616e5f7374726f6b655f737461747573616c6c2e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/b702d2df92e56ffae8f754aed08e84ebd4d0595f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733363332382f6d6973632f7374726f6e677377616e5f7374726f6b655f737461747573616c6c2e706e67\" data-is-external-image=\"true\"  alt=\"strongswan connection\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584736328/misc/strongswan_stroke_statusall.png\"></a></p>\n</article>\n</div>\n</div>\n</div>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "vpn",
                   "strongswan",
                   "ldap",
                   "kubernetes",
                   "ipsec",
                   "active directory"
            ],
            "date_published": "2020-08-11T20:44:46+02:00",
            "date_modified": "2020-11-14T22:55:59+01:00"
        },
        {
            "id": "https://www.k8s.it/docker-latency.html",
            "url": "https://www.k8s.it/docker-latency.html",
            "title": "Docker-latency",
            "summary": "aka the network blaming toolSo again another grafana stack with docker Well yes but with a precise scope In this period we are almost all working from home, the blaming topic is usually the connection with our offices or the datacenters. Is not so rare&hellip;",
            "content_html": "<h2><a id=\"user-content-aka-the-network-blaming-tool\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#aka-the-network-blaming-tool\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>aka the network blaming tool</h2>\n<p>So again another grafana stack with docker<br>Well yes but with a precise scope</p>\n<p>In this period we are almost all working from home,<br>the blaming topic is usually the connection with our offices or the datacenters.</p>\n<p>Is not so rare for a network Administrator hear people that sais ,<br><em>the vpn is slow</em> , <em>i cannot connect to ... $something</em> , bla bla bla</p>\n<p>In my experience this is usually due to the quality of the provider,<br>sometimes is also a problem on route path on T2/T3 providers</p>\n<h3><a id=\"user-content-how-we-can-undestand-if-our-network-is-really-slow-\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#how-we-can-undestand-if-our-network-is-really-slow-\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>HOW we can undestand if our network is really slow ?</h3>\n<p>The idea is to start a grafana stack ready-made to handle the basics statistics of our internet connection.<br>We need to choose some endpoints to monitor, example , your vpn endpoint , your datacenter/office public ip , the main dns servers and so on</p>\n<h4><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#requirements\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Requirements</h4>\n<ul>\n<li>Docker</li>\n<li>Docker Compose</li>\n</ul>\n<h4><a id=\"user-content-stack\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#stack\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Stack</h4>\n<ul>\n<li>Influxdb</li>\n<li>Grafana</li>\n<li>Telegraf</li>\n</ul>\n<h4><a id=\"user-content-tree\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#tree\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Tree</h4>\n<pre><code>├── .env\n├── Makefile\n├── README.md\n├── docker\n│   ├── grafana\n│   │   ├── Dashboard-PING.json\n│   │   ├── dashboard.yaml\n│   │   └── datasource.yaml\n│   ├── influxdb\n│   │   ├── influxdb.conf\n│   │   \n│   └── telegraf\n│       └── telegraf.conf\n├── docker-compose.yml\n</code></pre>\n<p>Makefile is ... well a makefile , commands allowed<br><em>up , down, dev, down, logs, clean</em><br>up is to startup the stack<br>down to shutdown clean is done to remove also the storage saved for influxdb and grafana</p>\n<p>.env contains the grafana and influxdb credentials (yes the default password is quite complicated)<br>Since this tool is hosted in your laptop (could be everywhere), never mind the <em>security</em></p>\n<pre><code>GRAFANA_USER=admin\nGRAFANA_PASSWORD=EQyFJpjxvJG8k2K8\nINFLUXDB_DOMAIN=influxdb\nINFLUXDB_DATABASE=ping\n</code></pre>\n<h3><a id=\"user-content-configuration\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#configuration\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Configuration</h3>\n<p>We just need to choose the endpoints we'd like to monitor from our internet connection This could be done editing <em>telegraf.conf</em></p>\n<pre><code>[global_tags]\n[agent]\n  interval = \"10s\"\n  round_interval = true\n  metric_batch_size = 1000\n  metric_buffer_limit = 10000\n  collection_jitter = \"0s\"\n  flush_interval = \"10s\"\n  flush_jitter = \"0s\"\n  precision = \"\"\n  hostname = \"local-telegraf\"\n  omit_hostname = false\n[[outputs.influxdb]]\n   urls = [\"http://127.0.0.1:8086\"]\n   database = \"ping\"\n[[inputs.ping]]\nurls = [\"1.1.1.1\", \"8.8.8.8\", \"208.67.222.222\", \"test1.velocable.com\"]\ncount = 7\nping_interval = 1.0\n</code></pre>\n<p>Edit <em>urls =</em> adding / modify the endpoints<br>(in this example, Cloudflare dns , Google dns, opendns, and a server in Madrid used for speedtest)</p>\n<p>The configuration is collecting information every 10 seconds , and run a ping command 7 time each with 1 second delay.</p>\n<h3><a id=\"user-content-startup\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#startup\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Startup</h3>\n<p>Inside the main folder run</p>\n<p><code>make up</code></p>\n<p>output:</p>\n<pre><code>docker-latency$ make up\ndocker-compose -f docker-compose.yml up -d\nCreating network \"docker-latency_default\" with the default driver\nCreating grafana  ... done\nCreating influxdb ... done\nCreating telegraf ... done\n</code></pre>\n<p>login to:<br><code>http://localhost:3000/ </code>admin/EQyFJpjxvJG8k2K8</p>\n<p>you will see</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/56bea14df7a89b07f4e319b45ad4d27c39ad865f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353634313235322f6d6973632f67726166616e615f686f6d652e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/56bea14df7a89b07f4e319b45ad4d27c39ad865f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353634313235322f6d6973632f67726166616e615f686f6d652e706e67\" data-is-external-image=\"true\"  alt=\"grafana_home\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1585641252/misc/grafana_home.png\"></a></p>\n<p>than , checking for the only board present --&gt; <em>internet latency</em></p>\n<p>you will have all details about the endpoint chosen , packet loss especially</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/5fd87b371e34b4497018003fcd41cd2e09d23c72/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353539353832342f6d6973632f67726166616e615f70696e672e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/5fd87b371e34b4497018003fcd41cd2e09d23c72/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353539353832342f6d6973632f67726166616e615f70696e672e706e67\" data-is-external-image=\"true\"  alt=\"grafana_ping\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1585595824/misc/grafana_ping.png\"></a></p>\n<p>100% packet loss simulated disabling network card for few seconds.<br>The dashboard is using variables in order to create 1 row for each endpoint.</p>\n<h3><a id=\"user-content-conclusion\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#conclusion\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion</h3>\n<p>Now we have data, so we know what is going on in our internet connection and we can probably<br>have more details about the <em>infomagic</em> words like ... <em>is slow</em></p>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
            ],
            "date_published": "2020-08-11T20:42:02+02:00",
            "date_modified": "2020-08-11T20:49:02+02:00"
        }
    ]
}
