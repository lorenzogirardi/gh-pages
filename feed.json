{
    "version": "https://jsonfeed.org/version/1",
    "title": "LAB",
    "description": "",
    "home_page_url": "https://www.k8s.it",
    "feed_url": "https://www.k8s.it/feed.json",
    "user_comment": "",
    "author": {
        "name": "lgirardi"
    },
    "items": [
        {
            "id": "https://www.k8s.it/kubernetes-guacamole.html",
            "url": "https://www.k8s.it/kubernetes-guacamole.html",
            "title": "Kubernetes-guacamole",
            "summary": "Here we are , another apache guacamole implementation in kubernetesThis service is designed to avoid the usage of mysql and create a standalone project The main idea is to use the user-mapping.xml as a config map For production environment i suggest to add the ldap auth (ad.openldap,freeipa),&hellip;",
            "content_html": "<div class=\"flex-shrink-0 col-12 col-md-9 mb-4 mb-md-0\">\n<div id=\"readme\" class=\"Box md js-code-block-container Box--responsive\">\n<div class=\"Box-body px-5 pb-5\">\n<article class=\"markdown-body entry-content container-lg\">\n<h2 id=\"mcetoc_1effdgcnt5\">Here we are , another apache guacamole implementation in kubernetes</h2>\n<p>This service is designed to avoid the usage of mysql and create a standalone project</p>\n<p>The main idea is to use the <strong>user-mapping.xml</strong> as a config map</p>\n<p>For production environment i suggest to add the ldap auth (ad.openldap,freeipa),<br>mysql database should be managed with a dedicated instances and mantained in case of \"exit\"</p>\n<h2 id=\"mcetoc_1effdg4pk0\"><a id=\"user-content-what-is-a-bastion-host\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#what-is-a-bastion-host\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>what is a bastion host</h2>\n<p>On the Internet, a bastion host is the only host computer that a company allows to be addressed<br>directly from the public network and that is designed to screen the rest of its network from security exposure.</p>\n<h2 id=\"mcetoc_1effdg4pk1\"><a id=\"user-content-how-this-tool-can-be-used\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#how-this-tool-can-be-used\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>how this tool can be used</h2>\n<p>The tool is designed to be used when you have some dedicated service in production and you have to keep<br>the control of access and account used , guacamole has the ability to manage the most used platforms (windows and linux)<br>as host in backend to be reached from developers ... contractors ...</p>\n<h2 id=\"mcetoc_1effdg4pk2\"><a id=\"user-content-why-in-kubernetes\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#why-in-kubernetes\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>why in kubernetes</h2>\n<p>Since the auth method could scale by configmap or ldap or mysql , is designed to scale<br>we have also the benefits to have a low footprint compared to a traditional vm.</p>\n<h2 id=\"mcetoc_1effdg4pk3\"><a id=\"user-content-config-to-change\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#config-to-change\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>config to change</h2>\n<p>Before deploy you need to specify the following parameters in guacamole folder</p>\n<ul>\n<li>YOUR_DOMAIN to reflect your domain url in 03-guacamole-ing.yaml</li>\n<li>user YOUR_USERNAME / YOUR_MD5_PWD and hosts xml configuration in 04-guacamole-cfm.yaml following <a href=\"https://guacamole.apache.org/doc/gug/configuring-guacamole.html#user-mapping\" rel=\"nofollow\">https://guacamole.apache.org/doc/gug/configuring-guacamole.html#user-mapping</a></li>\n</ul>\n<p>screenshots</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/905e74d0ce81c8b239f67d405567100a3f181292/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d77696e2e706e67\"><img src=\"https://camo.githubusercontent.com/905e74d0ce81c8b239f67d405567100a3f181292/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d77696e2e706e67\" alt=\"windows\" ></a><br><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/fd53b1991cd9693679aae9aadf72bc75d025c2ad/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d6c696e75782e706e67\"><img src=\"https://camo.githubusercontent.com/fd53b1991cd9693679aae9aadf72bc75d025c2ad/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d6c696e75782e706e67\" alt=\"linux\" ></a></p>\n<h2 id=\"mcetoc_1effdg4pk4\"><a id=\"user-content-deploy\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#deploy\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>deploy</h2>\n<p id=\"mcetoc_1effdgp3l6\"><code>kubectl apply -f guacd</code></p>\n<p id=\"mcetoc_1effdgsfc7\"><code>kubectl apply -f guacamole</code></p>\n<p>You can secure the connection with kube-lego and use cillium to add network rules </p>\n</article>\n</div>\n</div>\n</div>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
            ],
            "date_published": "2020-08-11T20:46:54+02:00",
            "date_modified": "2020-08-11T20:46:54+02:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-strongswan.html",
            "url": "https://www.k8s.it/kubernetes-strongswan.html",
            "title": "Kubernetes-strongswan",
            "summary": "How we can manage vpn in kubernetes environmentHi there , this project is to cover the vpn ipsec-xauth topic in a kubernetes evironment, the goal of this is to have the less effort possible when we have to manage users. Architecture Requirements: WHYThe traditional ipsec-xauth&hellip;",
            "content_html": "<div class=\"flex-shrink-0 col-12 col-md-9 mb-4 mb-md-0\">\n<div id=\"readme\" class=\"Box md js-code-block-container Box--responsive\">\n<div class=\"Box-body px-5 pb-5\">\n<article class=\"markdown-body entry-content container-lg\">\n<h2 id=\"mcetoc_1effdcouu0\">How we can manage vpn in kubernetes environment</h2>\n<p>Hi there , this project is to cover the vpn ipsec-xauth topic in a kubernetes evironment,<br>the goal of this is to have the less effort possible when we have to manage users.</p>\n<p>Architecture<br><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/ee7bbe0fe8e2f17b0bda45b6b92d585105d9adcc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538343733313733352f6d6973632f76706e5f6469616772616d2e6a7067\"><img src=\"https://camo.githubusercontent.com/ee7bbe0fe8e2f17b0bda45b6b92d585105d9adcc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538343733313733352f6d6973632f76706e5f6469616772616d2e6a7067\" alt=\"architecture\" ></a></p>\n<p>Requirements:</p>\n<ul>\n<li>Kubernetes</li>\n<li>Strongswan</li>\n<li>Microsoft Acrive Directory / openldap / freeipa etc etc LDAP (i'll use ldap instead the software name)</li>\n</ul>\n<h2 id=\"mcetoc_1effdcouu1\"><a id=\"user-content-why\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-strongswan#why\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>WHY</h2>\n<p>The traditional ipsec-xauth vpn with ikev1 is based on PSK<br>and a client username/password , this is a problem when the credential are stored in a file<br>in kubernetes update a file always mean rollout a new deploy or create a procedure to<br>make effective the changes.<br>So the idea is to deploy something that doesn't need any interaction<br>after the deploy and manage the clients, with the company standards,<br>like password expiration, password complexity, groups attributions and so on.</p>\n<h2 id=\"mcetoc_1effdcouu2\"><a id=\"user-content-how\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-strongswan#how\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>HOW</h2>\n<p>In order to have a fully managed services we can leverage the usage of ldap procedures (that all company has).<br>Strongswan (a fork of *swan ipsec software) could be integrated with ldap with pam.<br>pam is ... well --&gt; <a href=\"https://tldp.org/HOWTO/User-Authentication-HOWTO/x115.html\" rel=\"nofollow\">https://tldp.org/HOWTO/User-Authentication-HOWTO/x115.html</a></p>\n<p>So what we need in ldap ?<br>We need:</p>\n<ul>\n<li>a technical user that is a low level profile that will be used only to check the users inside the ldap tree and the groups associated</li>\n<li>a group to associate to people who need/granted the vpn access</li>\n</ul>\n<p>in this scenario tech users is --&gt; <em>ldapbind</em><br>group is --&gt; <em>vpn</em></p>\n<p>here some screen related</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/48427e34136d63b4b7348ba8c2148e178665cdf0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f62696e645f757365722e706e67\"><img src=\"https://camo.githubusercontent.com/48427e34136d63b4b7348ba8c2148e178665cdf0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f62696e645f757365722e706e67\" alt=\"ldapbind\" ></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/141e29aaed92e477719b517dd704c815b18c23bc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f757365725f76706e5f67726f75702e706e67\"><img src=\"https://camo.githubusercontent.com/141e29aaed92e477719b517dd704c815b18c23bc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f757365725f76706e5f67726f75702e706e67\" alt=\"vpn group\" ></a></p>\n<p>Then... now we have to configure configure the Docker image in order to support pam ldap.</p>\n<p>Dockerfile</p>\n<pre><code>FROM debian:stretch\nMAINTAINER lgirardi &lt;l@k8s.it&gt;\n\n\nRUN apt-get -y update &amp;&amp; apt-get -yq install \\\n        strongswan \\\n        libcharon-extra-plugins \\\n        iptables \\\n        kmod \\\n        libpam-ldap \\\n        vim\n\nEXPOSE 500/udp 4500/udp\n\nCMD /usr/sbin/ipsec start --nofork\n</code></pre>\n<p>libpam-ldap and libcharon-extra-plugins are what we need to perform this kind of integration.</p>\n<p>Since strongswan is not traditionally used in kubernetes , has some files that needs a configuration.<br>ENV variables are the most useful to configure it,<br>unfortunately the process is not able to share the env this the child process,<br>so we will work with 2 concepts,<br>use the configmap for all files we need to configure use the secrets for all sensitive data we need to add</p>\n<p>files configured:</p>\n<ul>\n<li>ipsec.conf (the strongswan main configuration)</li>\n<li>xauth-pam.conf (strongswan configuration to enable pam)</li>\n<li>attr.conf (strongswan configuration file for split-tunnel)<br><em>split-tunnel is when you want to move in vpn only the company subnet and use the home gateway for all the other usages</em></li>\n<li>ipsec (pam configuration in /etc/pam.d)</li>\n</ul>\n<p>secrets:</p>\n<ul>\n<li>ipsec.secrets (file with the ipsec PSK) rif. 003-configmap.yaml</li>\n<li>pam_ldap.conf (configuration used by pam module to connect to ldap) rif. 002-secrets.yaml</li>\n</ul>\n<p><em>remember that all secrets files are managed using base64 encoding</em></p>\n<p>When we have multiple files to spread in different locations we have to create some tricks,<br>one is to create symlink in the Dockerfile , however we have to keep the configuration<br>as much as possible agnostic from the Dockerfile.</p>\n<p><em>volume</em> and <em>volumeMounts</em> can help on this topic</p>\n<pre><code>volumeMounts:\n- name: psk\n  mountPath: /etc/ipsec.secrets\n  subPath: psk\n  readOnly: true\n- name: pamldap\n  mountPath: /etc/pam_ldap.conf\n  subPath: pamldap\n- name: strongswan-attr\n  mountPath: /etc/strongswan.d/charon/attr.conf\n  subPath: attr.conf\n- name: strongswan-xauth-pam\n  mountPath: /etc/strongswan.d/charon/xauth-pam.conf\n  subPath: xauth-pam.conf\n- name: strongswan-ipsec\n  mountPath: /etc/pam.d/ipsec\n  subPath: ipsec\n- name: strongswan-ipseconf\n  mountPath: /etc/ipsec.conf\n  subPath: ipsec.conf\nvolumes:\n- name: strongswan-attr\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: attr.conf\n      path: attr.conf\n- name: strongswan-xauth-pam\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: xauth-pam.conf\n      path: xauth-pam.conf\n- name: strongswan-ipsec\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: ipsec\n      path: ipsec\n- name: strongswan-ipseconf\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: ipsec.conf\n      path: ipsec.conf\n- name: psk\n  secret:\n    secretName: strongswan-secret\n- name: pamldap\n  secret:\n    secretName: strongswan-secret\n</code></pre>\n<p>Now we have all configured, we can just run<br><code>kubectl apply -f deploy</code></p>\n<p>We will have soon a pod into strongswan namespace</p>\n<pre><code># kubectl get pods -n strongswan\nNAME                          READY   STATUS    RESTARTS   AGE\nstrongswan-77bfbb9f9f-57hmz   1/1     Running   0          22h\n</code></pre>\n<p>Since the service is configured with nodport we need to enable the default 500 and 4500<br>in our firewall , matching the kubernetes ports 30000-32767, in this this service are</p>\n<pre><code>ports:\n- name: isakmp-udp\n  protocol: UDP\n  nodePort: 30500\n  port: 500\n  targetPort: 500\n- name: ipsec-nat-t\n  protocol: UDP\n  nodePort: 30450\n  port: 4500\n  targetPort: 4500\ntype: NodePort\n</code></pre>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/9a42ba23f208fb8562105b7b19d240bc5e495426/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832372f6d6973632f7374726f6e677377616e5f6669726577616c6c5f6e61742e706e67\"><img src=\"https://camo.githubusercontent.com/9a42ba23f208fb8562105b7b19d240bc5e495426/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832372f6d6973632f7374726f6e677377616e5f6669726577616c6c5f6e61742e706e67\" alt=\"firewall configuration\" ></a></p>\n<p>We can configure our standard client (cisco ipsec client is enough)</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/ace3ff6a96cf31968f11209b7b05fce4ea5487a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733353439332f6d6973632f7374726f6e677377616e5f616e64726f69645f636c69656e742e706e67\"><img src=\"https://camo.githubusercontent.com/ace3ff6a96cf31968f11209b7b05fce4ea5487a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733353439332f6d6973632f7374726f6e677377616e5f616e64726f69645f636c69656e742e706e67\" alt=\"android configuration\" ></a></p>\n<pre><code># kubectl logs strongswan-77bfbb9f9f-57hmz -n strongswan\nStarting strongSwan 5.5.1 IPsec [starter]...\nno netkey IPsec stack detected\nno KLIPS IPsec stack detected\nno known IPsec stack detected, ignoring!\ncharon (13) started after 80 ms\n00[DMN] Starting IKE charon daemon (strongSwan 5.5.1, Linux 4.15.0-70-generic, x86_64)\n00[CFG] mapping attribute type split-exclpude failed\n00[CFG] loading ca certificates from '/etc/ipsec.d/cacerts'\n00[CFG] loading aa certificates from '/etc/ipsec.d/aacerts'\n00[CFG] loading ocsp signer certificates from '/etc/ipsec.d/ocspcerts'\n00[CFG] loading attribute certificates from '/etc/ipsec.d/acerts'\n00[CFG] loading crls from '/etc/ipsec.d/crls'\n00[CFG] loading secrets from '/etc/ipsec.secrets'\n00[CFG]   loaded IKE secret for %any\n00[CFG] loaded 0 RADIUS server configurations\n00[CFG] HA config misses local/remote address\n00[LIB] loaded plugins: charon aes rc2 sha2 sha1 md5 random nonce x509 revocation constraints pubkey pkcs1 pkcs7 pkcs8 pkcs12 pgp dnskey sshkey pem openssl fips-prf gmp agent xcbc hmac gcm attr kernel-netlink resolve socket-default connmark farp stroke updown eap-identity eap-aka eap-md5 eap-gtc eap-mschapv2 eap-radius eap-tls eap-ttls eap-tnc xauth-generic xauth-eap xauth-pam tnc-tnccs dhcp lookip error-notify certexpire led addrblock unity\n00[LIB] dropped capabilities, running as uid 0, gid 0\n00[JOB] spawning 16 worker threads\n05[CFG] received stroke: add connection 'roadw'\n05[CFG] adding virtual IP address pool 172.16.17.0/29\n05[CFG] added configuration 'roadw'\n08[NET] received packet: from 10.1.1.1[36312] to 10.1.1.84[500] (756 bytes)\n08[ENC] parsed ID_PROT request 0 [ SA V V V V V V V V ]\n08[IKE] received NAT-T (RFC 3947) vendor ID\n08[IKE] received draft-ietf-ipsec-nat-t-ike-02 vendor ID\n08[IKE] received draft-ietf-ipsec-nat-t-ike-02\\n vendor ID\n08[IKE] received draft-ietf-ipsec-nat-t-ike-00 vendor ID\n08[IKE] received XAuth vendor ID\n08[IKE] received Cisco Unity vendor ID\n08[IKE] received FRAGMENTATION vendor ID\n08[IKE] received DPD vendor ID\n08[IKE] 10.1.1.1 is initiating a Main Mode IKE_SA\n08[ENC] generating ID_PROT response 0 [ SA V V V V ]\n08[NET] sending packet: from 10.1.1.84[500] to 10.1.1.1[36312] (160 bytes)\n05[NET] received packet: from 10.1.1.1[36312] to 10.1.1.84[500] (228 bytes)\n05[ENC] parsed ID_PROT request 0 [ KE No NAT-D NAT-D ]\n05[IKE] local host is behind NAT, sending keep alives\n05[IKE] remote host is behind NAT\n05[ENC] generating ID_PROT response 0 [ KE No NAT-D NAT-D ]\n05[NET] sending packet: from 10.1.1.84[500] to 10.1.1.1[36312] (244 bytes)\n09[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (92 bytes)\n09[ENC] parsed ID_PROT request 0 [ ID HASH ]\n09[CFG] looking for XAuthInitPSK peer configs matching 10.1.1.84...10.1.1.1[100.106.113.62]\n09[CFG] selected peer config \"roadw\"\n09[ENC] generating ID_PROT response 0 [ ID HASH ]\n09[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (92 bytes)\n09[ENC] generating TRANSACTION request 3276308191 [ HASH CPRQ(X_USER X_PWD) ]\n09[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (76 bytes)\n11[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (108 bytes)\n11[ENC] parsed TRANSACTION response 3276308191 [ HASH CPRP(X_USER X_PWD) ]\n11[IKE] PAM authentication of 'lgirardi' successful\n11[IKE] XAuth authentication of 'lgirardi' successful\n11[ENC] generating TRANSACTION request 1380277626 [ HASH CPS(X_STATUS) ]\n11[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (76 bytes)\n10[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (108 bytes)\n10[ENC] parsed INFORMATIONAL_V1 request 4006980307 [ HASH N(INITIAL_CONTACT) ]\n12[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (92 bytes)\n12[ENC] parsed TRANSACTION response 1380277626 [ HASH CPA(X_STATUS) ]\n12[IKE] IKE_SA roadw[1] established between 10.1.1.84[ETHZERO_HOME_VPN]...10.1.1.1[100.106.113.62]\n12[IKE] scheduling rekeying in 86047s\n12[IKE] maximum IKE_SA lifetime 86227s\n</code></pre>\n<p>ok now i'm connected and i can see my network in tun0</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/0ec58f59178a15278c87059d926b2a8b7b2938a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733303936302f6d6973632f7374726f6e677377616e5f636c69656e745f616e64726f69642e6a7067\"><img src=\"https://camo.githubusercontent.com/0ec58f59178a15278c87059d926b2a8b7b2938a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733303936302f6d6973632f7374726f6e677377616e5f636c69656e745f616e64726f69642e6a7067\" alt=\"android ip\" ></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/89492159c8fb5380197b4ecd266dce5c4068a9a0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733363033342f6d6973632f7374726f6e677377616e5f616e64726f69645f70696e672e6a7067\"><img src=\"https://camo.githubusercontent.com/89492159c8fb5380197b4ecd266dce5c4068a9a0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733363033342f6d6973632f7374726f6e677377616e5f616e64726f69645f70696e672e6a7067\" alt=\"android ping\" ></a></p>\n<p>Thats all ... here my connection</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/b702d2df92e56ffae8f754aed08e84ebd4d0595f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733363332382f6d6973632f7374726f6e677377616e5f7374726f6b655f737461747573616c6c2e706e67\"><img src=\"https://camo.githubusercontent.com/b702d2df92e56ffae8f754aed08e84ebd4d0595f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733363332382f6d6973632f7374726f6e677377616e5f7374726f6b655f737461747573616c6c2e706e67\" alt=\"strongswan connection\" ></a></p>\n</article>\n</div>\n</div>\n</div>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
            ],
            "date_published": "2020-08-11T20:44:46+02:00",
            "date_modified": "2020-08-11T20:47:06+02:00"
        },
        {
            "id": "https://www.k8s.it/docker-latency.html",
            "url": "https://www.k8s.it/docker-latency.html",
            "title": "docker-latency",
            "summary": "aka the network blaming toolSo again another grafana stack with docker Well yes but with a precise scope In this period we are almost all working from home, the blaming topic is usually the connection with our offices or the datacenters. Is not so rare&hellip;",
            "content_html": "<h2 id=\"mcetoc_1effd75jsc\"><a id=\"user-content-aka-the-network-blaming-tool\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#aka-the-network-blaming-tool\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>aka the network blaming tool</h2>\n<p>So again another grafana stack with docker<br>Well yes but with a precise scope</p>\n<p>In this period we are almost all working from home,<br>the blaming topic is usually the connection with our offices or the datacenters.</p>\n<p>Is not so rare for a network Administrator hear people that sais ,<br><em>the vpn is slow</em> , <em>i cannot connect to ... $something</em> , bla bla bla</p>\n<p>In my experience this is usually due to the quality of the provider,<br>sometimes is also a problem on route path on T2/T3 providers</p>\n<h3 id=\"mcetoc_1effd75jte\"><a id=\"user-content-how-we-can-undestand-if-our-network-is-really-slow-\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#how-we-can-undestand-if-our-network-is-really-slow-\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>HOW we can undestand if our network is really slow ?</h3>\n<p>The idea is to start a grafana stack ready-made to handle the basics statistics of our internet connection.<br>We need to choose some endpoints to monitor, example , your vpn endpoint , your datacenter/office public ip , the main dns servers and so on</p>\n<h4 id=\"mcetoc_1effd75jtf\"><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#requirements\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Requirements</h4>\n<ul>\n<li>Docker</li>\n<li>Docker Compose</li>\n</ul>\n<h4 id=\"mcetoc_1effd75jtg\"><a id=\"user-content-stack\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#stack\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Stack</h4>\n<ul>\n<li>Influxdb</li>\n<li>Grafana</li>\n<li>Telegraf</li>\n</ul>\n<h4 id=\"mcetoc_1effd75jth\"><a id=\"user-content-tree\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#tree\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Tree</h4>\n<pre><code>├── .env\n├── Makefile\n├── README.md\n├── docker\n│   ├── grafana\n│   │   ├── Dashboard-PING.json\n│   │   ├── dashboard.yaml\n│   │   └── datasource.yaml\n│   ├── influxdb\n│   │   ├── influxdb.conf\n│   │   \n│   └── telegraf\n│       └── telegraf.conf\n├── docker-compose.yml\n</code></pre>\n<p>Makefile is ... well a makefile , commands allowed<br><em>up , down, dev, down, logs, clean</em><br>up is to startup the stack<br>down to shutdown clean is done to remove also the storage saved for influxdb and grafana</p>\n<p>.env contains the grafana and influxdb credentials (yes the default password is quite complicated)<br>Since this tool is hosted in your laptop (could be everywhere), never mind the <em>security</em></p>\n<pre><code>GRAFANA_USER=admin\nGRAFANA_PASSWORD=EQyFJpjxvJG8k2K8\nINFLUXDB_DOMAIN=influxdb\nINFLUXDB_DATABASE=ping\n</code></pre>\n<h3 id=\"mcetoc_1effd75jti\"><a id=\"user-content-configuration\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#configuration\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Configuration</h3>\n<p>We just need to choose the endpoints we'd like to monitor from our internet connection This could be done editing <em>telegraf.conf</em></p>\n<pre><code>[global_tags]\n[agent]\n  interval = \"10s\"\n  round_interval = true\n  metric_batch_size = 1000\n  metric_buffer_limit = 10000\n  collection_jitter = \"0s\"\n  flush_interval = \"10s\"\n  flush_jitter = \"0s\"\n  precision = \"\"\n  hostname = \"local-telegraf\"\n  omit_hostname = false\n[[outputs.influxdb]]\n   urls = [\"http://127.0.0.1:8086\"]\n   database = \"ping\"\n[[inputs.ping]]\nurls = [\"1.1.1.1\", \"8.8.8.8\", \"208.67.222.222\", \"test1.velocable.com\"]\ncount = 7\nping_interval = 1.0\n</code></pre>\n<p>Edit <em>urls =</em> adding / modify the endpoints<br>(in this example, Cloudflare dns , Google dns, opendns, and a server in Madrid used for speedtest)</p>\n<p>The configuration is collecting information every 10 seconds , and run a ping command 7 time each with 1 second delay.</p>\n<h3 id=\"mcetoc_1effd75jtj\"><a id=\"user-content-startup\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#startup\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Startup</h3>\n<p>Inside the main folder run</p>\n<p><code>make up</code></p>\n<p>output:</p>\n<pre><code>docker-latency$ make up\ndocker-compose -f docker-compose.yml up -d\nCreating network \"docker-latency_default\" with the default driver\nCreating grafana  ... done\nCreating influxdb ... done\nCreating telegraf ... done\n</code></pre>\n<p>login to:<br><code>http://localhost:3000/ </code>admin/EQyFJpjxvJG8k2K8</p>\n<p>you will see</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/56bea14df7a89b07f4e319b45ad4d27c39ad865f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353634313235322f6d6973632f67726166616e615f686f6d652e706e67\"><img src=\"https://camo.githubusercontent.com/56bea14df7a89b07f4e319b45ad4d27c39ad865f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353634313235322f6d6973632f67726166616e615f686f6d652e706e67\" alt=\"grafana_home\" ></a></p>\n<p>than , checking for the only board present --&gt; <em>internet latency</em></p>\n<p>you will have all details about the endpoint chosen , packet loss especially</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/5fd87b371e34b4497018003fcd41cd2e09d23c72/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353539353832342f6d6973632f67726166616e615f70696e672e706e67\"><img src=\"https://camo.githubusercontent.com/5fd87b371e34b4497018003fcd41cd2e09d23c72/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353539353832342f6d6973632f67726166616e615f70696e672e706e67\" alt=\"grafana_ping\" ></a></p>\n<p>100% packet loss simulated disabling network card for few seconds.<br>The dashboard is using variables in order to create 1 row for each endpoint.</p>\n<h3 id=\"mcetoc_1effd75jtk\"><a id=\"user-content-conclusion\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#conclusion\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion</h3>\n<p>Now we have data, so we know what is going on in our internet connection and we can probably<br>have more details about the <em>infomagic</em> words like ... <em>is slow</em></p>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
            ],
            "date_published": "2020-08-11T20:42:02+02:00",
            "date_modified": "2020-08-11T20:42:02+02:00"
        },
        {
            "id": "https://www.k8s.it/terraform-your-free-claudflare-account.html",
            "url": "https://www.k8s.it/terraform-your-free-claudflare-account.html",
            "title": "Terraform your free Claudflare account",
            "summary": "So... after some experience with akamai www.ethzero.it is an alias for aku-cs-akamaiflowers.com.edgesuite.net. aku-cs-akamaiflowers.com.edgesuite.net is an alias for a169.dscksd.akamai.net. a169.dscksd.akamai.net has address 193.45.15.98 a169.dscksd.akamai.net has address 193.45.15.122 a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f62 a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f7aand some others with Incapsula bunker.ethzero.it is an alias for&hellip;",
            "content_html": "<p>So...</p>\n<p>after some experience with akamai </p>\n<pre><code><em>www.ethzero.it is an alias for aku-cs-akamaiflowers.com.edgesuite.net.</em></code><br><code><em>aku-cs-akamaiflowers.com.edgesuite.net is an alias for a169.dscksd.akamai.net.</em></code><br><code><em>a169.dscksd.akamai.net has address 193.45.15.98</em></code><br><code><em>a169.dscksd.akamai.net has address 193.45.15.122</em></code><br><code><em>a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f62</em></code><br><code><em>a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f7a</em></code></pre>\n<p>and some others with Incapsula</p>\n<pre><code><em>bunker.ethzero.it is an alias for ve7cu.x.incapdns.net.</em></code><br><code><em>ve7cu.x.incapdns.net has address 107.154.167.38</em></code></pre>\n<p>It's now the moment to talk about Cloudflare</p>\n<p> <a href=\"https://www.cloudflare.com/\">Claudflare</a> provide a good free account that allow you to hide your source ip or you want to discover how it's work the free waf protection or have a https certificate having your origin in http and so on ... but what is really cool and quickwin than the competitors is the API support and the native integration with <a href=\"https://www.terraform.io/docs/providers/cloudflare/index.html\">Terraform</a></p>\n<p><img src=\"https://www.k8s.it/media/posts/5/git-terraform-cloudflare.png\" alt=\"\" width=\"2394\" height=\"1254\"></p>\n<p>Terraform is the most integrated tool for cloud (not only) automation and infrastructure as a code </p>\n<p>Here some steps that can show how it's esay deploy a configuration</p>\n<p>First of all , retrive the api key from Cloudflare portal</p>\n<p><img src=\"https://www.k8s.it/media/posts/5/cloudflare-api-key.png\" alt=\"\" width=\"1922\" height=\"556\"></p>\n<p><img src=\"https://www.k8s.it/media/posts/5/cloudflare-global-apikey.png\" alt=\"\" width=\"1910\" height=\"396\"> </p>\n<p>then start the main terraform file in a dedicated folder (better in a <a href=\"https://gitlab.com/\">gitlab</a> repo)</p>\n<pre><code>$ cat cloudflare-auth.tf</code><code><br>provider \"cloudflare\" {<br> email = \"cloudflare_registration_email\"<br> token = \"cloudflare_token_api_key\"<br>}<br></code></pre>\n<p>make a $<code>terraform init</code> and now you can start to configure your account</p>\n<p>manage your domain(s)</p>\n<pre>$ <code>cat cloudflare_domains.tf</code><br><code>variable \"domain\" {</code><br><code> default = \"k8s.it\"</code><br><code>} </code></pre>\n<p> </p>\n<p>create dns configuration</p>\n<pre>$ <code>cat cloudflare_dns.tf</code><br><code>resource \"cloudflare_record\" \"www\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"www\"</code><br><code> value = \"something.github.io\"</code><br><code> type = \"CNAME\"</code><br><code> proxied = true</code><br><code>}</code><br><br><code>resource \"cloudflare_record\" \"smtp\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"smtp\"</code><br><code> value = \"IP.OF.PRIVATE.VPS\"</code><br><code> type = \"A\"</code><br><code> proxied = false</code><br><code>}</code><br><br><code>resource \"cloudflare_record\" \"services\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"services\"</code><br><code> value = \"something.related.to.my.home\"</code><br><code> type = \"CNAME\"</code><br><code> proxied = true</code><br><code>}</code><br><br><code>resource \"cloudflare_record\" \"mx\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"${var.domain}\"</code><br><code> value = \"smtp.k8s.it\"</code><br><code> type = \"MX\"</code><br><code> priority = \"1\"</code><br><code>}</code><br><br><code>resource \"cloudflare_record\" \"google-verification\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"${var.domain}\"</code><br><code> value = \"google-site-verification=fdsfdssgfdg4teurtxh\"</code><br><code> type = \"TXT\"</code><br><code>}</code><br><br><code>resource \"cloudflare_record\" \"spf\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"${var.domain}\"</code><br><code> value = \"v=spf1 ip4:IP.OF.PRIVATE.VPS mx ~all\"</code><br><code> type = \"TXT\"</code><br><code>}</code></pre>\n<p>Force the HTTPS with page rules</p>\n<pre>$ <code>cat cloudflare_rules.tf</code><br><code>resource \"cloudflare_page_rule\" \"always_use_https_www\" {</code><br><code> zone = \"${var.domain}\"</code><br><code> target = \"http://www.${var.domain}/*\"</code><br><code> priority = 1</code><br><br><code> actions = {</code><br><code> always_use_https = \"true\",</code><br><code> }</code><br><code>}</code><br><br><code>resource \"cloudflare_page_rule\" \"always_use_https_services\" {</code><br><code> zone = \"${var.domain}\"</code><br><code> target = \"http://services.${var.domain}/*\"</code><br><code> priority = 2</code><br><br><code> actions = {</code><br><code> always_use_https = \"true\",</code><br><code> }</code><br><code>}</code></pre>\n<p>And finally create the common zone settings </p>\n<pre>$ <code>cat cloudflare_zone.tf</code><br><code>resource \"cloudflare_zone_settings_override\" \"k8s-settings\" {</code><br><code> name = \"${var.domain}\"</code><br><br><code> settings {</code><br><code> tls_1_3 = \"on\"</code><br><code> ssl = \"flexible\"</code><br><code> opportunistic_encryption = \"on\"</code><br><code> brotli = \"on\"</code><br><code> automatic_https_rewrites = \"on\"</code><br><code> security_level = \"medium\"</code><br><code> minify {</code><br><code> css = \"on\"</code><br><code> js = \"on\"</code><br><code> html = \"on\"</code><br><code> }</code><br><code> browser_cache_ttl = \"14400\"</code><br><code> }</code><br><code>}</code></pre>\n<p>use the terraform plan to check if everything it's of and terrafom plan to apply the changes</p>\n<pre>$ <code>terraform apply</code><br><code>cloudflare_record.mx: Refreshing state... (ID: c3624cc8fd163199ec082649a55f337a)</code><br><code>cloudflare_record.services: Refreshing state... (ID: 09041dfd16cbbf3b6915e79b14dc5466)</code><br><code>cloudflare_page_rule.always_use_https_services: Refreshing state... (ID: 92e196e6c7c8cba1f0759a60d713b0b9)</code><br><code>cloudflare_record.spf: Refreshing state... (ID: 3743b9f0be0a2c7a69245e169cf06ea5)</code><br><code>cloudflare_zone_settings_override.k8s-settings: Refreshing state... (ID: d4acc5e5713a0dede4f238b829f98947)</code><br><code>cloudflare_record.smtp: Refreshing state... (ID: 2d4628fc07c491d97e34b07da9ec60db)</code><br><code>cloudflare_page_rule.always_use_https_www: Refreshing state... (ID: 59c25cdd1096177a1019f834178de62f)</code><br><code>cloudflare_record.google-verification: Refreshing state... (ID: 131f35a9f8d2304a786a780db38b37e0)</code><br><code>cloudflare_record.www: Refreshing state... (ID: 76e3906f5ea172b627bed4922ebc1da7)</code><br><br><code>Apply complete! Resources: 0 added, 0 changed, 0 destroyed.</code></pre>\n<p> </p>\n<pre>$ <code>host www.k8s.it</code><br><code>www.k8s.it has address 104.27.164.146</code><br><code>www.k8s.it has address 104.27.165.146</code><br><code>www.k8s.it has IPv6 address 2400:cb00:2048:1::681b:a492</code><br><code>www.k8s.it has IPv6 address 2400:cb00:2048:1::681b:a592</code></pre>\n<pre>$ <code>echo | openssl s_client -servername www.k8s.it -connect www.k8s.it:443</code><br><code>CONNECTED(00000003)</code><br><code>depth=2 C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA Limited, CN = COMODO ECC Certification Authority</code><br><code>---</code><br><code>Certificate chain</code><br><code> 0 s:/OU=Domain Control Validated/OU=PositiveSSL Multi-Domain/CN=sni154797.cloudflaressl.com</code><br><code> i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Domain Validation Secure Server CA 2</code><br><code> 1 s:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Domain Validation Secure Server CA 2</code><br><code> i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Certification Authority</code><br><code> 2 s:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Certification Authority</code><br><code> i:/C=SE/O=AddTrust AB/OU=AddTrust External TTP Network/CN=AddTrust External CA Root</code></pre>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "waf",
                   "terraform",
                   "gitlab",
                   "cloudflare",
                   "cdn",
                   "automation"
            ],
            "date_published": "2018-07-06T22:10:34+02:00",
            "date_modified": "2018-07-07T11:47:37+02:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-for-mere-mortals.html",
            "url": "https://www.k8s.it/kubernetes-for-mere-mortals.html",
            "title": "Kubernetes for mere mortals",
            "summary": "Well, what do you need to build your homemade cluster? armbian 4.10.1 kubeadm and kubelet 1.6.4 traefik as a ingress controller heapster, collectd, influxdb and grafana as a monitoring stack NAMESPACE NAME READY STATUS RESTARTS AGEhome-prd k8s-helloworld-3468567185-2fwhb 1/1 Running 0 10dhome-prd k8s-helloworld-3468567185-lbgpk 1/1 Running 2&hellip;",
            "content_html": "<p>Well, what do you need to build your homemade cluster?</p>\n<p><img src=\"https://www.k8s.it/media/posts/3/k8s.arm-lg.jpeg\" alt=\"\" width=\"744\" height=\"400\"></p>\n<p><img src=\"https://www.k8s.it/media/posts/3/IMG_20170605_150237.jpg\" alt=\"\" width=\"832\" height=\"624\"></p>\n<ul>\n<li>1x usb hub Anker 60W PowerPort 6</li>\n<li>4x orangepi plus 2e</li>\n</ul>\n<p> armbian 4.10.1 </p>\n<p>kubeadm and kubelet 1.6.4</p>\n<p>traefik as a ingress controller</p>\n<p>heapster, collectd, influxdb and grafana as a monitoring stack</p>\n<div class=\"slate-resizable-image-embed slate-image-embed__resize-full-width\"><img src=\"https://media.licdn.com/dms/image/C5612AQFJsWW1J0HYig/article-inline_image-shrink_1500_2232/0?e=2122596000&amp;v=beta&amp;t=O4agFAs9-5g0xGt6frAU-koLZROOeVmv2p7yhmZyEAY\"  ></div>\n<p> </p>\n<div class=\"slate-resizable-image-embed slate-image-embed__resize-full-width\"><img src=\"https://media.licdn.com/dms/image/C4E12AQFGmg6f2D2CcQ/article-inline_image-shrink_1000_1488/0?e=2122596000&amp;v=beta&amp;t=H2Sp0_RJzeKQLmbD7JiF6jW-bqdvqkgRzPTmXqhogpI\"  ></div>\n<pre spellcheck=\"false\">NAMESPACE     NAME                                        READY     STATUS    RESTARTS   AGE\nhome-prd      k8s-helloworld<span class=\"hljs-number\">-3468567185-2f</span>whb             <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">10d</span>\nhome-prd      k8s-helloworld<span class=\"hljs-number\">-3468567185</span>-lbgpk             <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">2</span>          <span class=\"hljs-number\">73d</span>\nhome-prd      k8s-helloworld<span class=\"hljs-number\">-3468567185</span>-vz9n5             <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">2</span>          <span class=\"hljs-number\">73d</span>\nkube-system   etcd-k8s-node001                            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">19</span>         <span class=\"hljs-number\">81d</span>\nkube-system   heapster<span class=\"hljs-number\">-3703175019-7f</span>z27                   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">2</span>          <span class=\"hljs-number\">76d</span>\nkube-system   kube-apiserver-k8s-node001                  <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">8</span>          <span class=\"hljs-number\">81d</span>\nkube-system   kube-controller-manager-k8s-node001         <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">22</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kube-dns<span class=\"hljs-number\">-279829092</span>-r8595                    <span class=\"hljs-number\">3</span>/<span class=\"hljs-number\">3</span>       Running   <span class=\"hljs-number\">39</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kube-flannel-ds<span class=\"hljs-number\">-08</span>z1k                       <span class=\"hljs-number\">2</span>/<span class=\"hljs-number\">2</span>       Running   <span class=\"hljs-number\">44</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kube-flannel-ds<span class=\"hljs-number\">-3</span>bqmf                       <span class=\"hljs-number\">2</span>/<span class=\"hljs-number\">2</span>       Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">10d</span>\nkube-system   kube-flannel-ds-f51rq                       <span class=\"hljs-number\">2</span>/<span class=\"hljs-number\">2</span>       Running   <span class=\"hljs-number\">10</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kube-flannel-ds-l5wjs                       <span class=\"hljs-number\">2</span>/<span class=\"hljs-number\">2</span>       Running   <span class=\"hljs-number\">8</span>          <span class=\"hljs-number\">81d</span>\nkube-system   kube-proxy<span class=\"hljs-number\">-3</span>gn3x                            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">12</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kube-proxy<span class=\"hljs-number\">-88762</span>                            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">2</span>          <span class=\"hljs-number\">81d</span>\nkube-system   kube-proxy-dghmh                            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">10d</span>\nkube-system   kube-proxy-dtf9c                            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">3</span>          <span class=\"hljs-number\">81d</span>\nkube-system   kube-scheduler-k8s-node001                  <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">29</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kubernetes-dashboard<span class=\"hljs-number\">-1707270776</span>-jgxbp       <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">2</span>          <span class=\"hljs-number\">81d</span>\nkube-system   traefik-ingress-controller<span class=\"hljs-number\">-49053153</span>-kgb3p   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">1</span>          <span class=\"hljs-number\">30d</span>\n</pre>\n<p> </p>\n<p>backend docker example (nginx on arm) k8s-helloworld-arm</p>\n<p><a href=\"https://services.k8s.it/hello/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">live demo</a></p>\n<p><a href=\"https://services.k8s.it/grafana/dashboard/db/all-k8s-nodes?refresh=1m&amp;orgId=2&amp;from=now-24h&amp;to=now\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">monitoring</a></p>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "traefik",
                   "orangepi",
                   "lab",
                   "kubernetes",
                   "k8s",
                   "armbian",
                   "arm"
            ],
            "date_published": "2018-04-10T23:29:30+02:00",
            "date_modified": "2018-04-10T23:52:47+02:00"
        }
    ]
}
