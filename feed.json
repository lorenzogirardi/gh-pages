{
    "version": "https://jsonfeed.org/version/1",
    "title": "LAB",
    "description": "",
    "home_page_url": "https://www.k8s.it",
    "feed_url": "https://www.k8s.it/feed.json",
    "user_comment": "",
    "author": {
        "name": "lgirardi"
    },
    "items": [
        {
            "id": "https://www.k8s.it/kubernetes-servicemesh.html",
            "url": "https://www.k8s.it/kubernetes-servicemesh.html",
            "title": "Kubernetes-servicemesh",
            "summary": "Do we need a service mesh ?few years ago i started to evaluate this feature fitting in an existing infrastructure There are many concept to consider and many mistake the people usually think Better to start with what is NOT a work for a service mesh So&hellip;",
            "content_html": "<h2>Do we need a service mesh ?</h2>\n<p>few years ago i started to evaluate this feature fitting in an existing infrastructure</p>\n<p>There are many concept to consider and many mistake the people usually think<br>Better to start with what is <em>NOT</em> a work for a service mesh</p>\n<ul>\n<li>is not an apigw (even if could share some components)</li>\n<li>is not the place to put firewall rules</li>\n<li>is not something magic that boost the applications</li>\n<li>is something that if not used with a know scope could generate a mess</li>\n</ul>\n<p>So what is ...<br>well short answer</p>\n<ul>\n<li>is the missing link in the infrastructure observability</li>\n<li>is a way to handle in a structured way the application routing</li>\n<li>is an internal ratelimit / anti ddos / infrastructure layer (be careful)</li>\n<li>could be a clever way to improve some application limits (expanded next)</li>\n</ul>\n<p>Anyway is this something that we can add in our infrastructure ?</p>\n<p>There no YES/NO , however we can evaluate the company and the maturity of microservices<br>internal rate limit , is usually a feature that could safe the infrastructure during snowball effects<br>however means that if the infrastructure is SYNC (no decoupling) have the rate limit can just<br>stop the application to serve requests , and this will propagated to the others below.</p>\n<p>result: no answer<br>threads safe</p>\n<p>Sometimes it's better to have a strategic business login using the a circuit breaker that bring a huge complexity in configuration.</p>\n<p>The other point related to rate limit is .. who will maintain those values ?<br>Should be part of deployment pipeline and directly correlated with the application scope<br>In a 200+ micro services infrastructure this could be a huge problem:</p>\n<ul>\n<li>project that lost ownership</li>\n<li>projects not well maintained</li>\n<li>new legacy projects</li>\n</ul>\n<p>So my idea about rate limit is to use it in a specific \"strategic\" applications and should not indiscriminately added to the whole infrastructure</p>\n<p>About the routing feature, we can consider as a more detailed and customized blue green deployment , this specific case it's really useful when we have to deploy new features in production and <em>canary</em> deployment is not enough to cover the business measurement we need.</p>\n<p>This feature could be used to keep a specific affinity within the microservices and this is the real feature that some of you can consider, imagine a strict dependencies between application an cache (as usual)<br>So the application <em>Pippo</em> is using the cache <em>Paperino</em></p>\n<p>Pippo is a namespace composed by 10 pods<br>Paperino is a cache composed by 6 pods</p>\n<p>Imagine that we have the cache as a replication/sharded and we have 2 availability zones</p>\n<p>With service mesh we can use labels to say to Pippo to use the cache Paperino only in the availability zone where the call start from Pippo av, this will reduce dramatically the roundtrip and the answer</p>\n<p>I played a bit with service mesh in order to answer some questions,<br>however related to firewall rules the right answer is Cilium :-)</p>\n<p>With this, I'd like to say that service mash give you a great value only<br>if your infrastructure is able to embrace it and only if you know what you are doing with this infrastructure.</p>\n<ul>\n<li>observability</li>\n<li>routing purpose (this is strictly related to the microservice architecture)</li>\n<li>rate limitng</li>\n</ul>\n<h2><a id=\"user-content-service-mesh-sample-lab\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#service-mesh-sample-lab\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Service Mesh sample lab</h2>\n<p>This lab is provided to discover and test the functionality w'd like to implement in our environment</p>\n<h3><a id=\"user-content-basic-setup\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#basic-setup\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Basic setup</h3>\n<ul>\n<li>minikube v1.6.2</li>\n<li>Kubernetes v1.17.0 on Docker '19.03.5'</li>\n</ul>\n<p><code>curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64</code> <code>chmod +x minikube</code><br><code>sudo install minikube /usr/local/bin/</code><br><code>minikube start --memory=3000 --cpus=3</code></p>\n<ul>\n<li>network (since in production we are using flannel that is not able to manage network policy we can start using no CNI to have the environment as much as close to lmn environment)</li>\n</ul>\n<h4><a id=\"user-content-namespaces\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#namespaces\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Namespaces</h4>\n<p>a → traefik (ingress)<br>b → apache<br>c → application<br>d → redis</p>\n<p>b is a namespaces that manage an apache used for some rewrite rules<br>c is a python application that is connected to a redis database, provide some function to set a time, get a time with /set context and /get context<br>d is the redis database</p>\n<p>c code</p>\n<pre><code>\"\"\"\n    Example app that integrates with redis and save/get timing\n\"\"\"\nfrom os import environ\nfrom datetime import datetime\nimport json\nimport redis\nfrom flask import Flask, redirect\n\nVERSION = \"1.1.1\"\nREDIS_ENDPOINT = environ.get(\"REDIS_ENDPOINT\", \"redis-svc.d-redis.svc.cluster.local\")\nREDIS_PORT = int(environ.get(\"REDIS_PORT\", \"6379\"))\n\n\nAPP = Flask(__name__)\n\n\n@APP.route(\"/\")\ndef redisapp():\n    \"\"\"Main redirect\"\"\"\n    return redirect(\"/get\", code=302)\n\n\n@APP.route(\"/set\")\ndef set_var():\n    \"\"\"Set the time\"\"\"\n    red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)\n    red.set(\"time\", str(datetime.now()))\n    return json.dumps({\"time\": str(red.get(\"time\"))})\n\n\n@APP.route(\"/get\")\ndef get_var():\n    \"\"\"Get the time\"\"\"\n    red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)\n    return json.dumps({\"time\": str(red.get(\"time\"))})\n\n\n@APP.route(\"/reset\")\ndef reset():\n    \"\"\"Reset the time\"\"\"\n    red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)\n    red.delete(\"time\")\n    return json.dumps({\"time\": str(red.get(\"time\"))})\n\n\n@APP.route(\"/version\")\ndef version():\n    \"\"\"Get the app version\"\"\"\n    return json.dumps({\"version\": VERSION})\n\n\n@APP.route(\"/healthz\")\ndef health():\n    \"\"\"Check the app health\"\"\"\n    try:\n        red = redis.StrictRedis(host=REDIS_ENDPOINT, port=REDIS_PORT, db=0)\n        red.ping()\n    except redis.exceptions.ConnectionError:\n        return json.dumps({\"ping\": \"FAIL\"})\n\n    return json.dumps({\"ping\": red.ping()})\n\n\n@APP.route(\"/readyz\")\ndef ready():\n    \"\"\"Check the app readiness\"\"\"\n    return health()\n\n\nif __name__ == \"__main__\":\n    APP.run(debug=True, host=\"0.0.0.0\")\n</code></pre>\n<p>Dokerfile</p>\n<pre><code>FROM python:3.6-alpine\nCOPY . /app\nWORKDIR /app\nRUN pip install -r requirements.txt\nENTRYPOINT [\"python\"]\nCMD [\"app.py\"]\n</code></pre>\n<p>requirements.txt</p>\n<pre><code>Flask\nredis\npytest\npytest-flask\n</code></pre>\n<h3><a id=\"user-content-folders-structure\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#folders-structure\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Folders structure</h3>\n<pre><code>kubernetes/\n├── 00-traefik\n│   ├── A-00-traefik-ns.yaml\n│   ├── A-01-traefik-rbac.yaml\n│   └── A-02-traefik-ds.yaml\n├── 01-apache\n│   ├── B-00-k8s-apacherr-ns.yaml\n│   ├── B-01-k8s-apacherr-svc.yaml\n│   ├── B-02-k8s-apacherr-ing.yaml\n│   ├── B-03-k8s-apacherr-dpl.yaml\n│   └── B-04-k8s-apacherr-cfm.yaml\n├── 02-redis\n│   ├── D-00-lab-redis-ns.yaml\n│   ├── D-01-lab-redis-svc.yaml\n│   └── D-02-lab-redis-dpl.yaml\n└── 03-app\n    ├── C-00-app-ns.yaml\n    ├── C-01-app-svc.yaml\n    └── C-02-app-dpl.yaml\n</code></pre>\n<h3><a id=\"user-content-startup\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#startup\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Startup</h3>\n<p>kubernetes$ kubectl apply -f 00-traefik/</p>\n<pre><code>namespace/a-ingress-traefik created  \nclusterrole.rbac.authorization.k8s.io/traefik-ingress-controller created    \nserviceaccount/traefik-ingress-controller created  \nclusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller created\nserviceaccount/traefik-ingress-controller created\ndaemonset.apps/traefik-ingress-controller created\nservice/traefik-ingress-service created\n</code></pre>\n<p>kubernetes$ kubectl apply -f 01-apache/</p>\n<pre><code>namespace/b-apacherr created\nservice/apacherr-svc created\ningress.extensions/apacherr-ingress created\ndeployment.apps/apacherr created\nconfigmap/apacherr-80-config created\n</code></pre>\n<p>kubernetes$ kubectl apply -f 02-redis/</p>\n<pre><code>namespace/d-redis created\nservice/redis-svc created\ndeployment.apps/redis created\n</code></pre>\n<p>kubernetes$ kubectl apply -f 03-app/</p>\n<pre><code>namespace/c-app-count created    \nservice/app-count-svc created  \ndeployment.apps/pythonapp created  \n</code></pre>\n<p>kubectl get po --all-namespaces</p>\n<pre><code>NAMESPACE           NAME                               READY   STATUS    RESTARTS   AGE\na-ingress-traefik   traefik-ingress-controller-jkppg   1/1     Running   0          5m29s\nb-apacherr          apacherr-8b786b45d-g9vcl           1/1     Running   0          5m19s\nc-app-count         pythonapp-555d6d88cd-slhfb         1/1     Running   0          4m55s\nd-redis             redis-b869b89d-pf6ms               1/1     Running   0          5m12s\nkube-system         coredns-6955765f44-6nrdr           1/1     Running   1          74m\nkube-system         coredns-6955765f44-9fbgt           1/1     Running   1          74m\nkube-system         etcd-minikube                      1/1     Running   1          74m\nkube-system         kube-addon-manager-minikube        1/1     Running   1          74m\nkube-system         kube-apiserver-minikube            1/1     Running   1          74m\nkube-system         kube-controller-manager-minikube   1/1     Running   1          74m\nkube-system         kube-proxy-cchls                   1/1     Running   1          74m\nkube-system         kube-scheduler-minikube            1/1     Running   1          74m\nkube-system         storage-provisioner                1/1     Running   2          74m\n</code></pre>\n<p>make sure virtualbox 8081 port should be available</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/f303afac85505ee6e02651c55518f1eb809a6f97/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731352f6d6973632f696d675f7669727475616c626f782d706f7274666f7277617264696e672e706e67\"><img loading=\"lazy\" title=\"Virtualbox port forwarding\" src=\"https://camo.githubusercontent.com/f303afac85505ee6e02651c55518f1eb809a6f97/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731352f6d6973632f696d675f7669727475616c626f782d706f7274666f7277617264696e672e706e67\" data-is-external-image=\"true\"  alt=\"Virtualbox port forwarding\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1594573715/misc/img_virtualbox-portforwarding.png\"></a></p>\n<h2><a id=\"user-content-flow\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#flow\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>flow</h2>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/70a420864968278b8940023ba6aa95dd7bf932a6/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731342f6d6973632f696d675f666c6f772e706e67\"><img loading=\"lazy\" title=\"flow\" src=\"https://camo.githubusercontent.com/70a420864968278b8940023ba6aa95dd7bf932a6/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537333731342f6d6973632f696d675f666c6f772e706e67\" data-is-external-image=\"true\"  alt=\"flow\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1594573714/misc/img_flow.png\"></a></p>\n<h5><a id=\"user-content-inizialize-the-redis-database\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#inizialize-the-redis-database\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>inizialize the redis database</h5>\n<p><code>$ curl http://pippo.lan/count/set</code><br>{\"time\": \"b'2019-12-28 20:06:33.919059'\"}</p>\n<h5><a id=\"user-content-test-from-apache-to-application-case-1\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#test-from-apache-to-application-case-1\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>test from apache to application (case 1)</h5>\n<p><code>$ curl http://pippo.lan/count/get</code><br>{\"time\": \"b'2019-12-28 20:06:33.919059'\"}</p>\n<h5><a id=\"user-content-test-from-apache-to-redis-case-2\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#test-from-apache-to-redis-case-2\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>test from apache to redis (case 2)</h5>\n<p><code>$ curl http://pippo.lan/redis/GET/time</code><br>{\"GET\":\"2019-12-28 20:06:33.919059\"}</p>\n<h5><a id=\"user-content-network-rule-example\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#network-rule-example\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>network rule example</h5>\n<p>cilium labels</p>\n<pre><code>ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                           IPv6   IPv4            STATUS   \n           ENFORCEMENT        ENFORCEMENT                                                                                               \n201        Disabled           Disabled          32580      k8s:app=redis                                                10.15.182.193   ready   \n                                                           k8s:io.cilium.k8s.namespace.labels.name=d-redis                                      \n                                                           k8s:io.cilium.k8s.policy.cluster=default                                             \n                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                      \n                                                           k8s:io.kubernetes.pod.namespace=d-redis                                              \n                                                           k8s:track=redis                                                                      \n1257       Disabled           Disabled          4          reserved:health                                              10.15.197.106   ready   \n1663       Disabled           Disabled          54130      k8s:app=apacherr                                             10.15.192.41    ready   \n                                                           k8s:io.cilium.k8s.namespace.labels.name=b-apacherr                                   \n                                                           k8s:io.cilium.k8s.policy.cluster=default                                             \n                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                      \n                                                           k8s:io.kubernetes.pod.namespace=b-apacherr                                           \n3167       Disabled           Disabled          33702      k8s:app=pythonapp                                            10.15.247.186   ready   \n                                                           k8s:io.cilium.k8s.namespace.labels.name=c-app-count                                  \n                                                           k8s:io.cilium.k8s.namespace.labels.purpose=app                                       \n                                                           k8s:io.cilium.k8s.policy.cluster=default                                             \n                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                      \n                                                           k8s:io.kubernetes.pod.namespace=c-app-count                                          \n                                                           k8s:track=pythonapp-stable         \n</code></pre>\n<p>network rule</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: isolate-namespace\n  namespace: d-redis\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: c-app-count\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: c-app-count\n\n</code></pre>\n<p>   </p>\n<p>cilium/hubble <a href=\"https://github.com/cilium/hubble\">https://github.com/cilium/hubble</a> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/70234ad4768db6537d28a417f0e73061ce2e51b4/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f687562626c652d64726f702e706e67\"><img loading=\"lazy\" title=\"hubble\" src=\"https://camo.githubusercontent.com/70234ad4768db6537d28a417f0e73061ce2e51b4/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f687562626c652d64726f702e706e67\" data-is-external-image=\"true\"  alt=\"hubble\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1594574069/misc/hubble-drop.png\"></a></p>\n<p> </p>\n<p>istio/kiali <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/79a5b07227e5651705810596cef972d074ed201f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f697374696f2d6b69616c692e706e67\"><img loading=\"lazy\" title=\"kiali\" src=\"https://camo.githubusercontent.com/79a5b07227e5651705810596cef972d074ed201f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313539343537343036392f6d6973632f697374696f2d6b69616c692e706e67\" data-is-external-image=\"true\"  alt=\"kiali\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1594574069/misc/istio-kiali.png\"></a></p>\n<p> </p>\n<p>video Cilium example --&gt; <a href=\"https://res.cloudinary.com/ethzero/video/upload/v1594574074/misc/cilium.mkv\" rel=\"nofollow\">img/cilium.mkv</a></p>\n<p>video Istio + Cilium example --&gt; <a href=\"https://res.cloudinary.com/ethzero/video/upload/v1594574090/misc/istio.mkv\" rel=\"nofollow\">img/istio.mkv</a><br> </p>\n<h2><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-servicemesh#requirements\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>requirements</h2>\n<ul>\n<li>use service mesh to segregate redis \"d\" to accept connections only from application \"c\"<br>expected \"case 1\" still working, \"case 2\" stop working and receive an error</li>\n</ul>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
            ],
            "date_published": "2020-08-11T21:19:11+02:00",
            "date_modified": "2020-08-11T21:19:11+02:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-apacherr.html",
            "url": "https://www.k8s.it/kubernetes-apacherr.html",
            "title": "Kubernetes-apacherr",
            "summary": "The semi-unuseful apache implementation in kubernetesWell , why we are talking about apache httpd in kubernetes ? We have ingress resources , we have ambassador and we are using microservices... True but internet was not built yesterday and for some reasons out of my knowledge&hellip;",
            "content_html": "<h2>The semi-unuseful apache implementation in kubernetes</h2>\n<p>Well , why we are talking about apache httpd in kubernetes ?<br>We have ingress resources , we have ambassador and we are using microservices...<br>True but internet was not built yesterday and for some reasons out of my knowledge ,<br>people are ostinated to manage rewrite rules in apache instead to use a dedicated router application (react, zuul .. database!?!?! etc etc)<br>However sometimes we have to balance between the academic vision and the reality.</p>\n<h2><a id=\"user-content-digression\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-apacherr#digression\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>digression</h2>\n<p>Talking about apache https , nginx , haproxy ... i'm referring to the idea behind manage a complex website.<br>A website could be composed my hundreds of microservices but the domain it's usually one<br><a href=\"http://www.example.com/\" rel=\"nofollow\">www.example.com</a></p>\n<p><a href=\"http://www.example.com/\" rel=\"nofollow\">www.example.com</a> has the root path /<br>/it/ managed by cms<br>/it/offerte managed by cms<br>/uk/ managed by cms<br>/uk/offers managed by cms<br>/../ whatever<br>/it/clienti/ managed by customer-app<br>/uk/customers/ managed by customers-app<br>/../somethingelse<br>/secure/ managey by payment-app<br>...<br>omg path clash ... so we need to exclude in apache /uk/customers/ from cms proxypass but<br>meantime enable a dedicated proxy pass to a specific application endpoint.<br>and we are mannually manage all language , all applications with static configurations...<br>and if tomorrow we will open APAC ... what we have to do ?<br>and if we need to cover a former third parti company and acquire his seo ranking we should create<br>thousands of redirects ? and how we can can validate avoiding loops ?</p>\n<p>A better design start giving the right responsability , that could be managed using a business layer<br>that we can call \"front controller\" where we can apply all rules.</p>\n<p>In terms of responsability all applaction behind this layer should be working by selfcontained logic<br>example... if i have a seo application this should be working without this layer , removing direct dependency<br>same concept for cms application , customers application and so on.<br>So what this layer will do ?</p>\n<p>A front controller should be the owner of root path of our websites \"/\"<br>Should be also responsible to handle all the others paths after the root ones.</p>\n<p>Main duties:</p>\n<ul>\n<li>handle all requests and manage the backend application with business logic</li>\n<li>provide dynamic path based on business rules (language + brand + something else)</li>\n<li>provide the AB test logic</li>\n<li>provide a validation logic</li>\n<li>expose a company backoffice to trim the website layout</li>\n</ul>\n<p>Examples</p>\n<p>Having a global websites spread with multiple countris with differents domains/brands and languages we can immagine</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/184bca691d84bf02cd01d06642b3aac6f582d28f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538323238393238352f6d6973632f66726f6e742d636f6e74726f6c6c65722e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/184bca691d84bf02cd01d06642b3aac6f582d28f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538323238393238352f6d6973632f66726f6e742d636f6e74726f6c6c65722e706e67\" data-is-external-image=\"true\"  alt=\"frontcontroller\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1582289285/misc/front-controller.png\"></a></p>\n<p>Where the microservice/application CMS is responsible to hangle all domains and all languages and the<br>front controller take the ownership to match brand plus .tld (or paths \"/fr/\")<br>in order to dinamically generate the right url with canonical pages.</p>\n<p>Many and many others assumptions can be covered by this componet, however we have to stay grounded<br>and check how we can manage an apache responsible to redirects proxypass an rewrite rules.</p>\n<h2><a id=\"user-content-some-concepts-about-this-project\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-apacherr#some-concepts-about-this-project\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Some concepts about this project</h2>\n<p>Even if we are working in a dynamic environment it's no rare to have the traditional layers</p>\n<p>DMZ --&gt; layer 1<br>Application --&gt; layer 2<br>Database --&gt;layer 3</p>\n<p>In this picture apache httpd should usually placed on layer 1 ,<br>but consider apache not for the common web server but like a \"product\" ,<br>something that could be managed not by SRE , but Product Engeneer.<br>A product that own a dedicated business, like seo, sem , vanity urls etc etc.</p>\n<p>Having those considerations, we can \"downgrade\" apache httpd in layer 2 like any application<br>and honor the DMZ (if needed ?!?!) on top by ingress/haproxy/bigf5 (where maybe we can terminate the TLS).</p>\n<h2><a id=\"user-content-implementation\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-apacherr#implementation\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Implementation</h2>\n<p>The code in this project is designet to manage apache configuration by configmap,<br>however some websites are really complex and there are some limits implication with ectd max object size.</p>\n<p>In this scenario it's higly raccomended to deploy the release with a standard pipeline with compiled<br>container on the source.</p>\n<h2><a id=\"user-content-deploy\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-apacherr#deploy\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>deploy</h2>\n<p><code>kubectl apply -f apacherr/deployment/</code></p>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
            ],
            "date_published": "2020-08-11T21:19:11+02:00",
            "date_modified": "2020-08-11T21:19:11+02:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-guacamole.html",
            "url": "https://www.k8s.it/kubernetes-guacamole.html",
            "title": "Kubernetes-guacamole",
            "summary": "Here we are , another apache guacamole implementation in kubernetesThis service is designed to avoid the usage of mysql and create a standalone project The main idea is to use the user-mapping.xml as a config map For production environment i suggest to add the ldap auth (ad.openldap,freeipa),&hellip;",
            "content_html": "<div class=\"flex-shrink-0 col-12 col-md-9 mb-4 mb-md-0\">\n<div id=\"readme\" class=\"Box md js-code-block-container Box--responsive\">\n<div class=\"Box-body px-5 pb-5\">\n<article class=\"markdown-body entry-content container-lg\">\n<h2>Here we are , another apache guacamole implementation in kubernetes</h2>\n<p>This service is designed to avoid the usage of mysql and create a standalone project</p>\n<p>The main idea is to use the <strong>user-mapping.xml</strong> as a config map</p>\n<p>For production environment i suggest to add the ldap auth (ad.openldap,freeipa),<br>mysql database should be managed with a dedicated instances and mantained in case of \"exit\"</p>\n<h2><a id=\"user-content-what-is-a-bastion-host\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#what-is-a-bastion-host\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>what is a bastion host</h2>\n<p>On the Internet, a bastion host is the only host computer that a company allows to be addressed<br>directly from the public network and that is designed to screen the rest of its network from security exposure.</p>\n<h2><a id=\"user-content-how-this-tool-can-be-used\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#how-this-tool-can-be-used\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>how this tool can be used</h2>\n<p>The tool is designed to be used when you have some dedicated service in production and you have to keep<br>the control of access and account used , guacamole has the ability to manage the most used platforms (windows and linux)<br>as host in backend to be reached from developers ... contractors ...</p>\n<h2><a id=\"user-content-why-in-kubernetes\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#why-in-kubernetes\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>why in kubernetes</h2>\n<p>Since the auth method could scale by configmap or ldap or mysql , is designed to scale<br>we have also the benefits to have a low footprint compared to a traditional vm.</p>\n<h2><a id=\"user-content-config-to-change\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#config-to-change\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>config to change</h2>\n<p>Before deploy you need to specify the following parameters in guacamole folder</p>\n<ul>\n<li>YOUR_DOMAIN to reflect your domain url in 03-guacamole-ing.yaml</li>\n<li>user YOUR_USERNAME / YOUR_MD5_PWD and hosts xml configuration in 04-guacamole-cfm.yaml following <a href=\"https://guacamole.apache.org/doc/gug/configuring-guacamole.html#user-mapping\" rel=\"nofollow\">https://guacamole.apache.org/doc/gug/configuring-guacamole.html#user-mapping</a></li>\n</ul>\n<p>screenshots</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/905e74d0ce81c8b239f67d405567100a3f181292/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d77696e2e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/905e74d0ce81c8b239f67d405567100a3f181292/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d77696e2e706e67\" data-is-external-image=\"true\"  alt=\"windows\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1580850552/misc/guacamole-win.png\"></a><br><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/fd53b1991cd9693679aae9aadf72bc75d025c2ad/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d6c696e75782e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/fd53b1991cd9693679aae9aadf72bc75d025c2ad/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538303835303535322f6d6973632f67756163616d6f6c652d6c696e75782e706e67\" data-is-external-image=\"true\"  alt=\"linux\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1580850552/misc/guacamole-linux.png\"></a></p>\n<h2><a id=\"user-content-deploy\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-guacamole#deploy\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>deploy</h2>\n<p><code>kubectl apply -f guacd</code></p>\n<p><code>kubectl apply -f guacamole</code></p>\n<p>You can secure the connection with kube-lego and use cillium to add network rules </p>\n</article>\n</div>\n</div>\n</div>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
            ],
            "date_published": "2020-08-11T21:19:11+02:00",
            "date_modified": "2020-08-11T21:19:11+02:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-strongswan.html",
            "url": "https://www.k8s.it/kubernetes-strongswan.html",
            "title": "Kubernetes-strongswan",
            "summary": "How we can manage vpn in kubernetes environmentHi there , this project is to cover the vpn ipsec-xauth topic in a kubernetes evironment, the goal of this is to have the less effort possible when we have to manage users. Architecture Requirements: WHYThe traditional ipsec-xauth&hellip;",
            "content_html": "<div class=\"flex-shrink-0 col-12 col-md-9 mb-4 mb-md-0\">\n<div id=\"readme\" class=\"Box md js-code-block-container Box--responsive\">\n<div class=\"Box-body px-5 pb-5\">\n<article class=\"markdown-body entry-content container-lg\">\n<h2>How we can manage vpn in kubernetes environment</h2>\n<p>Hi there , this project is to cover the vpn ipsec-xauth topic in a kubernetes evironment,<br>the goal of this is to have the less effort possible when we have to manage users.</p>\n<p>Architecture<br><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/ee7bbe0fe8e2f17b0bda45b6b92d585105d9adcc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538343733313733352f6d6973632f76706e5f6469616772616d2e6a7067\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/ee7bbe0fe8e2f17b0bda45b6b92d585105d9adcc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538343733313733352f6d6973632f76706e5f6469616772616d2e6a7067\" data-is-external-image=\"true\"  alt=\"architecture\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1584731735/misc/vpn_diagram.jpg\"></a></p>\n<p>Requirements:</p>\n<ul>\n<li>Kubernetes</li>\n<li>Strongswan</li>\n<li>Microsoft Acrive Directory / openldap / freeipa etc etc LDAP (i'll use ldap instead the software name)</li>\n</ul>\n<h2><a id=\"user-content-why\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-strongswan#why\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>WHY</h2>\n<p>The traditional ipsec-xauth vpn with ikev1 is based on PSK<br>and a client username/password , this is a problem when the credential are stored in a file<br>in kubernetes update a file always mean rollout a new deploy or create a procedure to<br>make effective the changes.<br>So the idea is to deploy something that doesn't need any interaction<br>after the deploy and manage the clients, with the company standards,<br>like password expiration, password complexity, groups attributions and so on.</p>\n<h2><a id=\"user-content-how\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/kubernetes-strongswan#how\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>HOW</h2>\n<p>In order to have a fully managed services we can leverage the usage of ldap procedures (that all company has).<br>Strongswan (a fork of *swan ipsec software) could be integrated with ldap with pam.<br>pam is ... well --&gt; <a href=\"https://tldp.org/HOWTO/User-Authentication-HOWTO/x115.html\" rel=\"nofollow\">https://tldp.org/HOWTO/User-Authentication-HOWTO/x115.html</a></p>\n<p>So what we need in ldap ?<br>We need:</p>\n<ul>\n<li>a technical user that is a low level profile that will be used only to check the users inside the ldap tree and the groups associated</li>\n<li>a group to associate to people who need/granted the vpn access</li>\n</ul>\n<p>in this scenario tech users is --&gt; <em>ldapbind</em><br>group is --&gt; <em>vpn</em></p>\n<p>here some screen related</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/48427e34136d63b4b7348ba8c2148e178665cdf0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f62696e645f757365722e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/48427e34136d63b4b7348ba8c2148e178665cdf0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f62696e645f757365722e706e67\" data-is-external-image=\"true\"  alt=\"ldapbind\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584730828/misc/strongswan_bind_user.png\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/141e29aaed92e477719b517dd704c815b18c23bc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f757365725f76706e5f67726f75702e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/141e29aaed92e477719b517dd704c815b18c23bc/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832382f6d6973632f7374726f6e677377616e5f757365725f76706e5f67726f75702e706e67\" data-is-external-image=\"true\"  alt=\"vpn group\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584730828/misc/strongswan_user_vpn_group.png\"></a></p>\n<p>Then... now we have to configure configure the Docker image in order to support pam ldap.</p>\n<p>Dockerfile</p>\n<pre><code>FROM debian:stretch\nMAINTAINER lgirardi &lt;l@k8s.it&gt;\n\n\nRUN apt-get -y update &amp;&amp; apt-get -yq install \\\n        strongswan \\\n        libcharon-extra-plugins \\\n        iptables \\\n        kmod \\\n        libpam-ldap \\\n        vim\n\nEXPOSE 500/udp 4500/udp\n\nCMD /usr/sbin/ipsec start --nofork\n</code></pre>\n<p>libpam-ldap and libcharon-extra-plugins are what we need to perform this kind of integration.</p>\n<p>Since strongswan is not traditionally used in kubernetes , has some files that needs a configuration.<br>ENV variables are the most useful to configure it,<br>unfortunately the process is not able to share the env this the child process,<br>so we will work with 2 concepts,<br>use the configmap for all files we need to configure use the secrets for all sensitive data we need to add</p>\n<p>files configured:</p>\n<ul>\n<li>ipsec.conf (the strongswan main configuration)</li>\n<li>xauth-pam.conf (strongswan configuration to enable pam)</li>\n<li>attr.conf (strongswan configuration file for split-tunnel)<br><em>split-tunnel is when you want to move in vpn only the company subnet and use the home gateway for all the other usages</em></li>\n<li>ipsec (pam configuration in /etc/pam.d)</li>\n</ul>\n<p>secrets:</p>\n<ul>\n<li>ipsec.secrets (file with the ipsec PSK) rif. 003-configmap.yaml</li>\n<li>pam_ldap.conf (configuration used by pam module to connect to ldap) rif. 002-secrets.yaml</li>\n</ul>\n<p><em>remember that all secrets files are managed using base64 encoding</em></p>\n<p>When we have multiple files to spread in different locations we have to create some tricks,<br>one is to create symlink in the Dockerfile , however we have to keep the configuration<br>as much as possible agnostic from the Dockerfile.</p>\n<p><em>volume</em> and <em>volumeMounts</em> can help on this topic</p>\n<pre><code>volumeMounts:\n- name: psk\n  mountPath: /etc/ipsec.secrets\n  subPath: psk\n  readOnly: true\n- name: pamldap\n  mountPath: /etc/pam_ldap.conf\n  subPath: pamldap\n- name: strongswan-attr\n  mountPath: /etc/strongswan.d/charon/attr.conf\n  subPath: attr.conf\n- name: strongswan-xauth-pam\n  mountPath: /etc/strongswan.d/charon/xauth-pam.conf\n  subPath: xauth-pam.conf\n- name: strongswan-ipsec\n  mountPath: /etc/pam.d/ipsec\n  subPath: ipsec\n- name: strongswan-ipseconf\n  mountPath: /etc/ipsec.conf\n  subPath: ipsec.conf\nvolumes:\n- name: strongswan-attr\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: attr.conf\n      path: attr.conf\n- name: strongswan-xauth-pam\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: xauth-pam.conf\n      path: xauth-pam.conf\n- name: strongswan-ipsec\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: ipsec\n      path: ipsec\n- name: strongswan-ipseconf\n  configMap:\n    name: strongswanconfigmap\n    items:\n    - key: ipsec.conf\n      path: ipsec.conf\n- name: psk\n  secret:\n    secretName: strongswan-secret\n- name: pamldap\n  secret:\n    secretName: strongswan-secret\n</code></pre>\n<p>Now we have all configured, we can just run<br><code>kubectl apply -f deploy</code></p>\n<p>We will have soon a pod into strongswan namespace</p>\n<pre><code># kubectl get pods -n strongswan\nNAME                          READY   STATUS    RESTARTS   AGE\nstrongswan-77bfbb9f9f-57hmz   1/1     Running   0          22h\n</code></pre>\n<p>Since the service is configured with nodport we need to enable the default 500 and 4500<br>in our firewall , matching the kubernetes ports 30000-32767, in this this service are</p>\n<pre><code>ports:\n- name: isakmp-udp\n  protocol: UDP\n  nodePort: 30500\n  port: 500\n  targetPort: 500\n- name: ipsec-nat-t\n  protocol: UDP\n  nodePort: 30450\n  port: 4500\n  targetPort: 4500\ntype: NodePort\n</code></pre>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/9a42ba23f208fb8562105b7b19d240bc5e495426/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832372f6d6973632f7374726f6e677377616e5f6669726577616c6c5f6e61742e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/9a42ba23f208fb8562105b7b19d240bc5e495426/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733303832372f6d6973632f7374726f6e677377616e5f6669726577616c6c5f6e61742e706e67\" data-is-external-image=\"true\"  alt=\"firewall configuration\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584730827/misc/strongswan_firewall_nat.png\"></a></p>\n<p>We can configure our standard client (cisco ipsec client is enough)</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/ace3ff6a96cf31968f11209b7b05fce4ea5487a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733353439332f6d6973632f7374726f6e677377616e5f616e64726f69645f636c69656e742e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/ace3ff6a96cf31968f11209b7b05fce4ea5487a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733353439332f6d6973632f7374726f6e677377616e5f616e64726f69645f636c69656e742e706e67\" data-is-external-image=\"true\"  alt=\"android configuration\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_320/v1584735493/misc/strongswan_android_client.png\"></a></p>\n<pre><code># kubectl logs strongswan-77bfbb9f9f-57hmz -n strongswan\nStarting strongSwan 5.5.1 IPsec [starter]...\nno netkey IPsec stack detected\nno KLIPS IPsec stack detected\nno known IPsec stack detected, ignoring!\ncharon (13) started after 80 ms\n00[DMN] Starting IKE charon daemon (strongSwan 5.5.1, Linux 4.15.0-70-generic, x86_64)\n00[CFG] mapping attribute type split-exclpude failed\n00[CFG] loading ca certificates from '/etc/ipsec.d/cacerts'\n00[CFG] loading aa certificates from '/etc/ipsec.d/aacerts'\n00[CFG] loading ocsp signer certificates from '/etc/ipsec.d/ocspcerts'\n00[CFG] loading attribute certificates from '/etc/ipsec.d/acerts'\n00[CFG] loading crls from '/etc/ipsec.d/crls'\n00[CFG] loading secrets from '/etc/ipsec.secrets'\n00[CFG]   loaded IKE secret for %any\n00[CFG] loaded 0 RADIUS server configurations\n00[CFG] HA config misses local/remote address\n00[LIB] loaded plugins: charon aes rc2 sha2 sha1 md5 random nonce x509 revocation constraints pubkey pkcs1 pkcs7 pkcs8 pkcs12 pgp dnskey sshkey pem openssl fips-prf gmp agent xcbc hmac gcm attr kernel-netlink resolve socket-default connmark farp stroke updown eap-identity eap-aka eap-md5 eap-gtc eap-mschapv2 eap-radius eap-tls eap-ttls eap-tnc xauth-generic xauth-eap xauth-pam tnc-tnccs dhcp lookip error-notify certexpire led addrblock unity\n00[LIB] dropped capabilities, running as uid 0, gid 0\n00[JOB] spawning 16 worker threads\n05[CFG] received stroke: add connection 'roadw'\n05[CFG] adding virtual IP address pool 172.16.17.0/29\n05[CFG] added configuration 'roadw'\n08[NET] received packet: from 10.1.1.1[36312] to 10.1.1.84[500] (756 bytes)\n08[ENC] parsed ID_PROT request 0 [ SA V V V V V V V V ]\n08[IKE] received NAT-T (RFC 3947) vendor ID\n08[IKE] received draft-ietf-ipsec-nat-t-ike-02 vendor ID\n08[IKE] received draft-ietf-ipsec-nat-t-ike-02\\n vendor ID\n08[IKE] received draft-ietf-ipsec-nat-t-ike-00 vendor ID\n08[IKE] received XAuth vendor ID\n08[IKE] received Cisco Unity vendor ID\n08[IKE] received FRAGMENTATION vendor ID\n08[IKE] received DPD vendor ID\n08[IKE] 10.1.1.1 is initiating a Main Mode IKE_SA\n08[ENC] generating ID_PROT response 0 [ SA V V V V ]\n08[NET] sending packet: from 10.1.1.84[500] to 10.1.1.1[36312] (160 bytes)\n05[NET] received packet: from 10.1.1.1[36312] to 10.1.1.84[500] (228 bytes)\n05[ENC] parsed ID_PROT request 0 [ KE No NAT-D NAT-D ]\n05[IKE] local host is behind NAT, sending keep alives\n05[IKE] remote host is behind NAT\n05[ENC] generating ID_PROT response 0 [ KE No NAT-D NAT-D ]\n05[NET] sending packet: from 10.1.1.84[500] to 10.1.1.1[36312] (244 bytes)\n09[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (92 bytes)\n09[ENC] parsed ID_PROT request 0 [ ID HASH ]\n09[CFG] looking for XAuthInitPSK peer configs matching 10.1.1.84...10.1.1.1[100.106.113.62]\n09[CFG] selected peer config \"roadw\"\n09[ENC] generating ID_PROT response 0 [ ID HASH ]\n09[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (92 bytes)\n09[ENC] generating TRANSACTION request 3276308191 [ HASH CPRQ(X_USER X_PWD) ]\n09[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (76 bytes)\n11[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (108 bytes)\n11[ENC] parsed TRANSACTION response 3276308191 [ HASH CPRP(X_USER X_PWD) ]\n11[IKE] PAM authentication of 'lgirardi' successful\n11[IKE] XAuth authentication of 'lgirardi' successful\n11[ENC] generating TRANSACTION request 1380277626 [ HASH CPS(X_STATUS) ]\n11[NET] sending packet: from 10.1.1.84[4500] to 10.1.1.1[40011] (76 bytes)\n10[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (108 bytes)\n10[ENC] parsed INFORMATIONAL_V1 request 4006980307 [ HASH N(INITIAL_CONTACT) ]\n12[NET] received packet: from 10.1.1.1[40011] to 10.1.1.84[4500] (92 bytes)\n12[ENC] parsed TRANSACTION response 1380277626 [ HASH CPA(X_STATUS) ]\n12[IKE] IKE_SA roadw[1] established between 10.1.1.84[ETHZERO_HOME_VPN]...10.1.1.1[100.106.113.62]\n12[IKE] scheduling rekeying in 86047s\n12[IKE] maximum IKE_SA lifetime 86227s\n</code></pre>\n<p>ok now i'm connected and i can see my network in tun0</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/0ec58f59178a15278c87059d926b2a8b7b2938a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733303936302f6d6973632f7374726f6e677377616e5f636c69656e745f616e64726f69642e6a7067\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/0ec58f59178a15278c87059d926b2a8b7b2938a8/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733303936302f6d6973632f7374726f6e677377616e5f636c69656e745f616e64726f69642e6a7067\" data-is-external-image=\"true\"  alt=\"android ip\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_320/v1584730960/misc/strongswan_client_android.jpg\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/89492159c8fb5380197b4ecd266dce5c4068a9a0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733363033342f6d6973632f7374726f6e677377616e5f616e64726f69645f70696e672e6a7067\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/89492159c8fb5380197b4ecd266dce5c4068a9a0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3332302f76313538343733363033342f6d6973632f7374726f6e677377616e5f616e64726f69645f70696e672e6a7067\" data-is-external-image=\"true\"  alt=\"android ping\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_320/v1584736034/misc/strongswan_android_ping.jpg\"></a></p>\n<p>Thats all ... here my connection</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/b702d2df92e56ffae8f754aed08e84ebd4d0595f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733363332382f6d6973632f7374726f6e677377616e5f7374726f6b655f737461747573616c6c2e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/b702d2df92e56ffae8f754aed08e84ebd4d0595f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f635f7363616c652c775f3634302f76313538343733363332382f6d6973632f7374726f6e677377616e5f7374726f6b655f737461747573616c6c2e706e67\" data-is-external-image=\"true\"  alt=\"strongswan connection\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/c_scale,w_640/v1584736328/misc/strongswan_stroke_statusall.png\"></a></p>\n</article>\n</div>\n</div>\n</div>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
            ],
            "date_published": "2020-08-11T21:19:11+02:00",
            "date_modified": "2020-08-11T21:19:11+02:00"
        },
        {
            "id": "https://www.k8s.it/docker-latency.html",
            "url": "https://www.k8s.it/docker-latency.html",
            "title": "Docker-latency",
            "summary": "aka the network blaming toolSo again another grafana stack with docker Well yes but with a precise scope In this period we are almost all working from home, the blaming topic is usually the connection with our offices or the datacenters. Is not so rare&hellip;",
            "content_html": "<h2><a id=\"user-content-aka-the-network-blaming-tool\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#aka-the-network-blaming-tool\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>aka the network blaming tool</h2>\n<p>So again another grafana stack with docker<br>Well yes but with a precise scope</p>\n<p>In this period we are almost all working from home,<br>the blaming topic is usually the connection with our offices or the datacenters.</p>\n<p>Is not so rare for a network Administrator hear people that sais ,<br><em>the vpn is slow</em> , <em>i cannot connect to ... $something</em> , bla bla bla</p>\n<p>In my experience this is usually due to the quality of the provider,<br>sometimes is also a problem on route path on T2/T3 providers</p>\n<h3><a id=\"user-content-how-we-can-undestand-if-our-network-is-really-slow-\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#how-we-can-undestand-if-our-network-is-really-slow-\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>HOW we can undestand if our network is really slow ?</h3>\n<p>The idea is to start a grafana stack ready-made to handle the basics statistics of our internet connection.<br>We need to choose some endpoints to monitor, example , your vpn endpoint , your datacenter/office public ip , the main dns servers and so on</p>\n<h4><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#requirements\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Requirements</h4>\n<ul>\n<li>Docker</li>\n<li>Docker Compose</li>\n</ul>\n<h4><a id=\"user-content-stack\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#stack\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Stack</h4>\n<ul>\n<li>Influxdb</li>\n<li>Grafana</li>\n<li>Telegraf</li>\n</ul>\n<h4><a id=\"user-content-tree\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#tree\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Tree</h4>\n<pre><code>├── .env\n├── Makefile\n├── README.md\n├── docker\n│   ├── grafana\n│   │   ├── Dashboard-PING.json\n│   │   ├── dashboard.yaml\n│   │   └── datasource.yaml\n│   ├── influxdb\n│   │   ├── influxdb.conf\n│   │   \n│   └── telegraf\n│       └── telegraf.conf\n├── docker-compose.yml\n</code></pre>\n<p>Makefile is ... well a makefile , commands allowed<br><em>up , down, dev, down, logs, clean</em><br>up is to startup the stack<br>down to shutdown clean is done to remove also the storage saved for influxdb and grafana</p>\n<p>.env contains the grafana and influxdb credentials (yes the default password is quite complicated)<br>Since this tool is hosted in your laptop (could be everywhere), never mind the <em>security</em></p>\n<pre><code>GRAFANA_USER=admin\nGRAFANA_PASSWORD=EQyFJpjxvJG8k2K8\nINFLUXDB_DOMAIN=influxdb\nINFLUXDB_DATABASE=ping\n</code></pre>\n<h3><a id=\"user-content-configuration\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#configuration\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Configuration</h3>\n<p>We just need to choose the endpoints we'd like to monitor from our internet connection This could be done editing <em>telegraf.conf</em></p>\n<pre><code>[global_tags]\n[agent]\n  interval = \"10s\"\n  round_interval = true\n  metric_batch_size = 1000\n  metric_buffer_limit = 10000\n  collection_jitter = \"0s\"\n  flush_interval = \"10s\"\n  flush_jitter = \"0s\"\n  precision = \"\"\n  hostname = \"local-telegraf\"\n  omit_hostname = false\n[[outputs.influxdb]]\n   urls = [\"http://127.0.0.1:8086\"]\n   database = \"ping\"\n[[inputs.ping]]\nurls = [\"1.1.1.1\", \"8.8.8.8\", \"208.67.222.222\", \"test1.velocable.com\"]\ncount = 7\nping_interval = 1.0\n</code></pre>\n<p>Edit <em>urls =</em> adding / modify the endpoints<br>(in this example, Cloudflare dns , Google dns, opendns, and a server in Madrid used for speedtest)</p>\n<p>The configuration is collecting information every 10 seconds , and run a ping command 7 time each with 1 second delay.</p>\n<h3><a id=\"user-content-startup\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#startup\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Startup</h3>\n<p>Inside the main folder run</p>\n<p><code>make up</code></p>\n<p>output:</p>\n<pre><code>docker-latency$ make up\ndocker-compose -f docker-compose.yml up -d\nCreating network \"docker-latency_default\" with the default driver\nCreating grafana  ... done\nCreating influxdb ... done\nCreating telegraf ... done\n</code></pre>\n<p>login to:<br><code>http://localhost:3000/ </code>admin/EQyFJpjxvJG8k2K8</p>\n<p>you will see</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/56bea14df7a89b07f4e319b45ad4d27c39ad865f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353634313235322f6d6973632f67726166616e615f686f6d652e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/56bea14df7a89b07f4e319b45ad4d27c39ad865f/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353634313235322f6d6973632f67726166616e615f686f6d652e706e67\" data-is-external-image=\"true\"  alt=\"grafana_home\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1585641252/misc/grafana_home.png\"></a></p>\n<p>than , checking for the only board present --&gt; <em>internet latency</em></p>\n<p>you will have all details about the endpoint chosen , packet loss especially</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/5fd87b371e34b4497018003fcd41cd2e09d23c72/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353539353832342f6d6973632f67726166616e615f70696e672e706e67\"><img loading=\"lazy\" src=\"https://camo.githubusercontent.com/5fd87b371e34b4497018003fcd41cd2e09d23c72/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f6574687a65726f2f696d6167652f75706c6f61642f76313538353539353832342f6d6973632f67726166616e615f70696e672e706e67\" data-is-external-image=\"true\"  alt=\"grafana_ping\" data-canonical-src=\"https://res.cloudinary.com/ethzero/image/upload/v1585595824/misc/grafana_ping.png\"></a></p>\n<p>100% packet loss simulated disabling network card for few seconds.<br>The dashboard is using variables in order to create 1 row for each endpoint.</p>\n<h3><a id=\"user-content-conclusion\" class=\"anchor\" aria-hidden=\"true\" href=\"https://github.com/lorenzogirardi/docker-latency#conclusion\"><svg class=\"octicon octicon-link\" viewbox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion</h3>\n<p>Now we have data, so we know what is going on in our internet connection and we can probably<br>have more details about the <em>infomagic</em> words like ... <em>is slow</em></p>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
            ],
            "date_published": "2020-08-11T21:19:11+02:00",
            "date_modified": "2020-08-11T21:19:11+02:00"
        },
        {
            "id": "https://www.k8s.it/terraform-your-free-claudflare-account.html",
            "url": "https://www.k8s.it/terraform-your-free-claudflare-account.html",
            "title": "Terraform your free Claudflare account",
            "summary": "So... after some experience with akamai www.ethzero.it is an alias for aku-cs-akamaiflowers.com.edgesuite.net. aku-cs-akamaiflowers.com.edgesuite.net is an alias for a169.dscksd.akamai.net. a169.dscksd.akamai.net has address 193.45.15.98 a169.dscksd.akamai.net has address 193.45.15.122 a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f62 a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f7aand some others with Incapsula bunker.ethzero.it is an alias for&hellip;",
            "content_html": "<p>So...</p>\n<p>after some experience with akamai </p>\n<pre><code><em>www.ethzero.it is an alias for aku-cs-akamaiflowers.com.edgesuite.net.</em></code><br><code><em>aku-cs-akamaiflowers.com.edgesuite.net is an alias for a169.dscksd.akamai.net.</em></code><br><code><em>a169.dscksd.akamai.net has address 193.45.15.98</em></code><br><code><em>a169.dscksd.akamai.net has address 193.45.15.122</em></code><br><code><em>a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f62</em></code><br><code><em>a169.dscksd.akamai.net has IPv6 address 2001:2030:0:27::c12d:f7a</em></code></pre>\n<p>and some others with Incapsula</p>\n<pre><code><em>bunker.ethzero.it is an alias for ve7cu.x.incapdns.net.</em></code><br><code><em>ve7cu.x.incapdns.net has address 107.154.167.38</em></code></pre>\n<p>It's now the moment to talk about Cloudflare</p>\n<p> <a href=\"https://www.cloudflare.com/\">Claudflare</a> provide a good free account that allow you to hide your source ip or you want to discover how it's work the free waf protection or have a https certificate having your origin in http and so on ... but what is really cool and quickwin than the competitors is the API support and the native integration with <a href=\"https://www.terraform.io/docs/providers/cloudflare/index.html\">Terraform</a></p>\n<p><img loading=\"lazy\" src=\"https://www.k8s.it/media/posts/5/git-terraform-cloudflare.png\" sizes=\"(max-width: 48em) 100vw, 768px\" srcset=\"https://www.k8s.it/media/posts/5/responsive/git-terraform-cloudflare-xs.png 300w ,https://www.k8s.it/media/posts/5/responsive/git-terraform-cloudflare-sm.png 480w ,https://www.k8s.it/media/posts/5/responsive/git-terraform-cloudflare-md.png 768w\"  alt=\"\" width=\"2394\" height=\"1254\"></p>\n<p>Terraform is the most integrated tool for cloud (not only) automation and infrastructure as a code </p>\n<p>Here some steps that can show how it's esay deploy a configuration</p>\n<p>First of all , retrive the api key from Cloudflare portal</p>\n<p><img loading=\"lazy\" src=\"https://www.k8s.it/media/posts/5/cloudflare-api-key.png\" sizes=\"(max-width: 48em) 100vw, 768px\" srcset=\"https://www.k8s.it/media/posts/5/responsive/cloudflare-api-key-xs.png 300w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-api-key-sm.png 480w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-api-key-md.png 768w\"  alt=\"\" width=\"1922\" height=\"556\"></p>\n<p><img loading=\"lazy\" src=\"https://www.k8s.it/media/posts/5/cloudflare-global-apikey.png\" sizes=\"(max-width: 48em) 100vw, 768px\" srcset=\"https://www.k8s.it/media/posts/5/responsive/cloudflare-global-apikey-xs.png 300w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-global-apikey-sm.png 480w ,https://www.k8s.it/media/posts/5/responsive/cloudflare-global-apikey-md.png 768w\"  alt=\"\" width=\"1910\" height=\"396\"> </p>\n<p>then start the main terraform file in a dedicated folder (better in a <a href=\"https://gitlab.com/\">gitlab</a> repo)</p>\n<pre><code>$ cat cloudflare-auth.tf</code><code><br>provider \"cloudflare\" {<br> email = \"cloudflare_registration_email\"<br> token = \"cloudflare_token_api_key\"<br>}<br></code></pre>\n<p>make a $<code>terraform init</code> and now you can start to configure your account</p>\n<p>manage your domain(s)</p>\n<pre>$ <code>cat cloudflare_domains.tf</code><br><code>variable \"domain\" {</code><br><code> default = \"k8s.it\"</code><br><code>} </code></pre>\n<p> </p>\n<p>create dns configuration</p>\n<pre>$ <code>cat cloudflare_dns.tf</code><br><code>resource \"cloudflare_record\" \"www\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"www\"</code><br><code> value = \"something.github.io\"</code><br><code> type = \"CNAME\"</code><br><code> proxied = true</code><br><code>}</code><br><br><code>resource \"cloudflare_record\" \"smtp\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"smtp\"</code><br><code> value = \"IP.OF.PRIVATE.VPS\"</code><br><code> type = \"A\"</code><br><code> proxied = false</code><br><code>}</code><br><br><code>resource \"cloudflare_record\" \"services\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"services\"</code><br><code> value = \"something.related.to.my.home\"</code><br><code> type = \"CNAME\"</code><br><code> proxied = true</code><br><code>}</code><br><br><code>resource \"cloudflare_record\" \"mx\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"${var.domain}\"</code><br><code> value = \"smtp.k8s.it\"</code><br><code> type = \"MX\"</code><br><code> priority = \"1\"</code><br><code>}</code><br><br><code>resource \"cloudflare_record\" \"google-verification\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"${var.domain}\"</code><br><code> value = \"google-site-verification=fdsfdssgfdg4teurtxh\"</code><br><code> type = \"TXT\"</code><br><code>}</code><br><br><code>resource \"cloudflare_record\" \"spf\" {</code><br><code> domain = \"${var.domain}\"</code><br><code> name = \"${var.domain}\"</code><br><code> value = \"v=spf1 ip4:IP.OF.PRIVATE.VPS mx ~all\"</code><br><code> type = \"TXT\"</code><br><code>}</code></pre>\n<p>Force the HTTPS with page rules</p>\n<pre>$ <code>cat cloudflare_rules.tf</code><br><code>resource \"cloudflare_page_rule\" \"always_use_https_www\" {</code><br><code> zone = \"${var.domain}\"</code><br><code> target = \"http://www.${var.domain}/*\"</code><br><code> priority = 1</code><br><br><code> actions = {</code><br><code> always_use_https = \"true\",</code><br><code> }</code><br><code>}</code><br><br><code>resource \"cloudflare_page_rule\" \"always_use_https_services\" {</code><br><code> zone = \"${var.domain}\"</code><br><code> target = \"http://services.${var.domain}/*\"</code><br><code> priority = 2</code><br><br><code> actions = {</code><br><code> always_use_https = \"true\",</code><br><code> }</code><br><code>}</code></pre>\n<p>And finally create the common zone settings </p>\n<pre>$ <code>cat cloudflare_zone.tf</code><br><code>resource \"cloudflare_zone_settings_override\" \"k8s-settings\" {</code><br><code> name = \"${var.domain}\"</code><br><br><code> settings {</code><br><code> tls_1_3 = \"on\"</code><br><code> ssl = \"flexible\"</code><br><code> opportunistic_encryption = \"on\"</code><br><code> brotli = \"on\"</code><br><code> automatic_https_rewrites = \"on\"</code><br><code> security_level = \"medium\"</code><br><code> minify {</code><br><code> css = \"on\"</code><br><code> js = \"on\"</code><br><code> html = \"on\"</code><br><code> }</code><br><code> browser_cache_ttl = \"14400\"</code><br><code> }</code><br><code>}</code></pre>\n<p>use the terraform plan to check if everything it's of and terrafom plan to apply the changes</p>\n<pre>$ <code>terraform apply</code><br><code>cloudflare_record.mx: Refreshing state... (ID: c3624cc8fd163199ec082649a55f337a)</code><br><code>cloudflare_record.services: Refreshing state... (ID: 09041dfd16cbbf3b6915e79b14dc5466)</code><br><code>cloudflare_page_rule.always_use_https_services: Refreshing state... (ID: 92e196e6c7c8cba1f0759a60d713b0b9)</code><br><code>cloudflare_record.spf: Refreshing state... (ID: 3743b9f0be0a2c7a69245e169cf06ea5)</code><br><code>cloudflare_zone_settings_override.k8s-settings: Refreshing state... (ID: d4acc5e5713a0dede4f238b829f98947)</code><br><code>cloudflare_record.smtp: Refreshing state... (ID: 2d4628fc07c491d97e34b07da9ec60db)</code><br><code>cloudflare_page_rule.always_use_https_www: Refreshing state... (ID: 59c25cdd1096177a1019f834178de62f)</code><br><code>cloudflare_record.google-verification: Refreshing state... (ID: 131f35a9f8d2304a786a780db38b37e0)</code><br><code>cloudflare_record.www: Refreshing state... (ID: 76e3906f5ea172b627bed4922ebc1da7)</code><br><br><code>Apply complete! Resources: 0 added, 0 changed, 0 destroyed.</code></pre>\n<p> </p>\n<pre>$ <code>host www.k8s.it</code><br><code>www.k8s.it has address 104.27.164.146</code><br><code>www.k8s.it has address 104.27.165.146</code><br><code>www.k8s.it has IPv6 address 2400:cb00:2048:1::681b:a492</code><br><code>www.k8s.it has IPv6 address 2400:cb00:2048:1::681b:a592</code></pre>\n<pre>$ <code>echo | openssl s_client -servername www.k8s.it -connect www.k8s.it:443</code><br><code>CONNECTED(00000003)</code><br><code>depth=2 C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA Limited, CN = COMODO ECC Certification Authority</code><br><code>---</code><br><code>Certificate chain</code><br><code> 0 s:/OU=Domain Control Validated/OU=PositiveSSL Multi-Domain/CN=sni154797.cloudflaressl.com</code><br><code> i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Domain Validation Secure Server CA 2</code><br><code> 1 s:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Domain Validation Secure Server CA 2</code><br><code> i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Certification Authority</code><br><code> 2 s:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO ECC Certification Authority</code><br><code> i:/C=SE/O=AddTrust AB/OU=AddTrust External TTP Network/CN=AddTrust External CA Root</code></pre>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "waf",
                   "terraform",
                   "gitlab",
                   "cloudflare",
                   "cdn",
                   "automation"
            ],
            "date_published": "2020-08-11T21:19:11+02:00",
            "date_modified": "2020-08-11T21:19:11+02:00"
        },
        {
            "id": "https://www.k8s.it/kubernetes-for-mere-mortals.html",
            "url": "https://www.k8s.it/kubernetes-for-mere-mortals.html",
            "title": "Kubernetes for mere mortals",
            "summary": "Well, what do you need to build your homemade cluster? armbian 4.10.1 kubeadm and kubelet 1.6.4 traefik as a ingress controller heapster, collectd, influxdb and grafana as a monitoring stack NAMESPACE NAME READY STATUS RESTARTS AGEhome-prd k8s-helloworld-3468567185-2fwhb 1/1 Running 0 10dhome-prd k8s-helloworld-3468567185-lbgpk 1/1 Running 2&hellip;",
            "content_html": "<p>Well, what do you need to build your homemade cluster?</p>\n<p><img loading=\"lazy\" src=\"https://www.k8s.it/media/posts/3/k8s.arm-lg.jpeg\" sizes=\"(max-width: 48em) 100vw, 768px\" srcset=\"https://www.k8s.it/media/posts/3/responsive/k8s.arm-lg-xs.jpeg 300w ,https://www.k8s.it/media/posts/3/responsive/k8s.arm-lg-sm.jpeg 480w ,https://www.k8s.it/media/posts/3/responsive/k8s.arm-lg-md.jpeg 768w\"  alt=\"\" width=\"744\" height=\"400\"></p>\n<p><img loading=\"lazy\" src=\"https://www.k8s.it/media/posts/3/IMG_20170605_150237.jpg\" sizes=\"(max-width: 48em) 100vw, 768px\" srcset=\"https://www.k8s.it/media/posts/3/responsive/IMG_20170605_150237-xs.jpg 300w ,https://www.k8s.it/media/posts/3/responsive/IMG_20170605_150237-sm.jpg 480w ,https://www.k8s.it/media/posts/3/responsive/IMG_20170605_150237-md.jpg 768w\"  alt=\"\" width=\"832\" height=\"624\"></p>\n<ul>\n<li>1x usb hub Anker 60W PowerPort 6</li>\n<li>4x orangepi plus 2e</li>\n</ul>\n<p> armbian 4.10.1 </p>\n<p>kubeadm and kubelet 1.6.4</p>\n<p>traefik as a ingress controller</p>\n<p>heapster, collectd, influxdb and grafana as a monitoring stack</p>\n<div class=\"slate-resizable-image-embed slate-image-embed__resize-full-width\"><img loading=\"lazy\" src=\"https://media.licdn.com/dms/image/C5612AQFJsWW1J0HYig/article-inline_image-shrink_1500_2232/0?e=2122596000&amp;v=beta&amp;t=O4agFAs9-5g0xGt6frAU-koLZROOeVmv2p7yhmZyEAY\" data-is-external-image=\"true\"  data-media-urn=\"urn:li:digitalmediaAsset:C5612AQFJsWW1J0HYig\" data-li-src=\"https://media.licdn.com/dms/image/C5612AQFJsWW1J0HYig/article-inline_image-shrink_1500_2232/0?e=2122596000&amp;v=beta&amp;t=O4agFAs9-5g0xGt6frAU-koLZROOeVmv2p7yhmZyEAY\"></div>\n<p> </p>\n<div class=\"slate-resizable-image-embed slate-image-embed__resize-full-width\"><img loading=\"lazy\" src=\"https://media.licdn.com/dms/image/C4E12AQFGmg6f2D2CcQ/article-inline_image-shrink_1000_1488/0?e=2122596000&amp;v=beta&amp;t=H2Sp0_RJzeKQLmbD7JiF6jW-bqdvqkgRzPTmXqhogpI\" data-is-external-image=\"true\"  data-media-urn=\"urn:li:digitalmediaAsset:C4E12AQFGmg6f2D2CcQ\" data-li-src=\"https://media.licdn.com/dms/image/C4E12AQFGmg6f2D2CcQ/article-inline_image-shrink_1000_1488/0?e=2122596000&amp;v=beta&amp;t=H2Sp0_RJzeKQLmbD7JiF6jW-bqdvqkgRzPTmXqhogpI\"></div>\n<pre spellcheck=\"false\">NAMESPACE     NAME                                        READY     STATUS    RESTARTS   AGE\nhome-prd      k8s-helloworld<span class=\"hljs-number\">-3468567185-2f</span>whb             <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">10d</span>\nhome-prd      k8s-helloworld<span class=\"hljs-number\">-3468567185</span>-lbgpk             <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">2</span>          <span class=\"hljs-number\">73d</span>\nhome-prd      k8s-helloworld<span class=\"hljs-number\">-3468567185</span>-vz9n5             <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">2</span>          <span class=\"hljs-number\">73d</span>\nkube-system   etcd-k8s-node001                            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">19</span>         <span class=\"hljs-number\">81d</span>\nkube-system   heapster<span class=\"hljs-number\">-3703175019-7f</span>z27                   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">2</span>          <span class=\"hljs-number\">76d</span>\nkube-system   kube-apiserver-k8s-node001                  <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">8</span>          <span class=\"hljs-number\">81d</span>\nkube-system   kube-controller-manager-k8s-node001         <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">22</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kube-dns<span class=\"hljs-number\">-279829092</span>-r8595                    <span class=\"hljs-number\">3</span>/<span class=\"hljs-number\">3</span>       Running   <span class=\"hljs-number\">39</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kube-flannel-ds<span class=\"hljs-number\">-08</span>z1k                       <span class=\"hljs-number\">2</span>/<span class=\"hljs-number\">2</span>       Running   <span class=\"hljs-number\">44</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kube-flannel-ds<span class=\"hljs-number\">-3</span>bqmf                       <span class=\"hljs-number\">2</span>/<span class=\"hljs-number\">2</span>       Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">10d</span>\nkube-system   kube-flannel-ds-f51rq                       <span class=\"hljs-number\">2</span>/<span class=\"hljs-number\">2</span>       Running   <span class=\"hljs-number\">10</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kube-flannel-ds-l5wjs                       <span class=\"hljs-number\">2</span>/<span class=\"hljs-number\">2</span>       Running   <span class=\"hljs-number\">8</span>          <span class=\"hljs-number\">81d</span>\nkube-system   kube-proxy<span class=\"hljs-number\">-3</span>gn3x                            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">12</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kube-proxy<span class=\"hljs-number\">-88762</span>                            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">2</span>          <span class=\"hljs-number\">81d</span>\nkube-system   kube-proxy-dghmh                            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">10d</span>\nkube-system   kube-proxy-dtf9c                            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">3</span>          <span class=\"hljs-number\">81d</span>\nkube-system   kube-scheduler-k8s-node001                  <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">29</span>         <span class=\"hljs-number\">81d</span>\nkube-system   kubernetes-dashboard<span class=\"hljs-number\">-1707270776</span>-jgxbp       <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">2</span>          <span class=\"hljs-number\">81d</span>\nkube-system   traefik-ingress-controller<span class=\"hljs-number\">-49053153</span>-kgb3p   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>       Running   <span class=\"hljs-number\">1</span>          <span class=\"hljs-number\">30d</span>\n</pre>\n<p> </p>\n<p>backend docker example (nginx on arm) k8s-helloworld-arm</p>\n<p><a href=\"https://services.k8s.it/hello/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">live demo</a></p>\n<p><a href=\"https://services.k8s.it/grafana/dashboard/db/all-k8s-nodes?refresh=1m&amp;orgId=2&amp;from=now-24h&amp;to=now\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">monitoring</a></p>",
            "author": {
                "name": "lgirardi"
            },
            "tags": [
                   "traefik",
                   "orangepi",
                   "lab",
                   "kubernetes",
                   "k8s",
                   "armbian",
                   "arm"
            ],
            "date_published": "2020-08-11T21:19:11+02:00",
            "date_modified": "2020-08-11T21:19:11+02:00"
        }
    ]
}
